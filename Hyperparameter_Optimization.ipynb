{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascal-maker/machinelearning/blob/main/Hyperparameter_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CupQy7gxUPs"
      },
      "source": [
        "# Hyperparameter optimization by means of cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qf4UzbLIxUPt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "LJ4wyr2ExUPu",
        "outputId": "3eb5265a-4c15-4017-d240-46bb484fe759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6       92             62             32      126  32.0   \n",
              "1            2      125             60             20      140  33.8   \n",
              "2            0      117             80             31       53  45.2   \n",
              "3            1       87             78             27       32  34.6   \n",
              "4            3      116             74             15      105  26.3   \n",
              "5            1      128             82             17      183  27.5   \n",
              "6            4      110             76             20      100  28.4   \n",
              "7            6      105             70             32       68  30.8   \n",
              "8            1      157             72             21      168  25.6   \n",
              "9            2      102             86             36      120  45.5   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                      85.0   46        0  \n",
              "1                      88.0   31        0  \n",
              "2                      89.0   24        0  \n",
              "3                     101.0   22        0  \n",
              "4                     107.0   24        0  \n",
              "5                     115.0   22        0  \n",
              "6                     118.0   27        0  \n",
              "7                     122.0   37        0  \n",
              "8                     123.0   24        0  \n",
              "9                     127.0   23        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e74a4843-22f3-4d28-bbdf-52de2cd1011a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>92</td>\n",
              "      <td>62</td>\n",
              "      <td>32</td>\n",
              "      <td>126</td>\n",
              "      <td>32.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>125</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>140</td>\n",
              "      <td>33.8</td>\n",
              "      <td>88.0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>80</td>\n",
              "      <td>31</td>\n",
              "      <td>53</td>\n",
              "      <td>45.2</td>\n",
              "      <td>89.0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>78</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>34.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>15</td>\n",
              "      <td>105</td>\n",
              "      <td>26.3</td>\n",
              "      <td>107.0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>82</td>\n",
              "      <td>17</td>\n",
              "      <td>183</td>\n",
              "      <td>27.5</td>\n",
              "      <td>115.0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>110</td>\n",
              "      <td>76</td>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>28.4</td>\n",
              "      <td>118.0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>105</td>\n",
              "      <td>70</td>\n",
              "      <td>32</td>\n",
              "      <td>68</td>\n",
              "      <td>30.8</td>\n",
              "      <td>122.0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>157</td>\n",
              "      <td>72</td>\n",
              "      <td>21</td>\n",
              "      <td>168</td>\n",
              "      <td>25.6</td>\n",
              "      <td>123.0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>86</td>\n",
              "      <td>36</td>\n",
              "      <td>120</td>\n",
              "      <td>45.5</td>\n",
              "      <td>127.0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e74a4843-22f3-4d28-bbdf-52de2cd1011a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e74a4843-22f3-4d28-bbdf-52de2cd1011a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e74a4843-22f3-4d28-bbdf-52de2cd1011a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9b6a9e39-dcfe-4774-a025-ccb21b45f7e1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b6a9e39-dcfe-4774-a025-ccb21b45f7e1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9b6a9e39-dcfe-4774-a025-ccb21b45f7e1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 380,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 56,\n        \"max\": 198,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          95,\n          116,\n          144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 24,\n        \"max\": 110,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          46,\n          58,\n          74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 7,\n        \"max\": 60,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          40,\n          51,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 15,\n        \"max\": 846,\n        \"num_unique_values\": 180,\n        \"samples\": [\n          90,\n          510,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.946588020536825,\n        \"min\": 18.2,\n        \"max\": 67.1,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          36.7,\n          20.8,\n          21.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 339.66807037729683,\n        \"min\": 0.15,\n        \"max\": 2329.0,\n        \"num_unique_values\": 324,\n        \"samples\": [\n          408.0,\n          341.0,\n          423.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          40,\n          25,\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "dataset = pd.read_csv('diabetes.csv')\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UltYy3YBxUPu",
        "outputId": "c6626dc0-cfba-4458-b6f4-a4bf58cdc754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(280, 8)\n"
          ]
        }
      ],
      "source": [
        "y = dataset['Outcome'].values\n",
        "X = dataset.drop('Outcome',axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 100, random_state =0)\n",
        "print(X_train.shape)\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)  # Normaliseer naar gemiddelde = 0 en standaardafwijking = 1\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features (X): Alle kolommen behalve Outcome.\n",
        "\n",
        "Targets (y): Alleen de Outcome kolom.\n",
        "\n",
        "Train/Test Split: 100 samples voor de test set, de rest voor de train set.\n",
        "\n",
        "Waarom random_state? Voor reproduceerbare resultaten.\n",
        "\n"
      ],
      "metadata": {
        "id": "KnjxMis12hai"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyEfKx2FxUPu"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5vffuMQxUPu",
        "outputId": "dc4db852-5233-4e55-e1f1-c632f97b1130"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 70 candidates, totalling 350 fits\n",
            "Best accuracy :  0.7928571428571429\n",
            "Best parameters : {'C': np.float64(1111.12), 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81        63\n",
            "           1       0.71      0.46      0.56        37\n",
            "\n",
            "    accuracy                           0.73       100\n",
            "   macro avg       0.72      0.67      0.68       100\n",
            "weighted avg       0.73      0.73      0.71       100\n",
            "\n",
            "[[56  7]\n",
            " [20 17]]\n",
            "73.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "paramaters = [\n",
        "        {'kernel': ['linear'], 'C': np.linspace(0.01,10000,10)}, # 10 models\n",
        "        {'kernel': ['rbf'], 'C': np.linspace(0.01,10000,10), 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2]}, #10x5 = 50 models\n",
        "        {'kernel': ['poly'], 'C':np.linspace(0.01,10000,10)} ] # 10 models\n",
        "grid_search = GridSearchCV(estimator = model,\n",
        "                           param_grid = paramaters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5, # k=5\n",
        "                           n_jobs = -1,\n",
        "                           verbose =5)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_  )\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uitleg voor Beginners: SVM Hyperparameter Tuning met GridSearchCV**\n",
        "\n",
        "Deze code gebruikt **GridSearchCV** om de **beste** hyperparameters te vinden voor een **Support Vector Machine (SVM)**. Dit helpt je om een **nauwkeuriger** en **betrouwbaarder** model te maken.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Model Maken**\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "```\n",
        "\n",
        "* **SVC()** maakt een leeg **Support Vector Machine** model.\n",
        "* Dit model moet nog **getraind** worden.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Hyperparameter Grid Maken**\n",
        "\n",
        "```python\n",
        "paramaters = [\n",
        "    {'kernel': ['linear'], 'C': np.linspace(0.01, 10000, 10)},  # 10 modellen\n",
        "    {'kernel': ['rbf'], 'C': np.linspace(0.01, 10000, 10), 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2]},  # 50 modellen\n",
        "    {'kernel': ['poly'], 'C': np.linspace(0.01, 10000, 10)}  # 10 modellen\n",
        "]\n",
        "```\n",
        "\n",
        "* **Linear Kernel**:\n",
        "\n",
        "  * Alleen **C** wordt getest.\n",
        "* **RBF Kernel**:\n",
        "\n",
        "  * Zowel **C** als **gamma** worden getest.\n",
        "* **Polynomial Kernel**:\n",
        "\n",
        "  * Alleen **C** wordt getest.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. GridSearchCV Configureren**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='accuracy',\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    n_jobs=-1,  # Gebruik alle beschikbare CPU-kernen\n",
        "    verbose=5  # Laat je zien wat er gebeurt\n",
        ")\n",
        "```\n",
        "\n",
        "* **scoring='accuracy'**: Het model wordt beoordeeld op **nauwkeurigheid**.\n",
        "* **cv=5**: Gebruikt **5-fold cross-validation** voor een **betere** score.\n",
        "* **n\\_jobs=-1**: Maakt gebruik van **alle** beschikbare CPU-kernen voor **snellere** berekeningen.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Het Model Trainen**\n",
        "\n",
        "```python\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Hier wordt het model **getraind** met **alle** combinaties van hyperparameters.\n",
        "* Dit kan **lang duren** als je dataset **groot** is.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Beste Hyperparameters Vinden**\n",
        "\n",
        "```python\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', best_accuracy)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **grid\\_search.best\\_score\\_** geeft je de **hoogste** nauwkeurigheid die werd gevonden.\n",
        "* **grid\\_search.best\\_params\\_** vertelt je **welke** hyperparameters dit resultaat gaven.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Voorspellingen Maken met het Beste Model**\n",
        "\n",
        "```python\n",
        "y_pred = grid_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Maakt voorspellingen met het **beste** model dat **GridSearchCV** heeft gevonden.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Resultaten Evalueren**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report** geeft je:\n",
        "\n",
        "  * **Precision**: Hoeveel van je voorspellingen correct waren.\n",
        "  * **Recall**: Hoeveel van de echte voorbeelden correct werden voorspeld.\n",
        "  * **F1-score**: Balans tussen precision en recall.\n",
        "* **confusion\\_matrix** toont je hoeveel voorbeelden correct of fout zijn geclassificeerd.\n",
        "* **accuracy\\_score** geeft je het percentage **correcte** voorspellingen.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Verwachte Output**\n",
        "\n",
        "Bijvoorbeeld:\n",
        "\n",
        "```\n",
        "Best accuracy :  0.95\n",
        "Best parameters : {'C': 100, 'kernel': 'rbf', 'gamma': 0.01}\n",
        "[[50  5]\n",
        " [ 3 42]]\n",
        "95.0\n",
        "```\n",
        "\n",
        "* Dit betekent dat je model **95%** nauwkeurig was met de beste parameters.\n",
        "\n",
        "---\n",
        "\n",
        "### **9. Waarom Dit Belangrijk is**\n",
        "\n",
        "* **Automatische Optimalisatie**:\n",
        "\n",
        "  * Je hoeft niet **handmatig** elke combinatie te proberen.\n",
        "* **Sneller** en **Betrouwbaarder**:\n",
        "\n",
        "  * Maakt gebruik van **cross-validatie** voor betere resultaten.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LpkR0nNV234h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xVNPq26y2a1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search: Test alle combinaties van hyperparameters.\n",
        "\n",
        "Param Grid:\n",
        "\n",
        "Linear Kernel: Alleen C (10 waarden).\n",
        "\n",
        "RBF Kernel: C (10 waarden) en gamma (5 waarden).\n",
        "\n",
        "Polynomial Kernel: Alleen C (10 waarden).\n",
        "\n",
        "Aantal Geteste Modellen:\n",
        "\n",
        "10 + 50 + 10 = 70 modellen.\n",
        "\n",
        "Cross-Validation: 5-fold CV voor betrouwbaardere resultaten.\n",
        "\n",
        "n_jobs = -1: Gebruikt alle CPU cores.\n",
        "\n"
      ],
      "metadata": {
        "id": "5Vrv3InL2qHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "best_score_: Hoogste cross-validated accuracy.\n",
        "\n",
        "best_params_: Beste combinatie van hyperparameters."
      ],
      "metadata": {
        "id": "HMqnoQc_2wIA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC5UhT2YxUPv"
      },
      "source": [
        "## Random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra9fshUsxUPv",
        "outputId": "614fbf35-6d8c-444d-cc06-46d95269b4cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Best accuracy :  0.7821428571428571\n",
            "Best parameters : {'C': np.float64(4943.873696576355), 'gamma': np.float64(0.10439112845948587), 'kernel': 'linear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79        63\n",
            "           1       0.64      0.49      0.55        37\n",
            "\n",
            "    accuracy                           0.71       100\n",
            "   macro avg       0.69      0.66      0.67       100\n",
            "weighted avg       0.70      0.71      0.70       100\n",
            "\n",
            "[[53 10]\n",
            " [19 18]]\n",
            "71.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# distributions\n",
        "from scipy.stats import randint\n",
        "from scipy.stats import uniform\n",
        "\n",
        "\n",
        "\n",
        "model = SVC()\n",
        "parameters = {'kernel': ['linear','rbf','poly'],\n",
        "              'C': uniform(0.001, 10000), # haal C uit een random uniform distribution\n",
        "              'gamma': uniform(0.001, 0.2)}\n",
        "\n",
        "\n",
        "n_iter_search = 10\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
        "\n",
        "random_search = random_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', random_search.best_score_)\n",
        "print('Best parameters :',random_search.best_params_  )\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uitleg voor Beginners: SVM Hyperparameter Tuning met RandomizedSearchCV**\n",
        "\n",
        "In deze code gebruiken we **RandomizedSearchCV** om **automatisch** de **beste** hyperparameters voor een **Support Vector Machine (SVM)** te vinden. Dit is **sneller** dan **GridSearchCV** omdat het **willekeurig** combinaties probeert in plaats van **alle** mogelijke combinaties.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Het Model Maken**\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "```\n",
        "\n",
        "* **SVC()** maakt een **Support Vector Machine** model.\n",
        "* Dit model is nog niet **getraind**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Hyperparameter Distributies Maken**\n",
        "\n",
        "```python\n",
        "from scipy.stats import uniform\n",
        "\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],  # Test verschillende soorten kernels\n",
        "    'C': uniform(0.001, 10000),  # Kies C-waarden willekeurig tussen 0.001 en 10000\n",
        "    'gamma': uniform(0.001, 0.2)  # Kies gamma-waarden willekeurig tussen 0.001 en 0.2\n",
        "}\n",
        "```\n",
        "\n",
        "* **kernel**:\n",
        "\n",
        "  * **linear**: Rechte lijnen.\n",
        "  * **rbf** (Radial Basis Function): Gebogen lijnen.\n",
        "  * **poly** (Polynomial): Polynomiale lijnen.\n",
        "* **C**:\n",
        "\n",
        "  * Bepaalt hoe **streng** je model is bij het vermijden van fouten.\n",
        "* **gamma** (voor RBF en Poly):\n",
        "\n",
        "  * Bepaalt hoe ver de invloed van een enkel voorbeeld reikt.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. RandomizedSearchCV Configureren**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_iter_search = 10  # Test 10 willekeurige combinaties\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=parameters,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    n_iter=n_iter_search,  # Test 10 willekeurige combinaties\n",
        "    n_jobs=-1,  # Gebruik alle CPU-kernen\n",
        "    verbose=1  # Laat zien wat er gebeurt\n",
        ")\n",
        "```\n",
        "\n",
        "* **n\\_iter=10**:\n",
        "\n",
        "  * Test **10** willekeurige combinaties van hyperparameters.\n",
        "* **cv=5**:\n",
        "\n",
        "  * Gebruik **5-fold cross-validation** voor **betere** resultaten.\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Gebruik **alle** beschikbare CPU-kernen voor **snellere** berekeningen.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Model Trainen**\n",
        "\n",
        "```python\n",
        "random_search = random_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Hier wordt het model **getraind** met **willekeurige** combinaties van hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Beste Hyperparameters Vinden**\n",
        "\n",
        "```python\n",
        "best_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', best_accuracy)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **random\\_search.best\\_score\\_** geeft je de **hoogste** nauwkeurigheid die werd gevonden.\n",
        "* **random\\_search.best\\_params\\_** vertelt je **welke** hyperparameters dit resultaat gaven.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Voorspellingen Maken met het Beste Model**\n",
        "\n",
        "```python\n",
        "y_pred = random_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Maakt voorspellingen met de **beste** hyperparameters die werden gevonden.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Resultaten Evalueren**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Laat je **precision**, **recall**, en **f1-score** zien voor elke klasse.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Laat zien hoeveel voorbeelden correct en fout werden geclassificeerd.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Geeft je het **percentage** correcte voorspellingen.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Verwachte Output**\n",
        "\n",
        "Bijvoorbeeld:\n",
        "\n",
        "```\n",
        "Best accuracy : 0.95\n",
        "Best parameters : {'C': 123.45, 'gamma': 0.02, 'kernel': 'rbf'}\n",
        "[[50  5]\n",
        " [ 3 42]]\n",
        "95.0\n",
        "```\n",
        "\n",
        "* Dit betekent dat je model **95%** nauwkeurig was met de beste parameters.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ydpYAUhG2-7t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_r28Ug8xUPv"
      },
      "source": [
        "## Bayes search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEKCpKLDxUPv",
        "outputId": "7493ae40-7c63-4f06-cab0-2517a2f25d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best accuracy :  0.7821428571428571\n",
            "Best parameters : OrderedDict([('C', 72.85506732880897), ('gamma', 0.18885019239406514), ('kernel', 'linear')])\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79        63\n",
            "           1       0.64      0.49      0.55        37\n",
            "\n",
            "    accuracy                           0.71       100\n",
            "   macro avg       0.69      0.66      0.67       100\n",
            "weighted avg       0.70      0.71      0.70       100\n",
            "\n",
            "[[53 10]\n",
            " [19 18]]\n",
            "71.0\n"
          ]
        }
      ],
      "source": [
        "# BayesSearchCV\n",
        "\n",
        "from skopt import BayesSearchCV #scikit-optimize\n",
        "\n",
        "# distributions\n",
        "from scipy.stats import randint\n",
        "from scipy.stats import uniform\n",
        "\n",
        "\n",
        "model = SVC()\n",
        "parameters = {'kernel': ['linear','rbf','poly'],\n",
        "              'C': (0.01, 100,'uniform'),\n",
        "              'gamma': (0.001, 0.2,'uniform')}\n",
        "\n",
        "n_iter_search = 10\n",
        "\n",
        "Bayes_search = BayesSearchCV(model,parameters,n_iter=n_iter_search,cv=5,verbose=1)\n",
        "\n",
        "\n",
        "Bayes_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = Bayes_search.best_score_\n",
        "best_parameters = Bayes_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', Bayes_search.best_score_)\n",
        "print('Best parameters :',Bayes_search.best_params_  )\n",
        "\n",
        "y_pred = Bayes_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uitleg voor Beginners: Hyperparameter Tuning met BayesSearchCV**\n",
        "\n",
        "Deze code gebruikt **BayesSearchCV** om **automatisch** de **beste** hyperparameters voor een **Support Vector Machine (SVM)** te vinden. Dit is **sneller** en **slimmer** dan **GridSearchCV** of **RandomizedSearchCV** omdat het **Bayesiaanse optimalisatie** gebruikt.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Wat is BayesSearchCV?**\n",
        "\n",
        "* In plaats van **willekeurig** of **uitputtend** combinaties te proberen, leert BayesSearchCV welke hyperparametercombinaties **waarschijnlijk** de **beste** zijn.\n",
        "* Het gebruikt **Bayesiaanse optimalisatie** om sneller tot de beste hyperparameters te komen.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Het Model Maken**\n",
        "\n",
        "```python\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "```\n",
        "\n",
        "* **SVC()** maakt een **Support Vector Machine** model.\n",
        "* Dit model moet nog **getraind** worden.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Hyperparameter Ruimte Definiëren**\n",
        "\n",
        "```python\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],  # Test verschillende soorten kernels\n",
        "    'C': (0.01, 100, 'uniform'),  # Kies C-waarden willekeurig tussen 0.01 en 100\n",
        "    'gamma': (0.001, 0.2, 'uniform')  # Kies gamma-waarden willekeurig tussen 0.001 en 0.2\n",
        "}\n",
        "```\n",
        "\n",
        "* **kernel**:\n",
        "\n",
        "  * **linear**: Rechte lijnen.\n",
        "  * **rbf** (Radial Basis Function): Gebogen lijnen.\n",
        "  * **poly** (Polynomial): Polynomiale lijnen.\n",
        "* **C**:\n",
        "\n",
        "  * Bepaalt hoe **streng** je model is bij het vermijden van fouten.\n",
        "* **gamma** (voor RBF en Poly):\n",
        "\n",
        "  * Bepaalt hoe ver de invloed van een enkel voorbeeld reikt.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. BayesSearchCV Configureren**\n",
        "\n",
        "```python\n",
        "n_iter_search = 10  # Test 10 combinaties\n",
        "\n",
        "Bayes_search = BayesSearchCV(\n",
        "    model,\n",
        "    parameters,\n",
        "    n_iter=n_iter_search,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    verbose=1  # Laat zien wat er gebeurt\n",
        ")\n",
        "```\n",
        "\n",
        "* **n\\_iter\\_search = 10**:\n",
        "\n",
        "  * Test **10** combinaties van hyperparameters.\n",
        "* **cv = 5**:\n",
        "\n",
        "  * Gebruik **5-fold cross-validation** voor **betere** resultaten.\n",
        "* **verbose = 1**:\n",
        "\n",
        "  * Laat je **zien** welke combinaties worden geprobeerd.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Model Trainen**\n",
        "\n",
        "```python\n",
        "Bayes_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Hier wordt het model **getraind** met **Bayesiaanse optimalisatie**.\n",
        "* Het model leert **sneller** de beste hyperparameters te vinden.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Beste Hyperparameters Vinden**\n",
        "\n",
        "```python\n",
        "best_accuracy = Bayes_search.best_score_\n",
        "best_parameters = Bayes_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', best_accuracy)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **Bayes\\_search.best\\_score\\_** geeft je de **hoogste** nauwkeurigheid die werd gevonden.\n",
        "* **Bayes\\_search.best\\_params\\_** vertelt je **welke** hyperparameters dit resultaat gaven.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Voorspellingen Maken met het Beste Model**\n",
        "\n",
        "```python\n",
        "y_pred = Bayes_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Maakt voorspellingen met de **beste** hyperparameters die werden gevonden.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Resultaten Evalueren**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Laat je **precision**, **recall**, en **f1-score** zien voor elke klasse.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Laat zien hoeveel voorbeelden correct en fout werden geclassificeerd.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Geeft je het **percentage** correcte voorspellingen.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Verwachte Output**\n",
        "\n",
        "Bijvoorbeeld:\n",
        "\n",
        "```\n",
        "Best accuracy : 0.96\n",
        "Best parameters : {'C': 10.32, 'gamma': 0.12, 'kernel': 'rbf'}\n",
        "[[50  5]\n",
        " [ 3 42]]\n",
        "96.0\n",
        "```\n",
        "\n",
        "* Dit betekent dat je model **96%** nauwkeurig was met de beste parameters.\n",
        "\n",
        "---\n",
        "\n",
        "### **10. Waarom Dit Belangrijk is**\n",
        "\n",
        "* **Sneller** en **slimmer** dan GridSearchCV of RandomizedSearchCV.\n",
        "* Maakt gebruik van **Bayesiaanse optimalisatie** voor **snellere** convergentie.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGumlhDf3LUv"
      }
    },
    {
      "source": [
        "!pip install scikit-optimize"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2_CnsWAv2BzM",
        "outputId": "cb53d68f-256a-4a15-8310-39b5440b9921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.5.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bayesian Search: Geavanceerdere zoekstrategie die sneller convergeert naar optimale combinaties.\n",
        "\n",
        "n_iter_search: Test 10 combinaties.\n",
        "\n",
        "Voordeel: Efficiënter dan zowel Grid Search als Randomized Search Uitvoer: Geeft de beste combinatie van parameters en de bijbehorende accuracy.\n",
        "\n",
        "Vergelijk: Hoe presteert dit model in vergelijking met Grid Search en Randomized Search?\n",
        "\n"
      ],
      "metadata": {
        "id": "2zq3-Vbf3Lj8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvwhFAjvxUPw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMkEQu5qxUPw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}