{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascal-maker/machinelearning/blob/main/Demos_GDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcqaaT0PCAQH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "from ipywidgets import interact, FloatSlider\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0WLi8f9CAQH"
      },
      "outputs": [],
      "source": [
        "def compute_J(x,y,theta0, theta1):\n",
        "\n",
        "    x= np.c_[x,np.ones(len(x))]\n",
        "    theta = np.array([theta1,theta0])\n",
        "    h = np.dot(theta,x.T)\n",
        "    e = h.T - y\n",
        "    J = np.sum(e**2)/len(x)\n",
        "    return(J)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doel: Berekening van de kostenfunctie\n",
        "𝐽\n",
        "(\n",
        "𝜃\n",
        "0\n",
        ",\n",
        "𝜃\n",
        "1\n",
        ")\n",
        "J(θ\n",
        "0\n",
        "​\n",
        " ,θ\n",
        "1\n",
        "​\n",
        " ) voor lineaire regressie.\n",
        "\n",
        "x: Toevoegen van een bias-term (een kolom van enen) aan de invoer om de intercept (\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        " ) te kunnen modelleren.\n",
        "\n",
        "theta: Modelparameters\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        "  (helling) en\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        "  (intercept) als een numpy array.\n",
        "\n",
        "h: Voorspellingen (\n",
        "ℎ\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝜃\n",
        "1\n",
        "⋅\n",
        "𝑥\n",
        "+\n",
        "𝜃\n",
        "0\n",
        "h(x)=θ\n",
        "1\n",
        "​\n",
        " ⋅x+θ\n",
        "0\n",
        "​\n",
        " ) berekend met matrixvermenigvuldiging.\n",
        "\n",
        "e: Foutvector (verschil tussen voorspellingen en werkelijke waarden).\n",
        "\n",
        "J: Gemiddelde kwadratische fout (Mean Squared Error) voor een bepaalde combinatie van\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        "  en\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        " ."
      ],
      "metadata": {
        "id": "w6IeX748D2V2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOcStc8BCAQI"
      },
      "outputs": [],
      "source": [
        "data = np.genfromtxt('Blood_Pressure_GDS.csv',delimiter=',')\n",
        "J = compute_J(data[:,1],data[:,2],2.85,1.67)\n",
        "print(J)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data inlezen:\n",
        "\n",
        "Leest de dataset (Blood_Pressure_GDS.csv), waarbij de eerste kolom de index is, de tweede kolom weight en de derde kolom blood pressure.\n",
        "\n",
        "Berekening van J:\n",
        "\n",
        "Berekent\n",
        "𝐽\n",
        "J voor vaste waarden van\n",
        "𝜃\n",
        "0\n",
        "=\n",
        "2.85\n",
        "θ\n",
        "0\n",
        "​\n",
        " =2.85 en\n",
        "𝜃\n",
        "1\n",
        "=\n",
        "1.67\n",
        "θ\n",
        "1\n",
        "​\n",
        " =1.67."
      ],
      "metadata": {
        "id": "_tOkDOGsD_F9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqcFSakpCAQI"
      },
      "outputs": [],
      "source": [
        "# Cost function J(theta1, theta0 = 0)\n",
        "\n",
        "theta0 = 0\n",
        "theta1 = np.linspace(0,3.5,100)\n",
        "J = np.zeros(len(theta1))\n",
        "for t in range(0,len(theta1)):\n",
        "    J[t] = compute_J(data[:,1],data[:,2],theta0,theta1[t])\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(0, 249000,'ro')\n",
        "ax.plot(theta1, J )\n",
        "\n",
        "ax.set_xlabel('theta 1')\n",
        "ax.set_ylabel('J(theta)')\n",
        "ax.set_title('J as a function of theta1 with theta0 = 0');\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genereren van\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        "  waarden: Van 0 tot 3.5 met 100 stappen.\n",
        "\n",
        "Berekening van\n",
        "𝐽\n",
        "J voor elk\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        "  met een vaste\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        " .\n",
        "\n",
        "Visualisatie:\n",
        "\n",
        "Plot de kostenfunctie\n",
        "𝐽\n",
        "J als een functie van\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        " .\n",
        "\n",
        "Rood punt (\n",
        "0\n",
        ",\n",
        "249000\n",
        "0,249000) geeft een referentiepunt aan"
      ],
      "metadata": {
        "id": "-EFizZ8dEGVr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X362WQrbCAQI"
      },
      "outputs": [],
      "source": [
        "def callCompute_J(theta0,theta1):\n",
        "    Jtheta1 = compute_J(data[:,1],data[:,2],theta0,theta1)\n",
        "\n",
        "    theta1Axis = np.linspace(0,3,40)\n",
        "\n",
        "    xAxis = np.linspace(0,150,10)\n",
        "    yAxis = xAxis * theta1 + theta0\n",
        "    J = np.zeros(len(theta1Axis))\n",
        "    for t in range(0,len(theta1Axis)):\n",
        "        J[t] = compute_J(data[:,1],data[:,2],theta0,theta1Axis[t])\n",
        "\n",
        "\n",
        "    fig_subplots = plt.figure()\n",
        "    fig_subplots.set_size_inches(20,15)\n",
        "    ax1 = fig_subplots.add_subplot(2,3,1)\n",
        "    ax2 = fig_subplots.add_subplot(2,3,2)\n",
        "\n",
        "    ax1.plot(theta1, Jtheta1,'ro')\n",
        "    ax1.plot(theta1Axis, J )\n",
        "\n",
        "    ax1.set_xlabel('theta1')\n",
        "    ax1.set_ylabel('J')\n",
        "    ax1.set_title('Cost J');\n",
        "\n",
        "    ax2.scatter(data[:,1], data[:,2])\n",
        "    ax2.plot(xAxis,yAxis,'r')\n",
        "    ax2.set_xlabel('weight [kg]')\n",
        "    ax2.set_ylabel('Blood pressure [mmHg]')\n",
        "    ax2.set_title('Blood pressure as a funtion of the weight');\n",
        "\n",
        "    print('J = ', Jtheta1)\n",
        "    fig_subplots.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dit stuk code combineert een interactieve functie met matplotlib en ipywidgets om twee verschillende grafieken te plotten die samen de invloed van de theta parameters op de cost functie\n",
        "𝐽\n",
        "(\n",
        "𝜃\n",
        "0\n",
        ",\n",
        "𝜃\n",
        "1\n",
        ")\n",
        "J(θ\n",
        "0\n",
        "​\n",
        " ,θ\n",
        "1\n",
        "​\n",
        " ) en de lineaire fit van een dataset laten zien. Laten we de code stap voor stap bekijken:\n",
        "\n",
        "1. De Functie callCompute_J\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "def callCompute_J(theta0, theta1):\n",
        "Dit definieert een functie die twee parameters, theta0 en theta1, accepteert. Deze parameters vertegenwoordigen respectievelijk de bias en de helling van een lineair regressiemodel.\n",
        "\n",
        "2. Cost Berekening voor de Huidige Waarden van theta0 en theta1\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    Jtheta1 = compute_J(data[:,1], data[:,2], theta0, theta1)\n",
        "data[:,1]: De x-waarden (bijvoorbeeld gewicht in kg).\n",
        "\n",
        "data[:,2]: De y-waarden (bijvoorbeeld bloeddruk in mmHg).\n",
        "\n",
        "compute_J: Een externe functie die de cost berekent voor gegeven theta0 en theta1.\n",
        "\n",
        "3. Bereiding van de Assen voor de Plot\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    theta1Axis = np.linspace(0, 3, 40)\n",
        "    xAxis = np.linspace(0, 150, 10)\n",
        "    yAxis = xAxis * theta1 + theta0\n",
        "theta1Axis: Een reeks waarden voor theta1 om de cost functie over een bereik te plotten (0 tot 3, 40 punten).\n",
        "\n",
        "xAxis: De x-waarden voor de lineaire regressie lijn (0 tot 150 kg).\n",
        "\n",
        "yAxis: De bijbehorende y-waarden, berekend met de huidige theta0 en theta1 volgens de formule:\n",
        "\n",
        "𝑦\n",
        "=\n",
        "𝜃\n",
        "1\n",
        "⋅\n",
        "𝑥\n",
        "+\n",
        "𝜃\n",
        "0\n",
        "y=θ\n",
        "1\n",
        "​\n",
        " ⋅x+θ\n",
        "0\n",
        "​\n",
        "\n",
        "4. Berekening van de Cost Functie over theta1\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    J = np.zeros(len(theta1Axis))\n",
        "    for t in range(0, len(theta1Axis)):\n",
        "        J[t] = compute_J(data[:,1], data[:,2], theta0, theta1Axis[t])\n",
        "J: Een array om de cost waarden op te slaan.\n",
        "\n",
        "For-loop: Voor elke theta1 in theta1Axis wordt de cost berekend met de huidige theta0.\n",
        "\n",
        "5. Initialisatie van de Figuren\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    fig_subplots = plt.figure()\n",
        "    fig_subplots.set_size_inches(20, 15)\n",
        "    ax1 = fig_subplots.add_subplot(2, 3, 1)\n",
        "    ax2 = fig_subplots.add_subplot(2, 3, 2)\n",
        "fig_subplots: Een matplotlib figure object met een totaal van 6 (2 rijen × 3 kolommen) mogelijke subplots.\n",
        "\n",
        "ax1 en ax2: De eerste en tweede subplot van de figure.\n",
        "\n",
        "6. Plotten van de Cost Functie\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    ax1.plot(theta1, Jtheta1, 'ro')\n",
        "    ax1.plot(theta1Axis, J)\n",
        "    ax1.set_xlabel('theta1')\n",
        "    ax1.set_ylabel('J')\n",
        "    ax1.set_title('Cost J');\n",
        "Rode punt ('ro'): De cost voor de huidige theta0 en theta1.\n",
        "\n",
        "Blauwe lijn: De volledige cost curve voor verschillende theta1 waarden.\n",
        "\n",
        "Labels: Toegevoegd voor de x- en y-assen en een titel voor de grafiek.\n",
        "\n",
        "7. Plotten van de Lineaire Regressie\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    ax2.scatter(data[:,1], data[:,2])\n",
        "    ax2.plot(xAxis, yAxis, 'r')\n",
        "    ax2.set_xlabel('weight [kg]')\n",
        "    ax2.set_ylabel('Blood pressure [mmHg]')\n",
        "    ax2.set_title('Blood pressure as a function of the weight');\n",
        "Scatter Plot: De ruwe data punten.\n",
        "\n",
        "Rode Lijn: De lineaire regressie lijn gebaseerd op de huidige theta0 en theta1.\n",
        "\n",
        "8. Cost Waarde Printen en Layout Instellen\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "    print('J = ', Jtheta1)\n",
        "    fig_subplots.tight_layout()\n",
        "Cost Printen: Laat de huidige cost waarde in de console zien.\n",
        "\n",
        "tight_layout: Zorgt ervoor dat de subplots niet overlappen.\n",
        "\n",
        "9. De Interactieve Slider\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "interact(callCompute_J, theta0=FloatSlider(min=-20, max=20.0, step=1, value=0), theta1=FloatSlider(min=-1, max=3, step=0.1, value=0))\n",
        "interact: Maakt de functie callCompute_J interactief door sliders toe te voegen voor theta0 en theta1.\n",
        "\n",
        "Sliders:\n",
        "\n",
        "theta0: Verplaatsbaar van -20 tot 20 met stappen van 1.\n",
        "\n",
        "theta1: Verplaatsbaar van -1 tot 3 met stappen van 0.1.\n",
        "\n",
        "10. Wat Deze Code Doet\n",
        "Met deze code kun je interactief zien hoe de cost functie verandert als je theta0 en theta1 aanpast. Dit helpt bij het visualiseren van de optimalisatie van lineaire regressie, waarbij je zoekt naar de waarden voor theta0 en theta1 die de cost minimaliseren.\n",
        "\n"
      ],
      "metadata": {
        "id": "JAmpvExcFnZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFDWiuEQCAQI"
      },
      "outputs": [],
      "source": [
        "interact(callCompute_J,theta0=FloatSlider(min=-20, max=20.0, step=1, value=0),theta1=FloatSlider(min=-1, max=3, step=0.1, value=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doel: Maakt een interactieve visualisatie mogelijk.\n",
        "\n",
        "Sliders:\n",
        "\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        "  van -20 tot 20.\n",
        "\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        "  van -1 tot 3.\n",
        "\n",
        "Output:\n",
        "\n",
        "Linker plot: Kostenfunctie\n",
        "𝐽\n",
        "J als functie van\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        " .\n",
        "\n",
        "Rechter plot: Lineaire regressielijn bovenop de scatterplot van de gegevens."
      ],
      "metadata": {
        "id": "GbjjmIs3FzAE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIrLNWPsCAQJ"
      },
      "source": [
        "## 3D plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuQs8tuzCAQJ"
      },
      "outputs": [],
      "source": [
        "theta_0 = np.linspace(-20,30,100)\n",
        "theta_1 = np.linspace(1.3,2,100)\n",
        "J = np.zeros((len(theta_0),len(theta_1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a66cg3ugCAQJ"
      },
      "outputs": [],
      "source": [
        "for t0 in range(0,len(theta_0)):\n",
        "    for t1 in range(0,len(theta_1)):\n",
        "        J[t0,t1]= compute_J(data[:,1],data[:,2],theta_0[t0],theta_1[t1])\n",
        "\n",
        "x ,y = np.meshgrid(theta_0, theta_1)\n",
        "\n",
        "fig3D = plt.figure()\n",
        "fig3D.set_size_inches(20,15)\n",
        "axis3D = fig3D.add_subplot(111, projection='3d')\n",
        "axis3D.plot_surface(x, y, J, rstride=7, cstride=7,cmap=cm.coolwarm)\n",
        "#axis3D.scatter3D(20,1.5,35000,c='r', marker='o',s=100)\n",
        "axis3D.set_xlabel('theta0')\n",
        "axis3D.set_ylabel('theta1')\n",
        "axis3D.set_title('Kostenfunctie J');\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 6: 3D Kostenfunctie Plot**\n",
        "\n",
        "Deze cel maakt een 3D-plot van de kostenfunctie $J(\\theta_0, \\theta_1)$ voor een lineair regressiemodel, waarmee je kunt zien hoe de kosten veranderen naarmate de modelparameters variëren.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Definiëren van de parameterbereiken**\n",
        "\n",
        "```python\n",
        "theta_0 = np.linspace(-20, 30, 100)\n",
        "theta_1 = np.linspace(1.3, 2, 100)\n",
        "```\n",
        "\n",
        "* **theta\\_0**: Genereert 100 waarden tussen -20 en 30 voor de intercept.\n",
        "* **theta\\_1**: Genereert 100 waarden tussen 1.3 en 2 voor de helling.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Berekenen van de kostenfunctie voor elk $\\theta_0, \\theta_1$ paar**\n",
        "\n",
        "```python\n",
        "J = np.zeros((len(theta_0), len(theta_1)))\n",
        "\n",
        "for t0 in range(0, len(theta_0)):\n",
        "    for t1 in range(0, len(theta_1)):\n",
        "        J[t0, t1] = compute_J(data[:,1], data[:,2], theta_0[t0], theta_1[t1])\n",
        "```\n",
        "\n",
        "* **Initialisatie**:\n",
        "\n",
        "  * Creëert een 2D-array **J** van dezelfde grootte als de combinaties van **theta\\_0** en **theta\\_1** om de kosten op te slaan.\n",
        "* **Dubbele for-lus**:\n",
        "\n",
        "  * Berekent de kosten voor elk combinatiepaar van **theta\\_0** en **theta\\_1**.\n",
        "  * **compute\\_J** functie gebruikt de gewichten (kolom 1) en bloeddruk (kolom 2) uit de data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Creëren van een meshgrid voor 3D-plot**\n",
        "\n",
        "```python\n",
        "x, y = np.meshgrid(theta_0, theta_1)\n",
        "```\n",
        "\n",
        "* **np.meshgrid**:\n",
        "\n",
        "  * Zet de **theta\\_0** en **theta\\_1** waarden om in 2D arrays die de x- en y-waarden representeren voor de 3D-oppervlakteplot.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Plotten van het 3D-oppervlak**\n",
        "\n",
        "```python\n",
        "fig3D = plt.figure()\n",
        "fig3D.set_size_inches(20, 15)\n",
        "axis3D = fig3D.add_subplot(111, projection='3d')\n",
        "axis3D.plot_surface(x, y, J, rstride=7, cstride=7, cmap=cm.coolwarm)\n",
        "axis3D.set_xlabel('theta0')\n",
        "axis3D.set_ylabel('theta1')\n",
        "axis3D.set_title('Kostenfunctie J');\n",
        "```\n",
        "\n",
        "* **fig3D**:\n",
        "\n",
        "  * Creëert een nieuwe figure voor de 3D-plot.\n",
        "* **plot\\_surface**:\n",
        "\n",
        "  * Maakt een 3D-oppervlak met:\n",
        "\n",
        "    * **x**: Waarden voor **theta\\_0**.\n",
        "    * **y**: Waarden voor **theta\\_1**.\n",
        "    * **J**: Kostenwaarden voor elk combinatiepaar.\n",
        "  * **rstride** en **cstride** bepalen de resolutie van de gridlijnen.\n",
        "  * **cmap** gebruikt het kleurenschema **coolwarm** voor duidelijk contrast.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Optionele 3D-punten (uitgecommentarieerd)**\n",
        "\n",
        "```python\n",
        "# axis3D.scatter3D(20,1.5,35000,c='r', marker='o',s=100)\n",
        "```\n",
        "\n",
        "* **scatter3D** (uitgecommentarieerd) kan gebruikt worden om een specifiek punt te markeren, bijvoorbeeld een referentieoplossing of een lokaal minimum.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Labels en titels**\n",
        "\n",
        "```python\n",
        "axis3D.set_xlabel('theta0')\n",
        "axis3D.set_ylabel('theta1')\n",
        "axis3D.set_title('Kostenfunctie J');\n",
        "```\n",
        "\n",
        "* Labels voor de x- en y-assen, en een titel voor de grafiek.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultaat van deze cell:**\n",
        "\n",
        "* Het resultaat is een 3D-oppervlak dat de kostenfunctie $J(\\theta_0, \\theta_1)$ weergeeft.\n",
        "* Dit helpt om visueel te begrijpen hoe de keuze van $\\theta_0$ en $\\theta_1$ de fouten beïnvloedt.\n",
        "* Je kunt ook potentiële minima identificeren, waar de kosten minimaal zijn, wat het doel is van **gradient descent**.\n",
        "\n",
        "---\n",
        "\n",
        "Zal ik je helpen om de volgende cell met de **gradient descent** trajecten en optimalisatie uit te leggen? 😊\n"
      ],
      "metadata": {
        "id": "QKIYtRlyG9yZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3D Kostenfunctie:\n",
        "\n",
        "Visualiseert de kostenfunctie als een 3D-oppervlak."
      ],
      "metadata": {
        "id": "HYuU91K_F57j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "UqUnZpwLCAQJ"
      },
      "source": [
        "## Gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxuxUTTeCAQJ"
      },
      "outputs": [],
      "source": [
        "# Calculate gradients\n",
        "\n",
        "def gradient_J(x,y,theta0,theta1):\n",
        "    g0 = 0\n",
        "    g1 = 0\n",
        "    m = len(y)\n",
        "    for gcounter in range(0,m):\n",
        "        g0 = g0 + ((theta1*x[gcounter]+theta0)-y[gcounter])\n",
        "        g1 = g1 + ((theta1*x[gcounter]+theta0)-y[gcounter])*x[gcounter]\n",
        "    return g0,g1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7: Gradient Descent Implementatie en Visualisatie\n",
        "Gradient descent is een iteratief optimalisatie-algoritme dat wordt gebruikt om de parameters (\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        "  en\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        " ) te vinden die de kostenfunctie\n",
        "𝐽\n",
        "(\n",
        "𝜃\n",
        "0\n",
        ",\n",
        "𝜃\n",
        "1\n",
        ")\n",
        "J(θ\n",
        "0\n",
        "​\n",
        " ,θ\n",
        "1\n",
        "​\n",
        " ) minimaliseren.\n",
        "\n",
        "1. Functie om de gradiënten te berekenen\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "def gradient_J(x, y, theta0, theta1):\n",
        "    g0 = 0\n",
        "    g1 = 0\n",
        "    m = len(y)\n",
        "    for gcounter in range(0, m):\n",
        "        g0 += (theta1 * x[gcounter] + theta0) - y[gcounter]\n",
        "        g1 += ((theta1 * x[gcounter] + theta0) - y[gcounter]) * x[gcounter]\n",
        "    return g0, g1\n",
        "Doel: Berekening van de gradiënten van de kostenfunctie ten opzichte van\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        "  en\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        " .\n",
        "\n",
        "Uitleg:\n",
        "Gradiëntberekening:\n",
        "\n",
        "De gradiënt geeft de richting aan waarin de kosten het snelst toenemen.\n",
        "\n",
        "We willen bewegen in de tegengestelde richting van de gradiënt om de kosten te minimaliseren.\n",
        "\n",
        "Variabelen:\n",
        "\n",
        "g0: Afgeleide van de kostenfunctie naar\n",
        "𝜃\n",
        "0\n",
        "θ\n",
        "0\n",
        "​\n",
        " .\n",
        "\n",
        "g1: Afgeleide van de kostenfunctie naar\n",
        "𝜃\n",
        "1\n",
        "θ\n",
        "1\n",
        "​\n",
        " .\n",
        "\n",
        "m: Aantal datapunten.\n",
        "\n",
        "Gradiëntformules:\n",
        "𝑔\n",
        "0\n",
        "=\n",
        "1\n",
        "𝑚\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑚\n",
        "[\n",
        "(\n",
        "𝜃\n",
        "1\n",
        "⋅\n",
        "𝑥\n",
        "𝑖\n",
        "+\n",
        "𝜃\n",
        "0\n",
        ")\n",
        "−\n",
        "𝑦\n",
        "𝑖\n",
        "]\n",
        "g\n",
        "0\n",
        "​\n",
        " =\n",
        "m\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "m\n",
        "​\n",
        " [(θ\n",
        "1\n",
        "​\n",
        " ⋅x\n",
        "i\n",
        "​\n",
        " +θ\n",
        "0\n",
        "​\n",
        " )−y\n",
        "i\n",
        "​\n",
        " ]\n",
        "𝑔\n",
        "1\n",
        "=\n",
        "1\n",
        "𝑚\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑚\n",
        "[\n",
        "(\n",
        "(\n",
        "𝜃\n",
        "1\n",
        "⋅\n",
        "𝑥\n",
        "𝑖\n",
        "+\n",
        "𝜃\n",
        "0\n",
        ")\n",
        "−\n",
        "𝑦\n",
        "𝑖\n",
        ")\n",
        "⋅\n",
        "𝑥\n",
        "𝑖\n",
        "]\n",
        "g\n",
        "1\n",
        "​\n",
        " =\n",
        "m\n",
        "1\n",
        "​\n",
        "  \n",
        "i=1\n",
        "∑\n",
        "m\n",
        "​\n",
        " [((θ\n",
        "1\n",
        "​\n",
        " ⋅x\n",
        "i\n",
        "​\n",
        " +θ\n",
        "0\n",
        "​\n",
        " )−y\n",
        "i\n",
        "​\n",
        " )⋅x\n",
        "i\n",
        "​\n",
        " ]\n",
        "2. Initialisatie van Gradient Descent\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "theta0 = 0\n",
        "theta1 = 0\n",
        "mu = 0.00001\n",
        "iterations = 10\n",
        "\n",
        "xt = np.zeros((iterations))\n",
        "yt = np.zeros((iterations))\n",
        "zt = np.zeros((iterations))\n",
        "theta0 en theta1: Beginwaarden van de parameters.\n",
        "\n",
        "mu (leerfactor): Snelheid waarmee de parameters worden bijgewerkt (ook wel learning rate genoemd).\n",
        "\n",
        "iterations: Aantal stappen (iteraties) om te optimal"
      ],
      "metadata": {
        "id": "tjBbCNJhIauM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4zJcD0KCAQJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig_trajectory = plt.figure()\n",
        "fig_trajectory.set_size_inches(20,15)\n",
        "\n",
        "theta0 = 0\n",
        "theta1 = 0\n",
        "mu = 0.00001\n",
        "iterations =10\n",
        "\n",
        "xt = np.zeros((iterations))\n",
        "yt = np.zeros((iterations))\n",
        "zt = np.zeros((iterations))\n",
        "\n",
        "for s in range(0,iterations):\n",
        "\n",
        "    g0,g1 = gradient_J(data[:,1],data[:,2],theta0,theta1)\n",
        "    J = compute_J(data[:,1],data[:,2],theta0,theta1)\n",
        "    print('J = ',J,' theta0 = ',theta0,' theta1 = ',theta1)\n",
        "    theta0 = theta0 - mu*g0\n",
        "    theta1 = theta1 - mu*g1\n",
        "\n",
        "    xt[s] = theta0;\n",
        "    yt[s] = theta1;\n",
        "    zt[s] = J\n",
        "\n",
        "trajectory = fig_trajectory.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "\n",
        "trajectory.plot(xt,yt,'-ro')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deze code visualiseert de parameterupdate tijdens een **Gradient Descent** optimalisatie voor een lineaire regressieprobleem. Het volgt de verandering van de parameters $\\theta_0$ (intercept) en $\\theta_1$ (helling) tijdens meerdere iteraties van het algoritme. Hier is een stap-voor-stap uitleg:\n",
        "\n",
        "### 1. Setup van de Figuur\n",
        "\n",
        "```python\n",
        "fig_trajectory = plt.figure()\n",
        "fig_trajectory.set_size_inches(20,15)\n",
        "```\n",
        "\n",
        "* **`plt.figure()`**: Maakt een lege figuur aan waarin je grafieken kunt plotten.\n",
        "* **`set_size_inches(20,15)`**: Stelt de afmetingen van de figuur in (20 bij 15 inch), wat vrij groot is, waarschijnlijk om details van de trajecten duidelijk te maken.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Initialisatie van Parameters\n",
        "\n",
        "```python\n",
        "theta0 = 0\n",
        "theta1 = 0\n",
        "mu = 0.00001\n",
        "iterations = 10\n",
        "```\n",
        "\n",
        "* **`theta0` en `theta1`**: Beginwaarden voor de intercept en helling van de lineaire regressie.\n",
        "* **`mu`**: De learning rate, bepaalt hoe groot de stappen in de richting van de negatieve gradiënt zijn.\n",
        "* **`iterations`**: Het aantal iteraties van de gradient descent.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Arrays voor Traject Opname\n",
        "\n",
        "```python\n",
        "xt = np.zeros((iterations))\n",
        "yt = np.zeros((iterations))\n",
        "zt = np.zeros((iterations))\n",
        "```\n",
        "\n",
        "* **`xt`, `yt`, `zt`**: Lege arrays om de waardes van $\\theta_0$, $\\theta_1$ en de kostenfunctie $J$ tijdens elke iteratie op te slaan.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Gradient Descent Loop\n",
        "\n",
        "```python\n",
        "for s in range(0,iterations):\n",
        "    g0, g1 = gradient_J(data[:,1],data[:,2],theta0,theta1)\n",
        "    J = compute_J(data[:,1],data[:,2],theta0,theta1)\n",
        "    print('J = ',J,' theta0 = ',theta0,' theta1 = ',theta1)\n",
        "    theta0 = theta0 - mu*g0\n",
        "    theta1 = theta1 - mu*g1\n",
        "\n",
        "    xt[s] = theta0\n",
        "    yt[s] = theta1\n",
        "    zt[s] = J\n",
        "```\n",
        "\n",
        "* **`gradient_J`**: Berekent de partiële afgeleiden van de kostenfunctie $J$ met betrekking tot $\\theta_0$ en $\\theta_1$. Dit geeft de richting van de steilste stijging.\n",
        "* **`compute_J`**: Berekent de waarde van de kostenfunctie $J$ voor de huidige parameters.\n",
        "* **Parameterupdate**:\n",
        "\n",
        "  * **`theta0 = theta0 - mu * g0`**: Update voor $\\theta_0$.\n",
        "  * **`theta1 = theta1 - mu * g1`**: Update voor $\\theta_1$.\n",
        "* **Data Opslaan**:\n",
        "\n",
        "  * **`xt[s]`**: Slaat de nieuwe waarde van $\\theta_0$ op.\n",
        "  * **`yt[s]`**: Slaat de nieuwe waarde van $\\theta_1$ op.\n",
        "  * **`zt[s]`**: Slaat de huidige kostenfunctie $J$ op.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Visualisatie van het Traject\n",
        "\n",
        "```python\n",
        "trajectory = fig_trajectory.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "trajectory.plot(xt,yt,'-ro')\n",
        "```\n",
        "\n",
        "* **`add_axes`**: Voegt een assenstelsel toe aan de figuur.\n",
        "* **`plot(xt, yt, '-ro')`**:\n",
        "\n",
        "  * Plot de trajecten van $\\theta_0$ tegen $\\theta_1$ als rode lijnen met cirkelvormige markeringen ('ro').\n",
        "  * Dit laat zien hoe de parameters zich aanpassen tijdens de gradient descent.\n",
        "\n",
        "---\n",
        "\n",
        "### Wat Gebeurt Hier Eigenlijk?\n",
        "\n",
        "Het doel van deze code is om de **parametertrajecten** van een lineaire regressiemodel tijdens gradient descent te visualiseren. Dit helpt om te zien hoe de parameters stap voor stap dichter bij het optimale punt bewegen waar de kostenfunctie minimaal is.\n",
        "\n",
        "**Opmerkingen en mogelijke verbeteringen:**\n",
        "\n",
        "* Het aantal iteraties (10) is erg laag, wat betekent dat de beweging waarschijnlijk traag en onvolledig zal zijn.\n",
        "* De learning rate ($0.00001$) is vrij klein, wat de convergentie vertraagt.\n",
        "* Een 3D-plot zou hier nuttig kunnen zijn om ook $J$ te visualiseren (bijvoorbeeld een contour- of oppervlakdiagram).\n",
        "\n",
        "Zal ik je laten zien hoe je deze code kunt aanpassen voor een betere visualisatie met meer inzicht? 😊\n"
      ],
      "metadata": {
        "id": "75fhx_OwKwy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW9y3hFMCAQJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snoFsuNLCAQJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCSRhZIHCAQJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}