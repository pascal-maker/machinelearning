{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascal-maker/machinelearning/blob/main/Session_04_SVM_CV_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvFicl_vJQWI"
      },
      "source": [
        "# SVM & Cross-Validation\n",
        "\n",
        "In the realm of machine learning, Support Vector Machines (SVMs) stand out as a powerful tool for classification and regression tasks. With their ability to handle high-dimensional data and complex decision boundaries, SVMs have found extensive applications across various domains, including image recognition, text classification, and bioinformatics.\n",
        "\n",
        "Throughout this assignment, we aim to provide a comprehensive understanding of Support Vector Machines and their integration with cross-validation techniques, equipping you with the knowledge and skills necessary to apply these methods confidently in your own machine learning problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OuQj3Q7PJQWK"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "from scipy.stats import randint\n",
        "from scipy.stats import uniform\n",
        "from skimage.io import imread, imshow\n",
        "\n",
        "pd.set_option('display.max_rows',1000)\n",
        "pd.set_option('display.max_columns',1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn import svm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "FZra3xFOU_Dk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgVppKsiJQWK"
      },
      "source": [
        "## 1. Cancer detection\n",
        "\n",
        "\n",
        "Train a model to predict whether a specific tumor is benign or malignant. Use the dataset 'cancer.csv' for this purpose.\n",
        "\n",
        "Base your approach on methodologies from previous assignments to achieve the best possible results. Discuss the choices made and results obtained at each step, leading to a clear conclusion.\n",
        "\n",
        "Tip: A classifier can only be trained with numerical values. Therefore, replace the two classes present in the 'diagnosis' feature with 0 and 1, where 0 represents benign and 1 represents malignant.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "076m2Ae_JQWK",
        "outputId": "48a95afc-7889-4e52-a487-3556fadac54b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842517         M        20.57         17.77          132.90     1326.0   \n",
              "1  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "2  84348301         M        11.42         20.38           77.58      386.1   \n",
              "3  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "4    843786         M        12.45         15.70           82.57      477.1   \n",
              "5    844359         M        18.25         19.98          119.60     1040.0   \n",
              "6  84458202         M        13.71         20.83           90.20      577.9   \n",
              "7    844981         M        13.00         21.82           87.50      519.8   \n",
              "8  84501001         M        12.46         24.04           83.97      475.9   \n",
              "9    845636         M        16.02         23.24          102.70      797.8   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.08474           0.07864         0.08690              0.07017   \n",
              "1          0.10960           0.15990         0.19740              0.12790   \n",
              "2          0.14250           0.28390         0.24140              0.10520   \n",
              "3          0.10030           0.13280         0.19800              0.10430   \n",
              "4          0.12780           0.17000         0.15780              0.08089   \n",
              "5          0.09463           0.10900         0.11270              0.07400   \n",
              "6          0.11890           0.16450         0.09366              0.05985   \n",
              "7          0.12730           0.19320         0.18590              0.09353   \n",
              "8          0.11860           0.23960         0.22730              0.08543   \n",
              "9          0.08206           0.06669         0.03299              0.03323   \n",
              "\n",
              "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
              "0         0.1812                 0.05667     0.5435      0.7339         3.398   \n",
              "1         0.2069                 0.05999     0.7456      0.7869         4.585   \n",
              "2         0.2597                 0.09744     0.4956      1.1560         3.445   \n",
              "3         0.1809                 0.05883     0.7572      0.7813         5.438   \n",
              "4         0.2087                 0.07613     0.3345      0.8902         2.217   \n",
              "5         0.1794                 0.05742     0.4467      0.7732         3.180   \n",
              "6         0.2196                 0.07451     0.5835      1.3770         3.856   \n",
              "7         0.2350                 0.07389     0.3063      1.0020         2.406   \n",
              "8         0.2030                 0.08243     0.2976      1.5990         2.039   \n",
              "9         0.1528                 0.05697     0.3795      1.1870         2.466   \n",
              "\n",
              "   area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
              "0    74.08       0.005225        0.013080       0.01860           0.013400   \n",
              "1    94.03       0.006150        0.040060       0.03832           0.020580   \n",
              "2    27.23       0.009110        0.074580       0.05661           0.018670   \n",
              "3    94.44       0.011490        0.024610       0.05688           0.018850   \n",
              "4    27.19       0.007510        0.033450       0.03672           0.011370   \n",
              "5    53.91       0.004314        0.013820       0.02254           0.010390   \n",
              "6    50.96       0.008805        0.030290       0.02488           0.014480   \n",
              "7    24.32       0.005731        0.035020       0.03553           0.012260   \n",
              "8    23.94       0.007149        0.072170       0.07743           0.014320   \n",
              "9    40.51       0.004029        0.009269       0.01101           0.007591   \n",
              "\n",
              "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
              "0      0.01389              0.003532         24.99          23.41   \n",
              "1      0.02250              0.004571         23.57          25.53   \n",
              "2      0.05963              0.009208         14.91          26.50   \n",
              "3      0.01756              0.005115         22.54          16.67   \n",
              "4      0.02165              0.005082         15.47          23.75   \n",
              "5      0.01369              0.002179         22.88          27.66   \n",
              "6      0.01486              0.005412         17.06          28.14   \n",
              "7      0.02143              0.003749         15.49          30.73   \n",
              "8      0.01789              0.010080         15.09          40.68   \n",
              "9      0.01460              0.003042         19.19          33.88   \n",
              "\n",
              "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "0           158.80      1956.0            0.1238             0.1866   \n",
              "1           152.50      1709.0            0.1444             0.4245   \n",
              "2            98.87       567.7            0.2098             0.8663   \n",
              "3           152.20      1575.0            0.1374             0.2050   \n",
              "4           103.40       741.6            0.1791             0.5249   \n",
              "5           153.20      1606.0            0.1442             0.2576   \n",
              "6           110.60       897.0            0.1654             0.3682   \n",
              "7           106.20       739.3            0.1703             0.5401   \n",
              "8            97.65       711.4            0.1853             1.0580   \n",
              "9           123.80      1150.0            0.1181             0.1551   \n",
              "\n",
              "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0           0.2416               0.18600          0.2750   \n",
              "1           0.4504               0.24300          0.3613   \n",
              "2           0.6869               0.25750          0.6638   \n",
              "3           0.4000               0.16250          0.2364   \n",
              "4           0.5355               0.17410          0.3985   \n",
              "5           0.3784               0.19320          0.3063   \n",
              "6           0.2678               0.15560          0.3196   \n",
              "7           0.5390               0.20600          0.4378   \n",
              "8           1.1050               0.22100          0.4366   \n",
              "9           0.1459               0.09975          0.2948   \n",
              "\n",
              "   fractal_dimension_worst  \n",
              "0                  0.08902  \n",
              "1                  0.08758  \n",
              "2                  0.17300  \n",
              "3                  0.07678  \n",
              "4                  0.12440  \n",
              "5                  0.08368  \n",
              "6                  0.11510  \n",
              "7                  0.10720  \n",
              "8                  0.20750  \n",
              "9                  0.08452  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c13e95f-c9f2-4cbb-b02a-3e5aa72e986a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.040060</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.074580</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.024610</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>843786</td>\n",
              "      <td>M</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.033450</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.011370</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.17410</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>844359</td>\n",
              "      <td>M</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.013820</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.010390</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>84458202</td>\n",
              "      <td>M</td>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.014480</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.15560</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>844981</td>\n",
              "      <td>M</td>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.035020</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.012260</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>84501001</td>\n",
              "      <td>M</td>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.014320</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>845636</td>\n",
              "      <td>M</td>\n",
              "      <td>16.02</td>\n",
              "      <td>23.24</td>\n",
              "      <td>102.70</td>\n",
              "      <td>797.8</td>\n",
              "      <td>0.08206</td>\n",
              "      <td>0.06669</td>\n",
              "      <td>0.03299</td>\n",
              "      <td>0.03323</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.05697</td>\n",
              "      <td>0.3795</td>\n",
              "      <td>1.1870</td>\n",
              "      <td>2.466</td>\n",
              "      <td>40.51</td>\n",
              "      <td>0.004029</td>\n",
              "      <td>0.009269</td>\n",
              "      <td>0.01101</td>\n",
              "      <td>0.007591</td>\n",
              "      <td>0.01460</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>19.19</td>\n",
              "      <td>33.88</td>\n",
              "      <td>123.80</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.1551</td>\n",
              "      <td>0.1459</td>\n",
              "      <td>0.09975</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>0.08452</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c13e95f-c9f2-4cbb-b02a-3e5aa72e986a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c13e95f-c9f2-4cbb-b02a-3e5aa72e986a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c13e95f-c9f2-4cbb-b02a-3e5aa72e986a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0fc59116-3668-47ec-a0ac-2e76be3d24ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fc59116-3668-47ec-a0ac-2e76be3d24ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0fc59116-3668-47ec-a0ac-2e76be3d24ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Reading the dataset\n",
        "\n",
        "dataset = pd.read_csv('cancer.csv')\n",
        "dataset.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "h8qVkoZ1JQWL",
        "outputId": "6bd5c215-df56-47a1-88e6-6f53163979a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='diagnosis', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Check whether or not the dataset is imbalanced\n",
        "sns.countplot(x='diagnosis',data=dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Visualize the distribution of the target classes (benign and malignant).\n",
        "\n",
        "Important because class imbalance can significantly impact model performance."
      ],
      "metadata": {
        "id": "JXRpfMqk-PyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop('id',axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "N50OtdhWMUut"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yes -> 1 and no -> 0\n",
        "\n",
        "dataset.diagnosis.replace({'B':0,'M':1},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRGCV5OOMnNi",
        "outputId": "7a4e1125-d40c-40ef-81f9-f534bc37d845"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b39a50d46acb>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  dataset.diagnosis.replace({'B':0,'M':1},inplace=True)\n",
            "<ipython-input-7-b39a50d46acb>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset.diagnosis.replace({'B':0,'M':1},inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iWDsKEI1JQWL"
      },
      "outputs": [],
      "source": [
        "# Drop the ID column\n",
        "\n",
        "\n",
        "# Replace B by 0 and M by 1 in the diagnosis column\n",
        "\n",
        "\n",
        "\n",
        "# Split into features and targets\n",
        "\n",
        "X = dataset.drop('diagnosis',axis=1)\n",
        "y = dataset['diagnosis']\n",
        "\n",
        "\n",
        "\n",
        "# Split into training set and test set. Make sure that 150 samples end up in the test set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=150, random_state=0)\n",
        "\n",
        "\n",
        "# To avoid a conversion warning during scaling:\n",
        "\n",
        "X_train = X_train.astype('float64')\n",
        "X_test = X_test.astype('float64')\n",
        "\n",
        "# Scaling\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Standardize the feature values to have zero mean and unit variance.\n",
        "\n",
        "This helps many machine learning algorithms (like SVM and Logistic Regression) perform better.\n",
        "\n",
        "Purpose:\n",
        "\n",
        "Create training and test sets.\n",
        "\n",
        "Test set size is fixed at 150 to ensure consistent evaluation."
      ],
      "metadata": {
        "id": "hCesC7Xv--Cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Separate the feature matrix (X) and target vector (y), which is required for model training."
      ],
      "metadata": {
        "id": "o2scuvra-t30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Remove the ID column, which is not relevant for prediction.\n",
        "\n",
        "Convert the diagnosis column into numerical labels for binary classification"
      ],
      "metadata": {
        "id": "FX6FSeIV-mVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "model = LogisticRegression(max_iter=1)\n",
        "\n",
        "paramaters = [\n",
        "    {\n",
        "        'C': np.linspace(0.001, 100, 7),\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'solver': ['liblinear', 'saga']\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='accuracy',\n",
        "    cv=20,\n",
        "    n_jobs=-1,\n",
        "    verbose=5\n",
        ")\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best accuracy:', best_accuracy)\n",
        "print('Best parameters:', best_parameters)\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7YyrvFQqzD1",
        "outputId": "db0603ec-01c8-4568-f386-7acb1c53a1e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 20 folds for each of 28 candidates, totalling 560 fits\n",
            "Best accuracy: 0.9736904761904761\n",
            "Best parameters: {'C': np.float64(66.667), 'penalty': 'l1', 'solver': 'saga'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        99\n",
            "           1       0.94      0.90      0.92        51\n",
            "\n",
            "    accuracy                           0.95       150\n",
            "   macro avg       0.94      0.94      0.94       150\n",
            "weighted avg       0.95      0.95      0.95       150\n",
            "\n",
            "[[96  3]\n",
            " [ 5 46]]\n",
            "94.66666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Use GridSearchCV to find the optimal hyperparameters for Logistic Regression.\n",
        "\n",
        "Evaluates multiple combinations of C, penalty, and solver.\n",
        "\n",
        "Uses 20-fold cross-validation for a robust estimate of model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "L3_ww9S-_Lkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Logistic Regression Hyperparameter Tuning with GridSearchCV**\n",
        "\n",
        "This code uses **GridSearchCV** to **automatically** find the **best** hyperparameters for a **Logistic Regression** model. This is a very powerful technique because it **saves** you the trouble of **manually** trying out different parameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Create the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1)\n",
        "```\n",
        "\n",
        "* **LogisticRegression()**:\n",
        "\n",
        "  * Creates a **logistic regression** model.\n",
        "* **max\\_iter=1**:\n",
        "\n",
        "  * Sets the **maximum** number of iterations to **1**.\n",
        "  * This is very **low**, so the model might not converge (usually **100** or **1000** is better).\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Define the Hyperparameter Grid**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "paramaters = [\n",
        "    {\n",
        "        'C': np.linspace(0.001, 100, 7),  # Regularization strength\n",
        "        'penalty': ['l1', 'l2'],  # Type of regularization\n",
        "        'solver': ['liblinear', 'saga']  # Optimization algorithms\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "* **C**:\n",
        "\n",
        "  * Controls the **strength** of the regularization.\n",
        "  * **Lower** values make the model **more** strict (less likely to overfit).\n",
        "* **penalty**:\n",
        "\n",
        "  * **l1**: Lasso regularization (encourages **sparse** models).\n",
        "  * **l2**: Ridge regularization (reduces large coefficients).\n",
        "* **solver**:\n",
        "\n",
        "  * **liblinear**: Works with **l1** and **l2**.\n",
        "  * **saga**: Works with **l1**, **l2**, and **elastic net** (faster for large datasets).\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Set Up GridSearchCV**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='accuracy',  # Optimize for accuracy\n",
        "    cv=20,  # 20-fold cross-validation\n",
        "    n_jobs=-1,  # Use all CPU cores\n",
        "    verbose=5  # Print detailed output\n",
        ")\n",
        "```\n",
        "\n",
        "* **GridSearchCV**:\n",
        "\n",
        "  * Tests **all** possible combinations of hyperparameters.\n",
        "* **scoring='accuracy'**:\n",
        "\n",
        "  * Tries to **maximize** the accuracy.\n",
        "* **cv=20**:\n",
        "\n",
        "  * Uses **20-fold cross-validation** for **more reliable** results.\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Uses **all** available CPU cores to **speed up** the process.\n",
        "* **verbose=5**:\n",
        "\n",
        "  * Shows you **detailed** progress information.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Train the Model**\n",
        "\n",
        "```python\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* This **trains** the model using **all** the hyperparameter combinations.\n",
        "* This can take **a long time** if you have a **large** dataset.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Find the Best Parameters**\n",
        "\n",
        "```python\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best accuracy:', best_accuracy)\n",
        "print('Best parameters:', best_parameters)\n",
        "```\n",
        "\n",
        "* **grid\\_search.best\\_score\\_**:\n",
        "\n",
        "  * The **highest** accuracy found during the search.\n",
        "* **grid\\_search.best\\_params\\_**:\n",
        "\n",
        "  * The **best** combination of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Make Predictions with the Best Model**\n",
        "\n",
        "```python\n",
        "y_pred = grid_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Makes **predictions** on the **test data** using the **best** model.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Evaluate the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows **precision**, **recall**, **f1-score**, and **support** for each class.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows the **number** of correct and incorrect predictions.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Gives the **overall** accuracy as a **percentage**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best accuracy: 0.95\n",
        "Best parameters: {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "95.0\n",
        "```\n",
        "\n",
        "* **95%** accuracy means the model is very **accurate**.\n",
        "* The **confusion matrix** shows you where the model made **mistakes**.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PdNcoQ1OKn-6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ewYUP6NJQWL"
      },
      "source": [
        "Train a logistic regression model via cross-validation.\n",
        "\n",
        "Utilize grid search and random search to find the best hyperparameters: C value, class_weight, penalty (l1 or l2). More information: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html.\n",
        "\n",
        "Vary the value of K in K-fold cross-validation. Discuss the results.\n",
        "Test the obtained models on the test set. Which search technique do you prefer and why?\n",
        "\n",
        "Does it make sense to expand the feature set with polynomial features? Test this. Polynomial Features: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSlmQRrQJQWL",
        "outputId": "5dec8753-7517-475e-e2f8-0822bf5f4aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best SVM Parameters: {'C': np.float64(3959.854970880213), 'gamma': np.float64(0.004914632653341754), 'kernel': 'poly'}\n",
            "Best SVM Accuracy: 0.9569133677567413\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best Logistic Regression Parameters: {'C': np.float64(452.1001730167441), 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best Logistic Regression Accuracy: 0.9712851405622491\n",
            "\n",
            "Best Model Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        99\n",
            "           1       0.94      0.90      0.92        51\n",
            "\n",
            "    accuracy                           0.95       150\n",
            "   macro avg       0.94      0.94      0.94       150\n",
            "weighted avg       0.95      0.95      0.95       150\n",
            "\n",
            "Confusion Matrix:\n",
            " [[96  3]\n",
            " [ 5 46]]\n",
            "Test Accuracy: 94.66666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# SVM Random Search\n",
        "svm_model = SVC()\n",
        "svm_params = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': uniform(0.001, 10000),\n",
        "    'gamma': uniform(0.001, 0.2)\n",
        "}\n",
        "\n",
        "svm_search = RandomizedSearchCV(\n",
        "    estimator=svm_model,\n",
        "    param_distributions=svm_params,\n",
        "    cv=5,\n",
        "    n_iter=50,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "svm_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best SVM Parameters:\", svm_search.best_params_)\n",
        "print(\"Best SVM Accuracy:\", svm_search.best_score_)\n",
        "\n",
        "# Logistic Regression Random Search\n",
        "logreg_model = LogisticRegression(max_iter=1, tol=1e-2)\n",
        "logreg_params = {\n",
        "    'C': uniform(0.01, 1000),\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "logreg_search = RandomizedSearchCV(\n",
        "    estimator=logreg_model,\n",
        "    param_distributions=logreg_params,\n",
        "    cv=5,\n",
        "    n_iter=50,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "logreg_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Logistic Regression Parameters:\", logreg_search.best_params_)\n",
        "print(\"Best Logistic Regression Accuracy:\", logreg_search.best_score_)\n",
        "\n",
        "# Test set performance for the best model\n",
        "best_model = svm_search if svm_search.best_score_ > logreg_search.best_score_ else logreg_search\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"\\nBest Model Test Set Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Perform a RandomizedSearchCV for SVM with a broader hyperparameter space.\n",
        "\n",
        "Faster than GridSearchCV for high-dimensional hyperparameter spaces.\n",
        "\n"
      ],
      "metadata": {
        "id": "TgzUW_Xb_Rip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Hyperparameter Tuning with RandomizedSearchCV**\n",
        "\n",
        "This code **automatically** finds the **best** hyperparameters for both **SVM** and **Logistic Regression** using **RandomizedSearchCV**. It then **compares** the two models and picks the **best** one based on their **accuracy**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Import the Required Libraries**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import uniform\n",
        "```\n",
        "\n",
        "* **RandomizedSearchCV**: Finds the **best** hyperparameters using **random** sampling.\n",
        "* **SVC**: Support Vector Machine for classification.\n",
        "* **LogisticRegression**: Logistic regression for binary classification.\n",
        "* **uniform**: Generates random numbers for the hyperparameter search.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. SVM Hyperparameter Search**\n",
        "\n",
        "**Step 1: Create the SVM Model**\n",
        "\n",
        "```python\n",
        "svm_model = SVC()\n",
        "```\n",
        "\n",
        "* Creates a **Support Vector Machine** model.\n",
        "* This model needs to be **trained**.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 2: Define the Hyperparameter Grid**\n",
        "\n",
        "```python\n",
        "svm_params = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': uniform(0.001, 10000),\n",
        "    'gamma': uniform(0.001, 0.2)\n",
        "}\n",
        "```\n",
        "\n",
        "* **kernel**:\n",
        "\n",
        "  * **linear**: Straight line decision boundary.\n",
        "  * **rbf** (Radial Basis Function): More flexible, curved decision boundary.\n",
        "  * **poly** (Polynomial): Curved decision boundary with polynomial features.\n",
        "* **C**:\n",
        "\n",
        "  * Controls how **strict** the model is about avoiding **errors**.\n",
        "  * **Smaller** values = **stricter**.\n",
        "* **gamma**:\n",
        "\n",
        "  * Controls how **far** each data point influences the decision boundary.\n",
        "  * **Smaller** values = **smoother** boundary.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 3: Set Up RandomizedSearchCV**\n",
        "\n",
        "```python\n",
        "svm_search = RandomizedSearchCV(\n",
        "    estimator=svm_model,\n",
        "    param_distributions=svm_params,\n",
        "    cv=5,\n",
        "    n_iter=50,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "```\n",
        "\n",
        "* **cv=5**:\n",
        "\n",
        "  * Use **5-fold cross-validation** for more reliable results.\n",
        "* **n\\_iter=50**:\n",
        "\n",
        "  * Test **50** random combinations of hyperparameters.\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Use **all** available CPU cores for faster training.\n",
        "* **verbose=1**:\n",
        "\n",
        "  * Print detailed progress information.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 4: Train the SVM Model**\n",
        "\n",
        "```python\n",
        "svm_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Trains the SVM model using **50** random hyperparameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 5: Print the Best SVM Hyperparameters and Accuracy**\n",
        "\n",
        "```python\n",
        "print(\"Best SVM Parameters:\", svm_search.best_params_)\n",
        "print(\"Best SVM Accuracy:\", svm_search.best_score_)\n",
        "```\n",
        "\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** hyperparameter combination.\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** accuracy achieved during training.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Logistic Regression Hyperparameter Search**\n",
        "\n",
        "**Step 1: Create the Logistic Regression Model**\n",
        "\n",
        "```python\n",
        "logreg_model = LogisticRegression(max_iter=1, tol=1e-2)\n",
        "```\n",
        "\n",
        "* Creates a **Logistic Regression** model.\n",
        "* **max\\_iter=1**:\n",
        "\n",
        "  * Limits the training to **1** iteration (**very low**, usually use **100** or **1000**).\n",
        "* **tol=1e-2**:\n",
        "\n",
        "  * Sets the **tolerance** for convergence (how precise the solution needs to be).\n",
        "\n",
        "---\n",
        "\n",
        "**Step 2: Define the Hyperparameter Grid**\n",
        "\n",
        "```python\n",
        "logreg_params = {\n",
        "    'C': uniform(0.01, 1000),\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "```\n",
        "\n",
        "* **C**:\n",
        "\n",
        "  * Controls the **strength** of regularization (how strict the model is about avoiding errors).\n",
        "* **solver**:\n",
        "\n",
        "  * **liblinear**: Good for small datasets.\n",
        "  * **saga**: Faster for large datasets.\n",
        "* **penalty**:\n",
        "\n",
        "  * **l1**: Lasso regularization (encourages **simpler** models).\n",
        "  * **l2**: Ridge regularization (reduces large coefficients).\n",
        "\n",
        "---\n",
        "\n",
        "**Step 3: Set Up RandomizedSearchCV**\n",
        "\n",
        "```python\n",
        "logreg_search = RandomizedSearchCV(\n",
        "    estimator=logreg_model,\n",
        "    param_distributions=logreg_params,\n",
        "    cv=5,\n",
        "    n_iter=50,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "```\n",
        "\n",
        "* Same settings as the SVM search, but with **different** hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 4: Train the Logistic Regression Model**\n",
        "\n",
        "```python\n",
        "logreg_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Trains the **Logistic Regression** model using **50** random hyperparameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 5: Print the Best Logistic Regression Hyperparameters and Accuracy**\n",
        "\n",
        "```python\n",
        "print(\"Best Logistic Regression Parameters:\", logreg_search.best_params_)\n",
        "print(\"Best Logistic Regression Accuracy:\", logreg_search.best_score_)\n",
        "```\n",
        "\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** hyperparameter combination for Logistic Regression.\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** accuracy achieved during training.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Test Set Performance for the Best Model**\n",
        "\n",
        "**Step 1: Choose the Best Model**\n",
        "\n",
        "```python\n",
        "best_model = svm_search if svm_search.best_score_ > logreg_search.best_score_ else logreg_search\n",
        "```\n",
        "\n",
        "* Compares the **best** accuracy scores of SVM and Logistic Regression.\n",
        "* Chooses the model with the **highest** accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 2: Make Predictions on the Test Set**\n",
        "\n",
        "```python\n",
        "y_pred = best_model.predict(X_test)\n",
        "```\n",
        "\n",
        "* Makes **predictions** on the **test** data using the **best** model.\n",
        "\n",
        "---\n",
        "\n",
        "**Step 3: Print the Final Results**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(\"\\nBest Model Test Set Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows precision, recall, f1-score, and support.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows the number of correct and incorrect predictions.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Prints the overall accuracy as a percentage.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best SVM Parameters: {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
        "Best SVM Accuracy: 0.95\n",
        "\n",
        "Best Model Test Set Performance:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "Confusion Matrix:\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "Test Accuracy: 95.0\n",
        "```\n",
        "\n",
        "* The best model was **SVM** with **95%** accuracy.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9FtUj7P1LWdl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPqy9kOyJQWL"
      },
      "source": [
        "Re-train the grid search again but select the model that yields the highest balanced accuracy.\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score\n",
        "Also check http://mvpa.blogspot.com/2015/12/balanced-accuracy-what-and-why.html\n",
        "\n",
        "Discuss the result and compare it with the best accuracy score achieved earlier."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from scipy.stats import uniform\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# SVM Model\n",
        "model = SVC()\n",
        "\n",
        "# Hyperparameter Space\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': uniform(0.001, 10000),\n",
        "    'gamma': uniform(0.001, 0.2)\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV with Balanced Accuracy\n",
        "n_iter_search = 10\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=parameters,\n",
        "    cv=5,\n",
        "    n_iter=n_iter_search,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    scoring='balanced_accuracy'\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_balanced_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best balanced accuracy:', best_balanced_accuracy)\n",
        "print('Best parameters:', best_parameters)\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOJzDlTJuz42",
        "outputId": "b7f4abdc-b5a4-432b-860d-285233fcc9be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Best balanced accuracy: 0.9479260935143288\n",
            "Best parameters: {'C': np.float64(1316.6999090939119), 'gamma': np.float64(0.04565586125652772), 'kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97        99\n",
            "           1       0.98      0.90      0.94        51\n",
            "\n",
            "    accuracy                           0.96       150\n",
            "   macro avg       0.97      0.95      0.95       150\n",
            "weighted avg       0.96      0.96      0.96       150\n",
            "\n",
            "[[98  1]\n",
            " [ 5 46]]\n",
            "Test Accuracy: 96.0\n",
            "Balanced Accuracy Score: 0.9459298871063577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Select the model with the best cross-validated score (either SVM or Logistic Regression).\n",
        "\n",
        "Evaluate it on the test set to measure real-world performance"
      ],
      "metadata": {
        "id": "ox918Tte_YoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: SVM Hyperparameter Tuning with Balanced Accuracy**\n",
        "\n",
        "This code uses **RandomizedSearchCV** to **automatically** find the **best** hyperparameters for an **SVM** (**Support Vector Machine**) model, while optimizing for **balanced accuracy**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Create the SVM Model**\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "```\n",
        "\n",
        "* **SVC()**:\n",
        "\n",
        "  * Creates a **Support Vector Machine** model.\n",
        "* This model needs to be **trained** with **data**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Define the Hyperparameter Space**\n",
        "\n",
        "```python\n",
        "from scipy.stats import uniform\n",
        "\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': uniform(0.001, 10000),  # Random values from 0.001 to 10000\n",
        "    'gamma': uniform(0.001, 0.2)  # Random values from 0.001 to 0.2\n",
        "}\n",
        "```\n",
        "\n",
        "* **kernel**:\n",
        "\n",
        "  * **linear**: Straight line decision boundary.\n",
        "  * **rbf** (Radial Basis Function): Curved decision boundary, very flexible.\n",
        "  * **poly** (Polynomial): More complex, curved decision boundary.\n",
        "* **C**:\n",
        "\n",
        "  * Controls how **strict** the model is about avoiding **errors**.\n",
        "  * **Smaller** values = **stricter**.\n",
        "* **gamma**:\n",
        "\n",
        "  * Controls how **far** each data point influences the decision boundary.\n",
        "  * **Smaller** values = **smoother** boundary.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Set Up RandomizedSearchCV**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_iter_search = 10  # Test 10 random combinations\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=parameters,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    n_iter=n_iter_search,  # Test 10 random combinations\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    verbose=1,  # Print progress information\n",
        "    scoring='balanced_accuracy'  # Optimize for balanced accuracy\n",
        ")\n",
        "```\n",
        "\n",
        "* **cv=5**:\n",
        "\n",
        "  * Uses **5-fold cross-validation** for **more reliable** results.\n",
        "* **n\\_iter=10**:\n",
        "\n",
        "  * Tests **10** random hyperparameter combinations.\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Uses **all** available CPU cores for **faster** training.\n",
        "* **verbose=1**:\n",
        "\n",
        "  * Shows you what is happening in the background.\n",
        "* **scoring='balanced\\_accuracy'**:\n",
        "\n",
        "  * Optimizes for **balanced accuracy**, which is better for **imbalanced** datasets.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Train the Model**\n",
        "\n",
        "```python\n",
        "random_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Trains the SVM model using **10** random hyperparameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Print the Best Hyperparameters and Accuracy**\n",
        "\n",
        "```python\n",
        "best_balanced_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best balanced accuracy:', best_balanced_accuracy)\n",
        "print('Best parameters:', best_parameters)\n",
        "```\n",
        "\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** balanced accuracy found during training.\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** combination of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Make Predictions on the Test Set**\n",
        "\n",
        "```python\n",
        "y_pred = random_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Uses the **best** model found during the search to make **predictions** on the **test** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Evaluate the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows you precision, recall, f1-score, and support.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows you how many correct and incorrect predictions were made.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Prints the **overall** accuracy as a percentage.\n",
        "* **balanced\\_accuracy\\_score**:\n",
        "\n",
        "  * Gives a **better** measure for **imbalanced** datasets.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best balanced accuracy: 0.93\n",
        "Best parameters: {'C': 500, 'gamma': 0.05, 'kernel': 'rbf'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "Test Accuracy: 95.0\n",
        "Balanced Accuracy Score: 0.95\n",
        "```\n",
        "\n",
        "* This means the model found a configuration with **93%** balanced accuracy on the training set and **95%** on the test set.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Why This is Important**\n",
        "\n",
        "* **Balanced Accuracy**:\n",
        "\n",
        "  * Better for **imbalanced** datasets where one class is much larger than the other.\n",
        "* **Faster Tuning**:\n",
        "\n",
        "  * **RandomizedSearchCV** is faster than **GridSearchCV** because it **samples** random points instead of testing **all** combinations.\n",
        "* **Flexible**:\n",
        "\n",
        "  * Works for multiple types of SVM models (**linear**, **rbf**, **poly**).\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8e5pqeg7Lp6s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvEMD-CtJQWM"
      },
      "source": [
        "Search for the model that yields the highest F1-score. To do this, you should utilize the F1 micro score.\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2aSearNJQWM"
      },
      "outputs": [],
      "source": [
        "# Cross-validation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation via grid search\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=1, tol=1e-2,class_weight='balanced')  # balanced\n",
        "paramaters = [\n",
        "                {'C' : np.arange(0.001,1000,100), 'solver':['liblinear','saga']}\n",
        "\n",
        "             ]\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator = model,\n",
        "                           param_grid = paramaters,\n",
        "                           scoring = 'f1_micro',\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_f1 = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best f1 : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_  )\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cohld7D0vKyy",
        "outputId": "ff649ddb-0eca-44c7-da34-cd83f7bc04b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best f1 :  0.9713124274099882\n",
            "Best parameters : {'C': np.float64(100.001), 'solver': 'liblinear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        99\n",
            "           1       0.96      0.88      0.92        51\n",
            "\n",
            "    accuracy                           0.95       150\n",
            "   macro avg       0.95      0.93      0.94       150\n",
            "weighted avg       0.95      0.95      0.95       150\n",
            "\n",
            "[[97  2]\n",
            " [ 6 45]]\n",
            "94.66666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Cross-Validation with GridSearchCV for Logistic Regression**\n",
        "\n",
        "This code uses **GridSearchCV** to **automatically** find the **best** hyperparameters for a **Logistic Regression** model. It focuses on **f1-micro** as the scoring metric, which is good for **imbalanced** datasets.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Create the Logistic Regression Model**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1, tol=1e-2, class_weight='balanced')\n",
        "```\n",
        "\n",
        "* **LogisticRegression()**:\n",
        "\n",
        "  * Creates a **logistic regression** model.\n",
        "* **max\\_iter=1**:\n",
        "\n",
        "  * Limits the training to **1** iteration (**very low**, usually **100** or **1000** is better).\n",
        "* **tol=1e-2**:\n",
        "\n",
        "  * Sets the **tolerance** for convergence (how precise the solution needs to be).\n",
        "* **class\\_weight='balanced'**:\n",
        "\n",
        "  * Gives **more** weight to the **minority** class if the data is **imbalanced**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Define the Hyperparameter Grid**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "paramaters = [\n",
        "    {\n",
        "        'C': np.arange(0.001, 1000, 100),  # Regularization strength\n",
        "        'solver': ['liblinear', 'saga']  # Optimization algorithms\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "* **C**:\n",
        "\n",
        "  * Controls the **strength** of the regularization.\n",
        "  * **Smaller** values make the model **more** strict (less likely to overfit).\n",
        "* **solver**:\n",
        "\n",
        "  * **liblinear**: Good for small datasets.\n",
        "  * **saga**: Faster for large datasets, supports **l1** and **l2** penalties.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Set Up GridSearchCV**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='f1_micro',  # Optimize for f1-micro score\n",
        "    cv=10,  # 10-fold cross-validation\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    verbose=1  # Print progress information\n",
        ")\n",
        "```\n",
        "\n",
        "* **scoring='f1\\_micro'**:\n",
        "\n",
        "  * Focuses on the **f1-micro** score, which is good for **imbalanced** datasets.\n",
        "* **cv=10**:\n",
        "\n",
        "  * Uses **10-fold cross-validation** for **more reliable** results.\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Uses **all** available CPU cores for **faster** training.\n",
        "* **verbose=1**:\n",
        "\n",
        "  * Shows you what is happening in the background.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Train the Model**\n",
        "\n",
        "```python\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Trains the logistic regression model using **all** possible hyperparameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Print the Best Hyperparameters and F1 Score**\n",
        "\n",
        "```python\n",
        "best_f1 = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best f1 : ', best_f1)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** f1-micro score found during training.\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** combination of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Make Predictions on the Test Set**\n",
        "\n",
        "```python\n",
        "y_pred = grid_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Uses the **best** model found during the search to make **predictions** on the **test** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Evaluate the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows you precision, recall, f1-score, and support.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows you how many correct and incorrect predictions were made.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Prints the **overall** accuracy as a percentage.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best f1 : 0.92\n",
        "Best parameters : {'C': 100, 'solver': 'liblinear'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "Test Accuracy: 95.0\n",
        "```\n",
        "\n",
        "* The best **f1-micro** score was **0.92** with **C=100** and **liblinear** as the solver.\n",
        "* The model has **95%** test accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Why This is Important**\n",
        "\n",
        "* **Automatic Tuning**:\n",
        "\n",
        "  * Saves you from manually trying different hyperparameter combinations.\n",
        "* **Balanced Training**:\n",
        "\n",
        "  * Accounts for **imbalanced** data with **class\\_weight='balanced'**.\n",
        "* **Cross-Validation**:\n",
        "\n",
        "  * Provides **more reliable** results.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HcvPcKMXMCTR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHjHDPyru_Uw"
      },
      "source": [
        "Search for the model that yields the highest F1-score. To do this, you should utilize the F1 micro score.\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S7843poJQWM"
      },
      "source": [
        "Since the dataset is slightly imbalanced, most trained models tend to have a 'preference' for the majority class. Investigate whether you can increase the F1-score (or recall) by applying the following techniques:\n",
        "\n",
        "Passing the parameter class_weight='balanced' to the models.\n",
        "Performing oversampling using SMOTE. More information: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html. You may need to install the imbalanced-learn library using pip3 install imbalanced-learn or in Anaconda: **conda install conda-forge::imbalanced-learn**\n",
        "\n",
        "\n",
        "Discuss the results you have achieved, paying particular attention to the F1 micro score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling with SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "print(y_resampled.shape)\n",
        "\n",
        "model = LogisticRegression(max_iter=1, tol=1e-2)\n",
        "paramaters = [\n",
        "                {'C' : np.arange(0.001,1000,100), 'solver':['liblinear','saga']}\n",
        "\n",
        "             ]\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator = model,\n",
        "                           param_grid = paramaters,\n",
        "                           scoring = 'f1_micro',\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "grid_search = grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "best_f1 = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best f1 : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_  )\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VynjQ6ku-Hs",
        "outputId": "8aefa2f6-19a3-440e-d049-d5a31f8d6089"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(516,)\n",
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
            "Best f1 :  0.9650452488687783\n",
            "Best parameters : {'C': np.float64(100.001), 'solver': 'liblinear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        99\n",
            "           1       0.96      0.88      0.92        51\n",
            "\n",
            "    accuracy                           0.95       150\n",
            "   macro avg       0.95      0.93      0.94       150\n",
            "weighted avg       0.95      0.95      0.95       150\n",
            "\n",
            "[[97  2]\n",
            " [ 6 45]]\n",
            "94.66666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Oversampling with SMOTE and Hyperparameter Tuning**\n",
        "\n",
        "This code uses **SMOTE** to handle **imbalanced** data before training a **Logistic Regression** model. It then uses **GridSearchCV** to **automatically** find the **best** hyperparameters for the model.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. What is SMOTE?**\n",
        "\n",
        "* **SMOTE (Synthetic Minority Over-sampling Technique)**:\n",
        "\n",
        "  * **Creates** new samples of the **minority** class to **balance** your dataset.\n",
        "  * Helps **avoid** bias in your model.\n",
        "  * Makes it easier for the model to **learn** the minority class.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Oversample the Training Data with SMOTE**\n",
        "\n",
        "```python\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "print(y_resampled.shape)\n",
        "```\n",
        "\n",
        "* **SMOTE()**:\n",
        "\n",
        "  * Creates **synthetic** samples for the **minority** class.\n",
        "* **fit\\_resample()**:\n",
        "\n",
        "  * **Resamples** the training data to make it **balanced**.\n",
        "* **print(y\\_resampled.shape)**:\n",
        "\n",
        "  * Shows you the **new** shape of the balanced training data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Create the Logistic Regression Model**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1, tol=1e-2)\n",
        "```\n",
        "\n",
        "* **LogisticRegression()**:\n",
        "\n",
        "  * Creates a **logistic regression** model.\n",
        "* **max\\_iter=1**:\n",
        "\n",
        "  * Limits the training to **1** iteration (**very low**, usually **100** or **1000** is better).\n",
        "* **tol=1e-2**:\n",
        "\n",
        "  * Sets the **tolerance** for convergence (how precise the solution needs to be).\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Define the Hyperparameter Grid**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "paramaters = [\n",
        "    {\n",
        "        'C': np.arange(0.001, 1000, 100),  # Regularization strength\n",
        "        'solver': ['liblinear', 'saga']  # Optimization algorithms\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "* **C**:\n",
        "\n",
        "  * Controls the **strength** of the regularization.\n",
        "  * **Smaller** values make the model **more** strict (less likely to overfit).\n",
        "* **solver**:\n",
        "\n",
        "  * **liblinear**: Good for small datasets.\n",
        "  * **saga**: Faster for large datasets, supports **l1** and **l2** penalties.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Set Up GridSearchCV**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='f1_micro',  # Optimize for f1-micro score\n",
        "    cv=10,  # 10-fold cross-validation\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    verbose=1  # Print progress information\n",
        ")\n",
        "```\n",
        "\n",
        "* **scoring='f1\\_micro'**:\n",
        "\n",
        "  * Focuses on the **f1-micro** score, which is good for **imbalanced** datasets.\n",
        "* **cv=10**:\n",
        "\n",
        "  * Uses **10-fold cross-validation** for **more reliable** results.\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Uses **all** available CPU cores for **faster** training.\n",
        "* **verbose=1**:\n",
        "\n",
        "  * Shows you what is happening in the background.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Train the Model**\n",
        "\n",
        "```python\n",
        "grid_search = grid_search.fit(X_resampled, y_resampled)\n",
        "```\n",
        "\n",
        "* Trains the logistic regression model using **all** possible hyperparameter combinations.\n",
        "* **Uses the balanced data** created by **SMOTE**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Print the Best Hyperparameters and F1 Score**\n",
        "\n",
        "```python\n",
        "best_f1 = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best f1 : ', best_f1)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** f1-micro score found during training.\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** combination of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Make Predictions on the Test Set**\n",
        "\n",
        "```python\n",
        "y_pred = grid_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Uses the **best** model found during the search to make **predictions** on the **test** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Evaluate the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows you precision, recall, f1-score, and support.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows you how many correct and incorrect predictions were made.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Prints the **overall** accuracy as a percentage.\n",
        "\n",
        "---\n",
        "\n",
        "#### **10. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best f1 : 0.92\n",
        "Best parameters : {'C': 100, 'solver': 'liblinear'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "Test Accuracy: 95.0\n",
        "```\n",
        "\n",
        "* The best **f1-micro** score was **0.92** with **C=100** and **liblinear** as the solver.\n",
        "* The model has **95%** test accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "#### **11. Why This is Important**\n",
        "\n",
        "* **SMOTE**:\n",
        "\n",
        "  * Helps balance your data so the model is **less biased**.\n",
        "* **Automatic Tuning**:\n",
        "\n",
        "  * Saves you from manually trying different hyperparameter combinations.\n",
        "* **Cross-Validation**:\n",
        "\n",
        "  * Provides **more reliable** results.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZUzFoqHlMcZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tAfY2LpvVrF",
        "outputId": "789416cb-ffa7-4ea6-9956-79ef7ba577d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwrnKaswJQWM"
      },
      "outputs": [],
      "source": [
        "# Balancing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f-eDtFeJQWM",
        "outputId": "7140928d-9533-42be-f9ec-20cb7f761349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(516,)\n"
          ]
        }
      ],
      "source": [
        "# Oversampling with SMOTE\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "X_resampled, y_resampled = SMOTE( ).fit_resample(X_train, y_train)\n",
        "\n",
        "print(y_resampled.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Oversampling with SMOTE**\n",
        "\n",
        "#### **1. What is SMOTE?**\n",
        "\n",
        "* **SMOTE (Synthetic Minority Over-sampling Technique)**:\n",
        "\n",
        "  * Creates **new** samples for the **minority** class in your training data.\n",
        "  * This helps **balance** the data so that the model is **less** biased towards the **majority** class.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Why Use SMOTE?**\n",
        "\n",
        "* If you have an **imbalanced** dataset (e.g., **90%** class **0** and **10%** class **1**), the model might **ignore** the minority class.\n",
        "* **SMOTE** helps by **generating** realistic, synthetic samples of the **minority** class, making your model **fairer**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. The Code:**\n",
        "\n",
        "```python\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "\n",
        "print(y_resampled.shape)\n",
        "```\n",
        "\n",
        "* **from imblearn.over\\_sampling import SMOTE**:\n",
        "\n",
        "  * Imports the **SMOTE** function from the **imbalanced-learn** library.\n",
        "\n",
        "* **SMOTE()**:\n",
        "\n",
        "  * Creates a **SMOTE** object.\n",
        "\n",
        "* **fit\\_resample(X\\_train, y\\_train)**:\n",
        "\n",
        "  * **Fits** the SMOTE object to your **training** data.\n",
        "  * **Generates** new samples for the **minority** class.\n",
        "\n",
        "* **X\\_resampled, y\\_resampled**:\n",
        "\n",
        "  * **X\\_resampled**: The **features** of the **balanced** training set.\n",
        "  * **y\\_resampled**: The **labels** of the **balanced** training set.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Print the New Shape**\n",
        "\n",
        "```python\n",
        "print(y_resampled.shape)\n",
        "```\n",
        "\n",
        "* Prints the **shape** of the **balanced** training set.\n",
        "* You should now have **more** samples than you started with.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Example Output (Before and After)**\n",
        "\n",
        "**Before SMOTE:**\n",
        "\n",
        "* **Original Training Set**:\n",
        "\n",
        "  * **X\\_train shape**: (500, 20)\n",
        "  * **y\\_train shape**: (500,)\n",
        "\n",
        "**After SMOTE:**\n",
        "\n",
        "* **Balanced Training Set**:\n",
        "\n",
        "  * **X\\_resampled shape**: (900, 20)\n",
        "  * **y\\_resampled shape**: (900,)\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Why This is Important**\n",
        "\n",
        "* **Fairer Models**:\n",
        "\n",
        "  * Balances your training data so your model learns **better**.\n",
        "* **Higher Accuracy**:\n",
        "\n",
        "  * Helps improve **precision**, **recall**, and **f1-score** for the minority class.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iCk2smW7Mp-g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i91fH_QvJQWM"
      },
      "source": [
        "Suppose there is a demand to reduce the number of false negatives to 0. A false negative means that the diagnosis is benign while the tumor is actually malignant.\n",
        "\n",
        "\n",
        "Your options are to apply classweight balancing or threshold moving.\n",
        "\n",
        "\n",
        "Threshold moving, in the context of binary classification models like logistic regression or support vector machines, refers to adjusting the threshold value used to make predictions.\n",
        "\n",
        "By default, these models classify instances into one of two classes based on whether the predicted probability (output of the model) exceeds a certain threshold. For instance, if the threshold is set to 0.5, any instance with a predicted probability greater than 0.5 is classified as positive, while instances with predicted probabilities less than or equal to 0.5 are classified as negative.\n",
        "\n",
        "Threshold moving involves changing this threshold value to optimize specific metrics like accuracy, precision, recall, or F1-score. For example, if reducing false negatives is critical (e.g., in medical diagnosis where missing a positive case could be harmful), one might lower the threshold to ensure more instances are classified as positive, thus potentially reducing false negatives.\n",
        "\n",
        "\n",
        "\n",
        "Which threshold should be set to ensure that the model predicts no false negatives on the test set while still maintaining the highest possible accuracy? Plot the number of false negatives as a function of the threshold. Discuss the results."
      ]
    },
    {
      "source": [
        "# Reducing the number of false negatives\n",
        "y_pred_prob = grid_search.predict_proba(X_test)\n",
        "\n",
        "y_pred_class = y_pred_prob[:,1]\n",
        "\n",
        "false_negatives = []\n",
        "accuracy = []\n",
        "for threshold in np.linspace(0,1,100):\n",
        "    y_pred_class = y_pred_prob[:,1].copy()\n",
        "    #print(y_pred_poly_class)\n",
        "    y_pred_class[y_pred_class>=threshold]=1\n",
        "    y_pred_class[y_pred_class<threshold]=0\n",
        "    #print(y_pred_poly_class)\n",
        "    false_negatives.append(confusion_matrix(y_test,y_pred_class)[1,0])\n",
        "    accuracy.append(accuracy_score(y_test,y_pred_class)*100)\n",
        "false_negatives = np.asarray(false_negatives)\n",
        "#plt.bar(np.linspace(0,1,50),false_negatives)\n",
        "plt.figure(figsize=(15,5))\n",
        "chart = sns.barplot(x=np.round(np.linspace(0,1,100),2),y=false_negatives)\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=90,fontsize=7)\n",
        "chart.set_title('number of false negatives as a function of the threshold')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "chart = sns.barplot(x=np.round(np.linspace(0,1,100),2),y=accuracy)\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=90,fontsize=7)\n",
        "chart.set_title('accuracy as a function of the threshold')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "xEoJQLC4wLWR",
        "outputId": "a4614957-2432-41db-bc5c-16362f3457aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-eb26f7ec5e96>:20: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  chart.set_xticklabels(chart.get_xticklabels(), rotation=90,fontsize=7)\n",
            "<ipython-input-16-eb26f7ec5e96>:26: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  chart.set_xticklabels(chart.get_xticklabels(), rotation=90,fontsize=7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'accuracy as a function of the threshold')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABMIAAAHKCAYAAADhHOdqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUWFJREFUeJzt3Xd0VNX6//FPaAlSQk8INQISmkhT6aC5IoqXKmD50bxiQZDu5SpIEy6CgkizoijYwIrKFVHUC0hVEFHkCkgN1RBqIOT5/eHKfBlmQnLCTDLhvF9rzVrkzJ5nnjN79pmZh33ODjMzEwAAAAAAAHCFy5PTCQAAAAAAAADZgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAMAlTJ48WVdffbXy5s2r6667LqfT8Wv58uUKCwvT8uXLczqVS3rjjTcUFxen/Pnzq1ixYo4fv3PnToWFhWnKlCmBTy6TevXqpcKFC+fY818sGPlUrlxZvXr1yrDda6+9prCwMO3cuTOgzw8AQDBRCAMAAEjHF198oeHDh6tp06aaO3euJkyYkKP5zJo1S6+99lqO5pBVv/76q3r16qUqVaropZde0osvvphu288++0yjR4/OvuQucurUKY0ePTrkC4sAAMC5fDmdAAAAQKj66quvlCdPHr3yyisqUKBATqejWbNmqVSpUj6zdVq0aKHTp0+HRI7pWb58uVJTU/Xcc8+patWql2z72WefaebMmTlWDDt16pTGjBkjSWrVqlWO5AAAAIKDGWEAALjIyZMnczqFXOXgwYMqWLBgSBeYJClPnjyKiIhQnjyh+9Xu4MGDkpSlUyKvFCkpKTp79mxOpwEAgKuF7rclAABygT/++EMPP/ywqlevroIFC6pkyZK68847/V4zJzExUYMGDVLlypUVHh6u8uXLq0ePHjp8+LCnzZkzZzR69Ghdc801ioiIUNmyZdWpUyf9/vvvktK/FlTatZMuPG0u7dpBv//+u2677TYVKVJE99xzjyTpu+++05133qmKFSsqPDxcFSpU0KBBg3T69GmfvH/99Vd17dpVpUuXVsGCBVW9enU9/vjjkqSvv/5aYWFh+uCDD3wet2DBAoWFhWnVqlXpvn5Hjx7V0KFDVadOHRUuXFhFixZV27ZttXHjRp+2zz//vGrVqqWrrrpKxYsXV8OGDbVgwYJ0Y0vS2bNnNWrUKDVo0ECRkZEqVKiQmjdvrq+//vqSj5OksLAwzZ07VydPnlRYWJjn9fX3Wl/4mAtnMY0ePVphYWH63//+p169eqlYsWKKjIxU7969derUKZ/Hv/nmm7r++us9+9iiRQt98cUXkv66btPPP/+sb775xpNP2myl9N4X7733nho0aKCCBQuqVKlSuvfee7V3716vNmnvk71796pDhw4qXLiwSpcuraFDh+r8+fMZvk7SXzPVatWqpfDwcMXExKhfv35KTEz03F+5cmU9+eSTkqTSpUv7vE4X5zNz5kzP65l2u9iLL76oKlWqKDw8XI0aNdLatWt92vz666/q0qWLSpQooYiICDVs2FAff/zxJfdl586dKl26tCRpzJgxnue/ON+MXq8Lr2c2bdo0T65btmzJdG7nzp3TmDFjVK1aNUVERKhkyZJq1qyZli5d6pN3Zvrv5MmTGjJkiCpUqKDw8HBVr15dU6ZMkZld8jWRpJ9//lk33XSTChYsqPLly2v8+PFKTU3N8HEAAIQaTo0EAOAyrF27VitXrlT37t1Vvnx57dy5U7Nnz1arVq20ZcsWXXXVVZKkEydOqHnz5vrll1/Up08f1a9fX4cPH9bHH3+sPXv2qFSpUjp//rzatWunZcuWqXv37nr00Ud1/PhxLV26VJs3b1aVKlUc55eSkqI2bdqoWbNmmjJliief9957T6dOndJDDz2kkiVLas2aNXr++ee1Z88evffee57Hb9q0Sc2bN1f+/PnVt29fVa5cWb///rs++eQTPfXUU2rVqpUqVKig+fPnq2PHjl7PPX/+fFWpUkWNGzdON7/t27frww8/1J133qnY2FgdOHBAL7zwglq2bKktW7YoJiZGkvTSSy9pwIAB6tKlix599FGdOXNGmzZt0urVq3X33XenGz8pKUkvv/yy7rrrLt1///06fvy4XnnlFbVp00Zr1qy55MXv33jjDb344otas2aNXn75ZUlSkyZNMnzN/enatatiY2M1ceJEbdiwQS+//LLKlCmjSZMmedqMGTNGo0ePVpMmTTR27FgVKFBAq1ev1ldffaVbbrlF06ZNU//+/VW4cGFPITIqKird53zttdfUu3dvNWrUSBMnTtSBAwf03HPPacWKFfrhhx+8ZmadP39ebdq00Q033KApU6boyy+/1DPPPKMqVarooYceuuS+jR49WmPGjFF8fLweeughbd26VbNnz9batWu1YsUK5c+fX9OmTdO8efP0wQcfaPbs2SpcuLCuvfZav/EeeOAB7du3T0uXLtUbb7zht82CBQt0/PhxPfDAAwoLC9PTTz+tTp06afv27cqfP7+kvwo3TZs2Vbly5fTPf/5ThQoV0rvvvqsOHTpo0aJFPu/XNKVLl9bs2bP10EMPqWPHjurUqZMkeeXr5PWaO3euzpw5o759+yo8PFwlSpTIdG6jR4/WxIkT9Y9//EPXX3+9kpKStG7dOm3YsEF/+9vfHOVjZvr73/+ur7/+Wvfdd5+uu+46/ec//9GwYcO0d+9eTZ06Nd0+TkhIUOvWrZWSkuLJ98UXX1TBggXTfQwAACHLAABAlp06dcpn26pVq0ySzZs3z7Nt1KhRJsnef/99n/apqalmZvbqq6+aJHv22WfTbfP111+bJPv666+97t+xY4dJsrlz53q29ezZ0yTZP//5z0zlPXHiRAsLC7M//vjDs61FixZWpEgRr20X5mNmNmLECAsPD7fExETPtoMHD1q+fPnsySef9HmeC505c8bOnz/vsy/h4eE2duxYz7b27dtbrVq1LhnLn5SUFEtOTvba9ueff1pUVJT16dMnw8f37NnTChUq5JPfxa91Gkle+/zkk0+aJJ/n6tixo5UsWdLz97Zt2yxPnjzWsWNHn9fjwte6Vq1a1rJlS5/nvfh9cfbsWStTpozVrl3bTp8+7Wm3ePFik2SjRo3y2kdJXq+3mVm9evWsQYMGPs91oYMHD1qBAgXslltu8cp7xowZJsleffVVn9fi0KFDl4xpZtavXz/z9zU17bUvWbKkHT161LP9o48+Mkn2ySefeLbdfPPNVqdOHTtz5oxnW2pqqjVp0sSqVat2yec/dOiQT1+myezrlZZr0aJF7eDBg15tM5tb3bp17fbbb79krpnN58MPPzRJNn78eK92Xbp0sbCwMPvf//7n2VapUiXr2bOn5++BAweaJFu9erVn28GDBy0yMtIk2Y4dOy6ZIwAAoYRTIwEAuAwXzog4d+6cjhw5oqpVq6pYsWLasGGD575Fixapbt26fmehpJ32tWjRIpUqVUr9+/dPt01W+JvRc2HeJ0+e1OHDh9WkSROZmX744QdJ0qFDh/Ttt9+qT58+qlixYrr59OjRQ8nJyVq4cKFn2zvvvKOUlBTde++9l8wtPDzcc12r8+fP68iRIypcuLCqV6/u9foVK1ZMe/bs8Xv626XkzZvXc32v1NRUHT16VCkpKWrYsKFX/GB78MEHvf5u3ry5jhw5oqSkJEnShx9+qNTUVI0aNcrnOl9Z6ft169bp4MGDevjhhxUREeHZfvvttysuLk6ffvpppnLcvn37JZ/nyy+/1NmzZzVw4ECvvO+//34VLVrU7/MEQrdu3VS8eHGvXCV58j169Ki++uorde3aVcePH9fhw4d1+PBhHTlyRG3atNG2bdt8ThF1KrOvV+fOnT2nWjrNrVixYvr555+1bdu2y87ns88+U968eTVgwACvdkOGDJGZ6fPPP0839meffaYbb7xR119/vWdb6dKlPadaAwCQm1AIAwDgMpw+fVqjRo3yXHOnVKlSKl26tBITE3Xs2DFPu99//121a9e+ZKzff/9d1atXV758gbtyQb58+VS+fHmf7bt27VKvXr1UokQJzzWFWrZsKUmevNN+RGeUd1xcnBo1aqT58+d7ts2fP1833nhjhqsDpqamaurUqapWrZrX67dp0yav1++xxx5T4cKFdf3116tatWrq16+fVqxYkanX4PXXX9e1117rucZS6dKl9emnn3rFD7aLC4lpRZw///xT0l99nydPHtWsWTMgz/fHH39IkqpXr+5zX1xcnOf+NBEREV7FmrQc0/Jz+jwFChTQ1Vdf7fM8gZLR6/m///1PZqaRI0eqdOnSXre0a5WlXbw/K5y8XrGxsV5/O8lt7NixSkxM1DXXXKM6depo2LBh2rRpU5by+eOPPxQTE6MiRYp4tatRo4bn/vT88ccfqlatms92f+8vAABCHdcIAwDgMvTv319z587VwIED1bhxY0VGRiosLEzdu3cPyoWk05sdlN5FzS+ccXVh27/97W86evSoHnvsMcXFxalQoULau3evevXqlaW8e/TooUcffVR79uxRcnKyvv/+e82YMSPDx02YMEEjR45Unz59NG7cOJUoUUJ58uTRwIEDvfKoUaOGtm7dqsWLF2vJkiVatGiRZs2apVGjRmnMmDHpxn/zzTfVq1cvdejQQcOGDVOZMmWUN29eTZw40bMAgVNO+0D6a2aaP5aJi5Rnh/TyC1UZvZ5p752hQ4eqTZs2fttmVKTNyvP7c/F1tJzk1qJFC/3+++/66KOP9MUXX+jll1/W1KlTNWfOHP3jH//IUj4AALgdhTAAAC7DwoUL1bNnTz3zzDOebWfOnPFaMU+SqlSpos2bN18yVpUqVbR69WqdO3fOc8Hvi6XNfLk4vpOZNz/99JN+++03vf766+rRo4dn+8Ur0V199dWSlGHektS9e3cNHjxYb731lk6fPq38+fOrW7duGT5u4cKFat26tV555RWv7YmJiSpVqpTXtkKFCqlbt27q1q2bzp49q06dOumpp57SiBEjvE7/uzj+1Vdfrffff9+rgJU28yYrAtEHF6tSpYpSU1O1ZcuWS17AP7OnSVaqVEmStHXrVt10001e923dutVz/+W68HnS3i/SX6t17tixQ/Hx8VmKezmnAkv/997Nnz9/lnK43Oe/FKe5lShRQr1791bv3r114sQJtWjRQqNHj/YqhGVGpUqV9OWXX+r48eNes8J+/fVXz/2Xeqy/0zO3bt3qKAcAAEIBp0YCAHAZ8ubN6zOr5/nnn/eZHdS5c2dt3LhRH3zwgU+MtMd37txZhw8f9juTKq1NpUqVlDdvXn377bde98+aNctRzhfGTPv3c88959WudOnSatGihV599VXt2rXLbz5pSpUqpbZt2+rNN9/U/Pnzdeutt/oUstLL5eJY7733ns/1m44cOeL1d4ECBVSzZk2Zmc6dO3fJ+Bfnu3r1aq1atSrD3NJTtGhRlSpV6rL64GIdOnRQnjx5NHbsWJ8ZeRfmXqhQIZ8CnD8NGzZUmTJlNGfOHCUnJ3u2f/755/rll190++23ZznXC8XHx6tAgQKaPn26V56vvPKKjh07luXnKVSokCTfYmNmlSlTRq1atdILL7yg/fv3+9x/6NChSz4+bXXVrD5/oHK7+H1fuHBhVa1a1atPM+u2227T+fPnfY4vU6dOVVhYmNq2bXvJx37//fdas2aNV54Xng4NAEBuwYwwAAAuQ7t27fTGG28oMjJSNWvW1KpVq/Tll1+qZMmSXu2GDRumhQsX6s4771SfPn3UoEEDHT16VB9//LHmzJmjunXrqkePHpo3b54GDx6sNWvWqHnz5jp58qS+/PJLPfzww2rfvr0iIyN155136vnnn1dYWJiqVKmixYsXO7reUVxcnKpUqaKhQ4dq7969Klq0qBYtWuT3+kbTp09Xs2bNVL9+ffXt21exsbHauXOnPv30U/34449ebXv06KEuXbpIksaNG5fp12/s2LHq3bu3mjRpop9++knz58/3ml0kSbfccouio6PVtGlTRUVF6ZdfftGMGTN0++23+1zz6OL477//vjp27Kjbb79dO3bs0Jw5c1SzZk2dOHEiUzn6849//EP//ve/9Y9//EMNGzbUt99+q99++y3L8apWrarHH39c48aNU/PmzdWpUyeFh4dr7dq1iomJ0cSJEyVJDRo00OzZszV+/HhVrVpVZcqU8ZnxJf0122jSpEnq3bu3WrZsqbvuuksHDhzQc889p8qVK2vQoEFZzvVCpUuX1ogRIzRmzBjdeuut+vvf/66tW7dq1qxZatSoUYaLJaSnQYMGkqQBAwaoTZs2yps3r7p37+4oxsyZM9WsWTPVqVNH999/v66++modOHBAq1at0p49e7Rx48Z0H1uwYEHVrFlT77zzjq655hqVKFFCtWvXzvB6eYHOrWbNmmrVqpUaNGigEiVKaN26dVq4cKEeeeQRx895xx13qHXr1nr88ce1c+dO1a1bV1988YU++ugjDRw4UFWqVEn3scOHD9cbb7yhW2+9VY8++qgKFSqkF198UZUqVfJ7zTIAAEJatq9TCQDAFeTPP/+03r17W6lSpaxw4cLWpk0b+/XXX61SpUrWs2dPr7ZHjhyxRx55xMqVK2cFChSw8uXLW8+ePe3w4cOeNqdOnbLHH3/cYmNjLX/+/BYdHW1dunSx33//3dPm0KFD1rlzZ7vqqqusePHi9sADD9jmzZtNks2dO9fTrmfPnlaoUCG/eW/ZssXi4+OtcOHCVqpUKbv//vtt48aNPjHMzDZv3mwdO3a0YsWKWUREhFWvXt1GjhzpEzM5OdmKFy9ukZGRdvr06Uy9fmfOnLEhQ4ZY2bJlrWDBgta0aVNbtWqVtWzZ0lq2bOlp98ILL1iLFi2sZMmSFh4eblWqVLFhw4bZsWPHLhk/NTXVJkyYYJUqVbLw8HCrV6+eLV682Hr27GmVKlXKML/0XsNTp07ZfffdZ5GRkVakSBHr2rWrHTx40CTZk08+6Wn35JNPmiQ7dOiQ1+Pnzp1rkmzHjh1e21999VWrV6+ehYeHW/Hixa1ly5a2dOlSz/0JCQl2++23W5EiRUyS5zX6+uuvTZJ9/fXXXvHeeecdT7wSJUrYPffcY3v27MnUPqblnhkzZsywuLg4y58/v0VFRdlDDz1kf/75p994F78W/qSkpFj//v2tdOnSFhYW5sljx44dJskmT57s85iLX3szs99//9169Ohh0dHRlj9/fitXrpy1a9fOFi5cmGEOK1eutAYNGliBAgW8Ymf29bpUrpnNbfz48Xb99ddbsWLFrGDBghYXF2dPPfWUnT171tPGSf8dP37cBg0aZDExMZY/f36rVq2aTZ482VJTU73a+Tt+bdq0yVq2bGkRERFWrlw5GzdunL3yyit+38cAAISyMLMQuUorAADI1VJSUhQTE6M77rjD55pfAAAAQCjgGmEAACAgPvzwQx06dMjrAvwAAABAKGFGGAAAuCyrV6/Wpk2bNG7cOJUqVUobNmzI6ZQAAAAAv5gRBgAALsvs2bP10EMPqUyZMpo3b15OpwMAAACkixlhAAAAAAAAcAVmhAEAAAAAAMAVKIQBAAAAAADAFfI5fcC3336ryZMna/369dq/f78++OADdejQwXO/menJJ5/USy+9pMTERDVt2lSzZ89WtWrVPG2OHj2q/v3765NPPlGePHnUuXNnPffccypcuHCmckhNTdW+fftUpEgRhYWFOd0FAAAAAAAAXEHMTMePH1dMTIzy5El/3pfjQtjJkydVt25d9enTR506dfK5/+mnn9b06dP1+uuvKzY2ViNHjlSbNm20ZcsWRURESJLuuece7d+/X0uXLtW5c+fUu3dv9e3bVwsWLMhUDvv27VOFChWcpg4AAAAAAIAr2O7du1W+fPl077+si+WHhYV5zQgzM8XExGjIkCEaOnSoJOnYsWOKiorSa6+9pu7du+uXX35RzZo1tXbtWjVs2FCStGTJEt12223as2ePYmJiMnzeY8eOqVixYtq9e7eKFi2a1fQBAAAAAABwBUhKSlKFChWUmJioyMjIdNs5nhF2KTt27FBCQoLi4+M92yIjI3XDDTdo1apV6t69u1atWqVixYp5imCSFB8frzx58mj16tXq2LGjT9zk5GQlJyd7/j5+/LgkqWjRohTCAAAAAAAAIEkZXkIroBfLT0hIkCRFRUV5bY+KivLcl5CQoDJlynjdny9fPpUoUcLT5mITJ05UZGSk58ZpkQAAAAAAAHAqV6waOWLECB07dsxz2717d06nBAAAAAAAgFwmoIWw6OhoSdKBAwe8th84cMBzX3R0tA4ePOh1f0pKio4ePeppc7Hw8HDPaZCcDgkAAAAAAICsCGghLDY2VtHR0Vq2bJlnW1JSklavXq3GjRtLkho3bqzExEStX7/e0+arr75SamqqbrjhhkCmAwAAAAAAAHg4vlj+iRMn9L///c/z944dO/Tjjz+qRIkSqlixogYOHKjx48erWrVqio2N1ciRIxUTE+NZWbJGjRq69dZbdf/992vOnDk6d+6cHnnkEXXv3j1TK0YCAAAAAAAAWeG4ELZu3Tq1bt3a8/fgwYMlST179tRrr72m4cOH6+TJk+rbt68SExPVrFkzLVmyRBEREZ7HzJ8/X4888ohuvvlm5cmTR507d9b06dMDsDsAAAAAAACAf2FmZjmdhFNJSUmKjIzUsWPHuF4YAAAAAACAy2W2VpQrVo0EAAAAAAAALheFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALhCvpxOAAAAIFQ0GDYvwzbrJ/fIUvvMtL04PgAAAAKLGWEAAAAAAABwBQphAAAAAAAAcAVOjQQAADmK0xH9c/q6AAAAIGPMCAMAAAAAAIArMCMMAAAAOYaZbwAAIDsxIwwAAAAAAACuQCEMAAAAAAAArsCpkQAAAFeAQC8iEKqnIwZzsYScXrghuxaFCKVcAADIbswIAwAAAAAAgCswIwwAAARcbp5xBF/MCEKwcKwAAGQ3ZoQBAAAAAADAFSiEAQAAAAAAwBUohAEAAAAAAMAVKIQBAAAAAADAFbhYPgAAyBAXtAYQCjgWAQAuFzPCAAAAAAAA4AoUwgAAAAAAAOAKnBoJAIALZeb0IolTjADkXpxGCQDwhxlhAAAAAAAAcAVmhAEAcIVg9gMAAABwacwIAwAAAAAAgCtQCAMAAAAAAIArcGokAACXwcnpiE4vUM+pjgAAAEBgMSMMAAAAAAAArsCMMAAAAACuF8wZvgCA0MGMMAAAAAAAALgChTAAAAAAAAC4AqdGAgCueIE+3YVTXQAATjj9bGEhFgAIHmaEAQAAAAAAwBUohAEAAAAAAMAVODUSAAAAAOAXp1ICuNIwIwwAAAAAAACuwIwwAAAAAMBlY/YYgNyAGWEAAAAAAABwBQphAAAAAAAAcAVOjQQA5DqcegEAQO7n5PM8M20vbA8A6WFGGAAAAAAAAFyBGWEAgBzH//ICAAAAyA7MCAMAAAAAAIArUAgDAAAAAACAK3BqJAAAAADgiuJ0YZ1gXrifRX6A0MKMMAAAAAAAALgCM8IAAAAAAAgRgZ6dxmwzwBszwgAAAAAAAOAKFMIAAAAAAADgCpwaCQAICqbqAwAAAAg1zAgDAAAAAACAKzAjDAAAAAAAF2DGPsCMMAAAAAAAALgEhTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALhCvpxOAACQOzQYNi/DNusn98iGTAAAABBsmfnuJ/3f9z++KyK3CPiMsPPnz2vkyJGKjY1VwYIFVaVKFY0bN05m5mljZho1apTKli2rggULKj4+Xtu2bQt0KgAAAAAAAIBHwAthkyZN0uzZszVjxgz98ssvmjRpkp5++mk9//zznjZPP/20pk+frjlz5mj16tUqVKiQ2rRpozNnzgQ6HQAAAAAAAEBSEE6NXLlypdq3b6/bb79dklS5cmW99dZbWrNmjaS/ZoNNmzZNTzzxhNq3by9JmjdvnqKiovThhx+qe/fugU4JAOCH0+nuAAAAQKBwKiVySsBnhDVp0kTLli3Tb7/9JknauHGj/vvf/6pt27aSpB07dighIUHx8fGex0RGRuqGG27QqlWr/MZMTk5WUlKS1w0AAAAAAABwIuAzwv75z38qKSlJcXFxyps3r86fP6+nnnpK99xzjyQpISFBkhQVFeX1uKioKM99F5s4caLGjBkT6FQBAAAAAADgIgGfEfbuu+9q/vz5WrBggTZs2KDXX39dU6ZM0euvv57lmCNGjNCxY8c8t927dwcwYwAAAAAAALhBwGeEDRs2TP/85z891/qqU6eO/vjjD02cOFE9e/ZUdHS0JOnAgQMqW7as53EHDhzQdddd5zdmeHi4wsPDA50qAAAAAAAAXCTgM8JOnTqlPHm8w+bNm1epqamSpNjYWEVHR2vZsmWe+5OSkrR69Wo1btw40OkAAAAAAAAAkoIwI+yOO+7QU089pYoVK6pWrVr64Ycf9Oyzz6pPnz6SpLCwMA0cOFDjx49XtWrVFBsbq5EjRyomJkYdOnQIdDoAAAAAAACApCAUwp5//nmNHDlSDz/8sA4ePKiYmBg98MADGjVqlKfN8OHDdfLkSfXt21eJiYlq1qyZlixZooiIiECnAwCuwjLUAAAAuNJk5juuxPdcZE7AC2FFihTRtGnTNG3atHTbhIWFaezYsRo7dmygnx4AAAAAAADwK+DXCAMAAAAAAABCEYUwAAAAAAAAuAKFMAAAAAAAALhCwK8RBgAAAAAAkFOcLiDFglPuwowwAAAAAAAAuAKFMAAAAAAAALgCp0YCQAhjmjYAAAAABA4zwgAAAAAAAOAKzAgDAAAAAADIBM7YyP2YEQYAAAAAAABXoBAGAAAAAAAAV+DUSADIZkynBgAAAICcwYwwAAAAAAAAuAIzwgDgMjHDCwAAAAByB2aEAQAAAAAAwBUohAEAAAAAAMAVODUSAAAAAAAgCLiMSuhhRhgAAAAAAABcgUIYAAAAAAAAXIFTIwEAAAAAAHJYZk6jlP7vVEpOu8waZoQBAAAAAADAFSiEAQAAAAAAwBUohAEAAAAAAMAVKIQBAAAAAADAFbhYPgBcxOlFKgEAAAAAuQMzwgAAAAAAAOAKzAgDAAAAAAC4wmXmzBc3nPXCjDAAAAAAAAC4AoUwAAAAAAAAuAKnRgJwBaYBAwAAAEDmOF1ALDf93mJGGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXCFfTicAAFmRm5bnBQAAAACEBmaEAQAAAAAAwBUohAEAAAAAAMAVKIQBAAAAAADAFSiEAQAAAAAAwBW4WD6AkJCZi99LXAAfAAAAAHK7nFz8jBlhAAAAAAAAcAUKYQAAAAAAAHAFCmEAAAAAAABwBQphAAAAAAAAcAUKYQAAAAAAAHAFVo0EAAAAAABASAr0CpPMCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK+TL6QQAXLkaDJuXYZv1k3tkQyYAAAAAADAjDAAAAAAAAC5BIQwAAAAAAACuwKmRADKNUx0BAAAAALkZM8IAAAAAAADgChTCAAAAAAAA4AoUwgAAAAAAAOAKQSmE7d27V/fee69KliypggULqk6dOlq3bp3nfjPTqFGjVLZsWRUsWFDx8fHatm1bMFIBAAAAAAAAJAXhYvl//vmnmjZtqtatW+vzzz9X6dKltW3bNhUvXtzT5umnn9b06dP1+uuvKzY2ViNHjlSbNm20ZcsWRUREBDolAJfABfABAAAAAG4R8ELYpEmTVKFCBc2dO9ezLTY21vNvM9O0adP0xBNPqH379pKkefPmKSoqSh9++KG6d+/uEzM5OVnJycmev5OSkgKdNgAAAAAAAK5wAT818uOPP1bDhg115513qkyZMqpXr55eeuklz/07duxQQkKC4uPjPdsiIyN1ww03aNWqVX5jTpw4UZGRkZ5bhQoVAp02AAAAAAAArnABL4Rt375ds2fPVrVq1fSf//xHDz30kAYMGKDXX39dkpSQkCBJioqK8npcVFSU576LjRgxQseOHfPcdu/eHei0AQAAAAAAcIUL+KmRqampatiwoSZMmCBJqlevnjZv3qw5c+aoZ8+eWYoZHh6u8PDwQKYJAAAAAAAAlwn4jLCyZcuqZs2aXttq1KihXbt2SZKio6MlSQcOHPBqc+DAAc99AAAAAAAAQKAFvBDWtGlTbd261Wvbb7/9pkqVKkn668L50dHRWrZsmef+pKQkrV69Wo0bNw50OgAAAAAAAICkIJwaOWjQIDVp0kQTJkxQ165dtWbNGr344ot68cUXJUlhYWEaOHCgxo8fr2rVqik2NlYjR45UTEyMOnToEOh0AAAAAAAAAElBKIQ1atRIH3zwgUaMGKGxY8cqNjZW06ZN0z333ONpM3z4cJ08eVJ9+/ZVYmKimjVrpiVLligiIiLQ6QAAAAAAAACSglAIk6R27dqpXbt26d4fFhamsWPHauzYscF4egAAAAAAAMBHwK8RBgAAAAAAAIQiCmEAAAAAAABwBQphAAAAAAAAcAUKYQAAAAAAAHAFCmEAAAAAAABwhaCsGgkg5zQYNi/DNusn98iGTAAAAAAACC3MCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCvky+kEAFxag2HzMtVu/eQeQc4EAAAAAIDcjRlhAAAAAAAAcAUKYQAAAAAAAHAFCmEAAAAAAABwBQphAAAAAAAAcAUulg/kgMxcAJ+L3wMAAAAAEFjMCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK1AIAwAAAAAAgCtQCAMAAAAAAIArUAgDAAAAAACAK+TL6QSAUNRg2LxMtVs/uUem26e1BQAAAAAAOYMZYQAAAAAAAHAFCmEAAAAAAABwBQphAAAAAAAAcAUKYQAAAAAAAHAFLpYP1+CC9gAAAAAAuBszwgAAAAAAAOAKFMIAAAAAAADgChTCAAAAAAAA4AoUwgAAAAAAAOAKFMIAAAAAAADgChTCAAAAAAAA4AoUwgAAAAAAAOAKFMIAAAAAAADgChTCAAAAAAAA4AoUwgAAAAAAAOAKFMIAAAAAAADgChTCAAAAAAAA4AoUwgAAAAAAAOAKFMIAAAAAAADgCvlyOgEgqxoMm5dhm/WTe2RDJgAAAAAAIDdgRhgAAAAAAABcgUIYAAAAAAAAXIFTIxFSON0RAAAAAAAES9BnhP373/9WWFiYBg4c6Nl25swZ9evXTyVLllThwoXVuXNnHThwINipAAAAAAAAwMWCWghbu3atXnjhBV177bVe2wcNGqRPPvlE7733nr755hvt27dPnTp1CmYqAAAAAAAAcLmgFcJOnDihe+65Ry+99JKKFy/u2X7s2DG98sorevbZZ3XTTTepQYMGmjt3rlauXKnvv/8+WOkAAAAAAADA5YJWCOvXr59uv/12xcfHe21fv369zp0757U9Li5OFStW1KpVq/zGSk5OVlJSktcNAAAAAAAAcCIoF8t/++23tWHDBq1du9bnvoSEBBUoUEDFihXz2h4VFaWEhAS/8SZOnKgxY8YEI1UAAAAAAAC4RMBnhO3evVuPPvqo5s+fr4iIiIDEHDFihI4dO+a57d69OyBxAQAAAAAA4B4BL4StX79eBw8eVP369ZUvXz7ly5dP33zzjaZPn658+fIpKipKZ8+eVWJiotfjDhw4oOjoaL8xw8PDVbRoUa8bAAAAAAAA4ETAT428+eab9dNPP3lt6927t+Li4vTYY4+pQoUKyp8/v5YtW6bOnTtLkrZu3apdu3apcePGgU4HAAAAAAAAkBSEQliRIkVUu3Ztr22FChVSyZIlPdvvu+8+DR48WCVKlFDRokXVv39/NW7cWDfeeGOg0wEAAAAAAAAkBeli+RmZOnWq8uTJo86dOys5OVlt2rTRrFmzciIVBFmDYfMybLN+co9syAQAAAAAALhdthTCli9f7vV3RESEZs6cqZkzZ2bH0wMAAAAAAACBv1g+AAAAAAAAEIoohAEAAAAAAMAVKIQBAAAAAADAFXLkYvnIvTJz8XuJC+ADAAAAAIDQw4wwAAAAAAAAuAKFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuEK+nE4Agddg2LwM26yf3CPL7QEAAAAAAHIjZoQBAAAAAADAFZgRlgtkZsaWxKwtAAAAAACAS2FGGAAAAAAAAFyBQhgAAAAAAABcIVefGtniibeUN7xghu3SThkM5kXkuUA9AAAAAABAaGNGGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXIFCGAAAAAAAAFyBQhgAAAAAAABcgUIYAAAAAAAAXCHghbCJEyeqUaNGKlKkiMqUKaMOHTpo69atXm3OnDmjfv36qWTJkipcuLA6d+6sAwcOBDoVAAAAAAAAwCPghbBvvvlG/fr10/fff6+lS5fq3LlzuuWWW3Ty5ElPm0GDBumTTz7Re++9p2+++Ub79u1Tp06dAp0KAAAAAAAA4JEv0AGXLFni9fdrr72mMmXKaP369WrRooWOHTumV155RQsWLNBNN90kSZo7d65q1Kih77//XjfeeGOgUwIAAAAAAACCf42wY8eOSZJKlCghSVq/fr3OnTun+Ph4T5u4uDhVrFhRq1at8hsjOTlZSUlJXjcAAAAAAADAiaAWwlJTUzVw4EA1bdpUtWvXliQlJCSoQIECKlasmFfbqKgoJSQk+I0zceJERUZGem4VKlQIZtoAAAAAAAC4AgW1ENavXz9t3rxZb7/99mXFGTFihI4dO+a57d69O0AZAgAAAAAAwC0Cfo2wNI888ogWL16sb7/9VuXLl/dsj46O1tmzZ5WYmOg1K+zAgQOKjo72Gys8PFzh4eHBShUAAAAAAAAuEPAZYWamRx55RB988IG++uorxcbGet3foEED5c+fX8uWLfNs27p1q3bt2qXGjRsHOh0AAAAAAABAUhBmhPXr108LFizQRx99pCJFiniu+xUZGamCBQsqMjJS9913nwYPHqwSJUqoaNGi6t+/vxo3bsyKkQAAAAAAAAiagBfCZs+eLUlq1aqV1/a5c+eqV69ekqSpU6cqT5486ty5s5KTk9WmTRvNmjUr0KkAAAAAAAAAHgEvhJlZhm0iIiI0c+ZMzZw5M9BPDwAAAAAAAPgV1FUjAQAAAAAAgFBBIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArkAhDAAAAAAAAK5AIQwAAAAAAACuQCEMAAAAAAAArpCjhbCZM2eqcuXKioiI0A033KA1a9bkZDoAAAAAAAC4guVYIeydd97R4MGD9eSTT2rDhg2qW7eu2rRpo4MHD+ZUSgAAAAAAALiC5Vgh7Nlnn9X999+v3r17q2bNmpozZ46uuuoqvfrqqzmVEgAAAAAAAK5g+XLiSc+ePav169drxIgRnm158uRRfHy8Vq1a5dM+OTlZycnJnr+PHTsmSTp/9nSmni8pKemv9skZt09r67R9Tscml+yPTS7ZH5tcsj82uWR/bHLJ/tjkkv2xySX7Y5NL9scml+yPTS7ZH5tcsj82uaTfNq29mV2ybZhl1CII9u3bp3LlymnlypVq3LixZ/vw4cP1zTffaPXq1V7tR48erTFjxmR3mgAAAAAAAMhFdu/erfLly6d7f47MCHNqxIgRGjx4sOfv1NRUHT16VCVLllRYWJhne1JSkipUqKDdu3eraNGiGcZ10j63xiaX7I9NLtkfm1yyPza5ZH9scsn+2OSS/bHJJftjk0v2xyaX7I9NLtkfm1yyPza5/DUT7Pjx44qJibnk43OkEFaqVCnlzZtXBw4c8Np+4MABRUdH+7QPDw9XeHi417ZixYqlG79o0aKZevGy0j63xiaX7I9NLtkfm1yyPza5ZH9scsn+2OSS/bHJJftjk0v2xyaX7I9NLtkfm1yyP7bbc4mMjMzwcTlysfwCBQqoQYMGWrZsmWdbamqqli1b5nWqJAAAAAAAABAoOXZq5ODBg9WzZ081bNhQ119/vaZNm6aTJ0+qd+/eOZUSAAAAAAAArmA5Vgjr1q2bDh06pFGjRikhIUHXXXedlixZoqioqCzHDA8P15NPPulzGmUg2ufW2OSS/bHJJftjk0v2xyaX7I9NLtkfm1yyPza5ZH9scsn+2OSS/bHJJftjk0v2xyaXzMuRVSMBAAAAAACA7JYj1wgDAAAAAAAAshuFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALhCri+E/fzzz5o0aZIGDBigAQMG6N///rd+/vlnRzGmTZt22Xl89NFH+vjjjyVJy5Yt04ABAzRr1iylpqZm6vHt2rW77BwkaeXKlUpKSpIknTx5Uk888YTuuOMODR8+XImJiZcdPzExUZMmTdK8efNkZnrqqafUrl07DRkyREeOHPFp/+WXX+rhhx9W+/bt1alTJz322GP67bffHD/vokWLMt02EP0pXV6fBqo/peD2abD7c/v27VqxYoVOnz7ttX3p0qWXlTdyxsaNG7Vp0yZJ0pYtW/Tss8/qs88+cxyHY27mOB2f0uUfcx988EHHedKfmZdTn6HIeTt27PB8FqampuqVV15R//79NWvWLJ07d85RLMZc5gT7GDp9+nT98ccfl5UjQse5c+f0zjvv6Ntvv5UkLViwQI888oief/55nT171lGsnB6jV+rvEMnZGN22bZuefvppPfrooxo8eLBmz56dpZxzuj8ljrnBEGZmli3PFATjx4/Xp59+qu7du6tcuXKSpL179+rtt9/WbbfdppEjR2YqTsWKFbVr1y6f7cuXL9fevXvVqlUrT3xJev3119WzZ0/P3/369dOhQ4eUnJysIkWKyMzUoUMHLV68WJGRkZo+fbpX3Ouvv97rbzPT5s2bVadOHUnSmjVrvO7fsWOHYmNjPW3nzJmjtWvXqlatWhowYIDy58/vaVurVi1t2rRJefPm1X333afo6Gh17NhRy5cv13fffaePPvrIK/bgwYPVoUMHtWjRIlOv1a233qp69eopKSlJmzdvVuPGjdWlSxctW7ZM3333nRYvXuxpO2TIEJ04cUKtW7fWxx9/rPLly6tu3bp6/vnnNWDAAN19992Zek4p/T5y0jaz/Sk569Ng9qfkrE9DqT9nzJihmTNnqnr16vrpp580ZcoUdezYUZJUv359bdiwIVM5StLQoUM1ZcoUz9+pqamaN2+e9u7dq1tuuUWNGjXy3Ddx4kSNGDHC6/FnzpzRCy+8oLCwMD3wwAN666239P777ysuLk6jRo1S4cKFM8zhuuuu048//uizfcWKFWratKkk6dSpUxo9erTWrVunWrVqady4cSpWrJhX+4ULF+qmm25SiRIldPDgQQ0ePFgbN25UjRo1NGXKFFWsWNHTtlOnTurQoYM6dOigokWLZpjjzp07NWnSJJUtW1aDBw/WoEGDtGrVKlWvXl2TJ0/W1Vdf7dX+/PnzevXVV/X+++9r3759yps3r6pVq6a+ffvq5ptv9mqbdrxNSUlRfHy8fvjhB9188836z3/+o9atW+vxxx/PML80oXzMDeb4lJyNUSfjU3I+Rrt27erzuixZskRt27aVJL377rsZ5iiFdn9KfIZK7j2GSs6Oo8E8htauXVvr1q1TRESEhgwZooMHD6p9+/Zavny5jh8/rtdffz3D1zANYy40jqHFihVT8eLFFR0drW7duqlr166KiYnJMK+LXTw+pewfo+mNT8nZGA3m+JScjVEn41OS7r77bpmZTp48qaJFiyo1NVWdOnXSsmXLlJSUpPnz52eYXxp/Y5TfIb6COUafeeYZffXVV2revLk+//xzXXvttYqOjta7776rZ555RvHx8ZnKUcre/pT43nqp7zk///yzFi9erL1790qSYmJidMcdd6hWrVoZ5ufDcrFq1apZamqqz/aUlBSrWrWq17bSpUv7vZUqVcry5cvnE+Nf//qXtWzZ0h599FGrWrWqTZ061XNfvXr1vNrWqVPHzMzOnTtnpUqVsnPnznnySLvvQp07d7Zu3brZ5s2bbefOnbZjxw4rX7687dy503bu3OnT/sLn+9e//mXdunWzTz/91B544AG7//77vdpWr17d8+/69et73Ve3bl2f2KVLl7ZmzZpZ+fLl7dFHH7WVK1f6tLnQdddd5/l3uXLl0r3PzKx27dqef6ekpNiNN95oZmbHjx+3mjVr+sRu1KiR31vDhg0tPDzcJ+9g9aeZsz4NZn+aOevTUOrP2rVr24kTJ8zMbNeuXdakSRObMGGC39hmZidPnvR7O3HihJUvX96r7X333Wf33HOPTZ061Ro1amQDBgyw8+fPm5n//uzatasNGTLE+vXrZ61bt7bBgwfbmjVr7IknnrB77rnHp32pUqW83lOlSpWyvHnzerZf6MLne/jhh23IkCH2888/24QJE+zOO+/0iX3ha9W5c2d74YUX7NChQ/buu+9a69atvdqWK1fO7r33XitdurS1b9/eFixY4HlN/WnWrJnNmTPHJk2aZDVq1LBZs2bZoUOH7K233rKWLVv6tL/nnntswoQJtmrVKhs+fLiNGjXK/vvf/9odd9xhU6ZM8Wpbq1YtO3/+vJ06dcqKFi3qyePMmTN+j3O59ZgbzPGZ9rpkdow6GZ9mzsfoDTfcYN27d7evvvrKli9fbl9//bVFR0fb8uXLbfny5T5558b+vPj5ruTPUI6hvsdQM2fH0WAeQ+Pi4vzus5nZtdde6xObMRf6x9C0GCtWrLCBAwdahQoVrHnz5jZjxgxLSEjwautkfJoFd4w6GZ8XP19GYzSY49PM2Rh1Mj7N/m9cpKSkWHR0tNdvzMsdo/wO8S+YYzTte6uZ2enTp6158+ZmZrZ///6Q7k8zvremd8wdN26c3XjjjTZt2jR777337L333rNp06bZjTfeaGPHjk03r/Tk6kJYrVq1bPPmzT7bf/rpJ6tVq5bXtooVK/p8KKXx9wFUp04dS0lJMTOzpKQk69y5s/Xt29dSUlJ8OvLCN02XLl287vM30MzMli5daq1bt7Z58+aZmVlsbKzfdmbeb5zrrrvOkpOTzczs/PnzPoOnV69eNnHiREtOTrZHHnnEPv/8czMzW7VqlTVt2jTd2Hv27LFp06ZZkyZNrFKlSjZ06FBbs2aNT/t69erZtm3bbP369VaqVCnbuHGjmZnt3LnT682cFnvXrl1mZrZ582av569Ro4ZP7KioKNuwYYNnkKfdduzYYWXLlvVqG8z+NHPep8HqTzNnfRpK/Xnhl34zs+TkZOvWrZv16dPHJ7aZWZ48eSw2NtYqV67suaX9nT9/fq+2F/ZBSkqKDRw40Nq2bWvHjx+/ZH+mpqb6vJf8HfSHDBli9957r+3evduzrXLlyj7tzLw/gOrWrev1xclf7Guuucbz7wYNGqS7X2b/15/Jycn24Ycf2t13322lS5e2Ll262LvvvusT+8J9r1ChQrr3pbn4/daoUSMz++uD+sIPyosf36RJE6/7/O1nbj3mBnN8Xhg/M2PUyfhMi+1kjKamptpLL71k8fHx9u23317ydcmt/Wnmns9QjqH+3y9OjqPBPIa2b9/e3n77bTP76wf6pk2bzMxsx44dPj9GzBhzueEY6u8H73fffWf9+/f3ef84GZ9mwR2jTsbnxfuZ0RgN5vi8sL1ZxmPUyfhMa//nn3/anj17LDIy0vbs2WNmZomJiX7738kY5XfI5X8mpsXP7BitXbu2HTt2zMzM9u3b5+l/M/NbZAml/jTje6u/MedkElRm5OpC2OrVq61Ro0ZWv359u+OOO+yOO+6wevXqWaNGjez777/3ajt+/Hhbt26d3zgjR4702ebvADl8+HC75ZZbvA7yZmZ33XWXHT9+3Kf9H3/8YY0bN043/3PnztmkSZPs5ptvtpiYmHTbXX311fbZZ5/Z4sWLfd4UF38AnTlzxp544gmrXLmyVa1a1cLCwqxYsWLWtWtX2759u09sfx/iu3btsmeeecZTlb3Ql19+aXXq1LG6devaihUrrEuXLlarVi2LioqyRYsWebX94osvrFKlSlarVi2LjY21//73v2ZmdvDgQRs0aJBP7H79+qVbZe7Vq5fX38HsT7Os9Wkw+tPMWZ9mR3/Wrl3bYmNjbcWKFWaWfn+2bdvW8+P6Qo899piFhYX5bK9WrZrf/7ky8/0Aql69uud/edLMnDnT6tev7/fL3IUfMgMGDEj3vgtt2bLF2rVrZ2PHjrUzZ86k+wFUvnx5mzlzps2YMcOqVKnidYD29wE0bNgwe/DBB23v3r02evRomz17tiUkJNhbb71lbdq08Wrrrz9Pnz5tCxcutG7duvncd8MNN9jSpUtt0aJFVrFiRVuyZImZmX3//fd+Y91www22du1aM/urf+Pj4z33XTxmWrRo4XdMHDp0yBo2bOizPbcec4M5Ps2cjVEn49PM+RhNc/ToUXvooYese/fufn9gm+Xe/jTL/Z+hme1PjqG+x1AzZ8fRYB5Djxw5Yvfee6/VqFHDmjVrZgUKFLC4uDhr0aKF37HFmAv9Y6i/H7xpLv6x5mR8mgV/jGZ2fKbll9kxGszxaeZsjDoZn2ZmCxYssJiYGIuJibFFixZZmzZtrF27dlaxYkWbNWuWT3snY5TfIZf/mWjmbIy++eabdvXVV1u7du2scuXK9tFHH3na+pttHGr9aeae761ptYKMjrlOJkFlRq4uhKXZt2+frVu3ztatW2f79u0LSMy7777b/vOf//hsnz17tt8p6f6cO3fOTp06lWG7vXv32qeffpru/b169fK6pVWr9+/fbzfddFO6j0tMTLTDhw9f8rnTpolejkOHDnmq4hdLTU21gwcPXvZzXK5A9KdZ5vo0WP1plnGfhlJ/njp1Kt3XKu1/2S708ssv+z24mZm98MILXn8PHTrUvvzyS592ixcv9vs/AkOGDPH7AbRt2zZr27at3+dM884771jTpk0tOjra7/2jR4/2uqW9Pvv377f/9//+n0/71NRUe/nll61Ro0YWHR1thQsXtri4OBs+fLgdPXrUq62/L4GXsnHjRrvjjjusffv29uuvv9qAAQOsTJkyVqNGDfvmm2982v/www/WoEEDK126tDVu3Nh++eUXM/vrPfDMM89k6jmPHTtmf/zxh6M8/QmVY24wx6fZ5Y/RS41Ps8s75v7www82e/bsrKbmJVT608w9n6EcQ32PoWbOjqOXOob6+4+dtGNomTJlrHHjxrZlyxYzu/Qx9NixY/bjjz/aunXrbP/+/ZnOLSOBGHMpKSlX/JgL5DHU35hIj5PxaZZ9YzSj8WnmbIwGc3yaORujGzZs8BqfTr/jnDt3ztauXRuQ35aB+h2SmTF6Jf8OMXM2Rg8fPmxr1qzx+967HNn5u9KM761pnEyCyoxcfbH8S0lISFB0dLTXtoBeXO0iTmOHUi6BiP/3v/9dNWvWDFou/vozPYsWLVLnzp0dxXfCSfxQyiWYsZ3m4aQ/Q8GpU6e0fft21a5dO6dTCUnp9efGjRsVFhama6+9Vlu2bNGSJUsUFxen22677bKf02nsUMrlcmPXqFHDc0H7YOWSmTH64IMPas6cOY7iZpbT2KGUSzDjBzuXYOEYemn+xtuOHTsUHR2tggULKjU1VXPnztWPP/6oGjVq6P777/e5ALITTmOHUi65ZT9z0/ccxmfG/PXnuXPn9P7776ts2bJq0aKFFixYoJUrV6p69ep64IEHVKBAgSw/n5PYwczjwvgxMTFq3rx5ju1nIPc1vfG5bds2ffDBB9q7d69ncYW77rrLZ9GWrHAaO5RyudzYd999tyIjIwOWy/79+7Vv3z5Jf9UWypYtm6Vcr9hC2O23365PP/3U8/e4ceP02WefOVphMrNFHKexs7LaZWZzCWZsp/ualdc8PRf356U4WWFScl7ECcQKljmRSyjtZ3r9uX37du3fv1/169dXwYIFPduXLl2qv/3tb1luG+z2uTV2Vtr7468/s7LKZGaLOE5jO23vpJiUm/fzUi7u00CsMJleEcdp7FDKxUlsp/Gd5pKcnKzw8HDP359//rln5aiLj/1O2ga7fW7IpXbt2urUqdNl55Ief8dQp6tMOiniOI0dSrmE0n466dPp06erQ4cOPqsmpicr7du3b69KlSoFtK3TXIKZd7BzuRR/Y9TJKpNOCzhOYjtd7TKYuQQzdlbaO+lPp6tMOingOI0d7FyWLVumFi1aZHo1zczGdxo7K7mkJyv/+ZDrC2F//vmnvvjiC68iTps2bVS8eHGvdtdcc422bt2qsLAwr+3nz59XXFyctm3b5rXdSRHHaexQysVpscpJfKe5SJnvz4uXlU1jZvrpp5905swZv/f746+I4yR+KOUSzNhZySOz/SlJM2bM0MyZM1W9enX99NNPmjJlijp27ChJql+/vjZs2JCltsFun1tjZ6W9k/6sXbu2Nm3apOTkZEVHR2vfvn0qVKiQkpOT1ahRI23atMmr/aWKOK1atdITTzyR5dhO2jvJI9D7eXGxKpj76bRPb7zxRsXGxqpv377KkyePzEx33XWX3n77bUlSy5Ytvdo7KeI4jR1KuTgtVjmJ7zSXC8fs1KlT9dFHH6lr1676/PPPVadOHU2YMCFLbQPd/tprr9VTTz2VLbFzMhd/7Z0cQ2vUqKFffvnF53kkqW7dutq4caNXeydFHKexQymXUNpPKfN9WqxYMRUvXlzR0dHq1q2bunbtqpiYGJ942dE+t8YOdi6SszF67bXXatOmTTp//rzKly+vffv2eX7zXPx+cVrAcRLbSdtg5xLM2Flpn5XvrXny5NGZM2d0yy236Ntvv1VCQoLatGnjFdtpAcdJ7FDLxUlRLpj7mZF27dpp8eLFmW4vSbn6GmEvv/yyVa9e3QYNGmSTJ0+2yZMn28CBAy0uLs5efvllr7ZOL67mZFUCp7FDKRenqy84ie80Fyf96WSFSbO/Vorxd2vYsKGFh4f7tHcSP5RyCaX9dNKfZn+t7pK2ZPauXbusSZMmNmHCBDPzvSCtk7bBbp9bYztt77Q/na4ymbbM9alTp6xo0aKevM6cOeNzMV6nsZ20d5JHVnIJlf00c9anTlaYNPvrIsXdu3e3r776ypYvX25ff/21RUdH2/Lly2358uWXFTuUcnES22l8p7lc2P/169e3pKQkM/trNTZ/K1Jmtm2w27slF6fHUKerTF64UvPFFze++GLpTmOHUi6htJ9O+jTtvbJixQobOHCgVahQwZo3b24zZszwu1JdMNvn1tjBzsXpGHWyymTa53tKSopFR0d7/fbyt5iB09hOVrsMdi7Biu20fVZ+h2R2lcm073Jmfy3ukHYdrf379/vdT6crWIZSLk7iB3M/M7Jq1SpH7c1y+cXyr7nmGs+PiAsdP37cqlWr5rXN6cXVnBRxnMYOpVycFqucxHeai5P+dLLCpJnzIo6T+KGUSyjtp5P+NPP+cmv21w+Jbt26WZ8+fXx+UDhpG+z2uTW20/ZO+9PpKpNOijhOYztp77SYlFv308x5n5plboVJM+dFHCexQymXrMR2Et9J27i4ONuyZYtt3rzZ57108d9O2ga7vVtycTrenK4y6aSI4zR2KOUSSvvppE/9rbz23XffWf/+/a1ChQo+9wWzfW6NHexcnI5RJ6tMOi34OIntdLXLYOYSzNhO2zvtTyerTDot4DhdwTKUcnESP5j7mRF/YzojuboQVr16db8r7uzbt8/v0qVp92VmhcmsrErgdPXKUMglq6svONnXzLbNSn9mltMiTjAFM5dQ2k+n/dm2bVu/q3I99thjFhYWluW2wW6fW2M7bR+o8ZneKpNOizhOYjtpH4g8LpVLqOyn2eX1aWZXmHRa3HISO5RyyUpsJ/Ez07ZVq1Zet7TP28OHD1uDBg2y3DbY7d2SS1bHW2ZXmXRaxHESO5RyCaX9dNKn/mZlp/F3ZkYw2+fW2MHO5XK/51xqlUmnBR8nsZ22DWYu2bmfGbXPSn9mdpXJrBRwnK5gGSq5OI0frP00M7vzzjv93rp06WKFChXK1PNdKFdfI2zx4sUaMmSIateu7bm+1Z49e/Tzzz/rmWeeUbt27TIV51IXV7vcVQmcXrgtp3IJxOoLTvbVX9vs6M9AuNz9zKlcghk7EP15+vRpSfK6YHuavXv3emI4bRvs9rk1ttP2gRqfkrP3VlJSkhITEzN9sdtAHnMvJw+nueTEfmbnMffHH3/U999/rwcffDDTOWc2dijlktXYmY2flbbnz59XcnKyrrrqqoC2DXb7Ky2X7DqGJiUlaceOHUpJSVG5cuUcf0cI5JgLZi6hsJ9O+vTEiRMqXLhwpp8vmO1za+xg55Kd33NSUlL0448/qly5ckH9bZmZtsHMJbv201/7YPfnkSNHtH37dlWtWtXvNccuJ3ao5RKI+IHYzxIlSuiNN97wGddmpm7duunAgQPOknJcOgsxKSkptnLlSlu4cKEtXLjQVq5caSkpKY5i3HbbbY7aZ+Z/k7IaO5RycRLbafz02oZ6fzqNH0q55Nb+NHOWu9P9DGb73Bo7vfaB6s9QOs6FyhhyGj9Q+xnqx1w+Q7M/F7ccQ3MiF7cfQ4OdS249hl5p7/OciB2oXHJijObWzwqn8YP9Hcpf+yutP0Mtl+w+5nbs2NG++eYbv+3j4+MdxTfL5TPCnHKycsSl+Fty1WnsUMrFSWyn8QOViz9X4n4GIpdgxg5mf2Yl98ttG+z2uTV2Vtr7E0rHuVAZQ07j59RnSzBjh9J+uuUzNLceW9yUiz+h9D4PpVyCGTsnvue45X2em/czPaHy3SKUPreCHTvUv+eE0n66/XtrRlxTCHvllVc0efJk3XbbbZ6lc/fu3aslS5Zo6NChuu+++3wek9mOcRo7lHJxEttp/Kzkklm5fT+DlUuo7adTwfzQD2b73Bo7K+0zK5SOc6EyhkJtP53I7fvpls/Q3HpscVMumRVK7/NQyiXU9tMJt7zPc/N+OhEq3y1C6XMr2LFD6XtOKO0n31uzxjWFsOrVq2vDhg0qVKiQ1/YTJ06ofv36+u2337y2O+kYp7FDKRenb0An8Z3m4kRu3s9g5hJK++lUMD/0g9k+t8bOSnsnQuk4FypjKJT206ncvJ9u+QzNrccWN+XiRCi9z0Mpl1DaTyfc8j7PzfvpVKh8twilz61gf4cKle85obSffG+9DI5PpsylnK4c4WTJVaexQykXp0vLOokfzFUgc/N+BjOXUNpPp5zk7nQ/g9k+t8bOSnsnQuk4FypjyGn8YH+2OJGb99Mtn6G59djiplycCKX3eSjlEkr76YRb3ue5eT+dCpXvFqH0uRXs71Ch8j0nlPaT761Zly+4ZbbQMWXKFLVs2TLdlSMuFhYWpuPHj/tUKI8fP66wsLDLih1KuTiJ7TS+01ycyM37GcxcQmk/nXKSu9P9DGb73Bo7K+2dCKXjXKiMoVDaT6dy83665TM0tx5b3JSLE6H0Pg+lXEJpP51wy/s8N++nU6Hy3SKUPreC/R0qVL7nhNJ+8r0161xzaqT013LWa9as0b59+yT9dX7r9ddfr7x58/q0dbrkqpPYoZRLVpaWdRLf6eviRG7dz2DmEkr76ZST3J3uZzDb59bYWWnvVKgc55y0D/YYCpX9zIrcup9u+QzNrccWN+XiVKi8z0Mpl1DaTyfc8j7PzfuZFaHy3SJUPreCvZ9Zae9EbtxPvrdmnasKYU7lZMdkZy6htJ/BFEr7SX/6F8yiXDDb59bYWWkfTKGSS7DzCJX9DLZQ2k+3HHNz67HFTbkEk1tyCaX9dMIt7/PcvJ/B5JZcQmk/gymU9pPvrVlDIQwAAAAAAACukCenEwAAAAAAAACyA4UwAAAAAAAAuAKFMAAAAAAAALgChTAAAAAAAAC4AoUwAAAAAAAAuAKFMAAAAAAAALgChTAAAAAAAAC4wv8HjXeBCeDnYsgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Reducing False Negatives in a Classification Model**\n",
        "\n",
        "This code helps you **reduce** the number of **false negatives** in a classification model by **adjusting** the **decision threshold**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. What is a False Negative?**\n",
        "\n",
        "* **False Negative (FN)**:\n",
        "\n",
        "  * When the model **predicts** a **negative** class, but the **actual** class is **positive**.\n",
        "  * Example: Predicting **\"no cancer\"** when the patient **actually** has **cancer**.\n",
        "* **Reducing** false negatives is **important** when missing a **positive** case has **serious** consequences.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Get the Predicted Probabilities**\n",
        "\n",
        "```python\n",
        "y_pred_prob = grid_search.predict_proba(X_test)\n",
        "```\n",
        "\n",
        "* **predict\\_proba()**:\n",
        "\n",
        "  * Returns the **probability** of each class for each sample in the **test** set.\n",
        "* **y\\_pred\\_prob\\[:,1]**:\n",
        "\n",
        "  * The **second** column contains the **probability** for the **positive** class (**class 1**).\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Initialize Lists for Results**\n",
        "\n",
        "```python\n",
        "false_negatives = []\n",
        "accuracy = []\n",
        "```\n",
        "\n",
        "* **false\\_negatives**:\n",
        "\n",
        "  * Will store the **number** of false negatives for each threshold.\n",
        "* **accuracy**:\n",
        "\n",
        "  * Will store the **accuracy** for each threshold.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Test Different Thresholds**\n",
        "\n",
        "```python\n",
        "for threshold in np.linspace(0, 1, 100):\n",
        "    y_pred_class = y_pred_prob[:,1].copy()\n",
        "    \n",
        "    # Convert probabilities to 0s and 1s\n",
        "    y_pred_class[y_pred_class >= threshold] = 1\n",
        "    y_pred_class[y_pred_class < threshold] = 0\n",
        "    \n",
        "    # Count false negatives\n",
        "    fn = confusion_matrix(y_test, y_pred_class)[1,0]\n",
        "    acc = accuracy_score(y_test, y_pred_class) * 100\n",
        "    \n",
        "    false_negatives.append(fn)\n",
        "    accuracy.append(acc)\n",
        "```\n",
        "\n",
        "* **np.linspace(0, 1, 100)**:\n",
        "\n",
        "  * Tests **100** different threshold values between **0** and **1**.\n",
        "* **Threshold Logic**:\n",
        "\n",
        "  * If **probability** is **greater** than the threshold, predict **1** (positive).\n",
        "  * If **less**, predict **0** (negative).\n",
        "* **Confusion Matrix**:\n",
        "\n",
        "  * **\\[1,0]** gives you the **number** of false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Convert to Numpy Arrays for Plotting**\n",
        "\n",
        "```python\n",
        "false_negatives = np.asarray(false_negatives)\n",
        "accuracy = np.asarray(accuracy)\n",
        "```\n",
        "\n",
        "* Converts the **lists** to **numpy** arrays for **easier** plotting.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Plot the False Negatives**\n",
        "\n",
        "```python\n",
        "plt.figure(figsize=(15,5))\n",
        "chart = sns.barplot(x=np.round(np.linspace(0,1,100),2), y=false_negatives)\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=90, fontsize=7)\n",
        "chart.set_title('Number of False Negatives as a Function of the Threshold')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* **x-axis**:\n",
        "\n",
        "  * The **threshold** values.\n",
        "* **y-axis**:\n",
        "\n",
        "  * The **number** of false negatives.\n",
        "* **Title**:\n",
        "\n",
        "  * Describes what the graph is showing.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Plot the Accuracy**\n",
        "\n",
        "```python\n",
        "plt.figure(figsize=(15,5))\n",
        "chart = sns.barplot(x=np.round(np.linspace(0,1,100),2), y=accuracy)\n",
        "chart.set_xticklabels(chart.get_xticklabels(), rotation=90, fontsize=7)\n",
        "chart.set_title('Accuracy as a Function of the Threshold')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* **x-axis**:\n",
        "\n",
        "  * The **threshold** values.\n",
        "* **y-axis**:\n",
        "\n",
        "  * The **accuracy** at each threshold.\n",
        "* **Title**:\n",
        "\n",
        "  * Describes what the graph is showing.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. What to Look for in the Plots**\n",
        "\n",
        "* **Low Threshold**:\n",
        "\n",
        "  * Fewer false negatives, but **more** false positives.\n",
        "* **High Threshold**:\n",
        "\n",
        "  * Fewer false positives, but **more** false negatives.\n",
        "* **Ideal Threshold**:\n",
        "\n",
        "  * A **balance** between **high accuracy** and **low** false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Why This is Important**\n",
        "\n",
        "* Helps you find the **best** threshold to **reduce** false negatives.\n",
        "* Useful in **medical** diagnostics, **fraud** detection, and **security** systems where **false negatives** are **costly**.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jZESju52NBB_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKASH0QEJQWM"
      },
      "source": [
        "## 2 - MNIST\n",
        "\n",
        "The MNIST (\"Modified National Institute of Standards and Technology\") dataset is commonly used for testing and benchmarking classification algorithms. It contains tens of thousands of images of handwritten digits. More information about this dataset can be found at: [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "For this task, three data files are provided:\n",
        "\n",
        "1. 'train.csv' contains labeled data for training the classifier.\n",
        "2. 'test.csv' contains labeled data for testing the trained classifier.\n",
        "3. 'test_Kaggle.csv' contains unlabeled data for evaluating the classifier through the competition found at [Kaggle Digit Recognizer](https://www.kaggle.com/c/digit-recognizer). This data is only useful for participating in the Kaggle competition.\n",
        "\n",
        "1) Train both a logistic regression classifier and a Support Vector Machine (with or without kernel). Tune the hyperparameters to find the most performant classifier by maximizing accuracy or minimizing the error rate on the 'test.csv' dataset. The error rate = 1 - accuracy. Training Support Vector Machines (especially those with kernel) requires significant computational resources. Therefore, it is advisable to initially train on a small portion of the training set. Training via logistic regression is less demanding on the CPU; nonetheless, it is recommended to use the lbfgs solver (LogisticRegression(multi_class='multinomial', solver='lbfgs')).\n",
        "\n",
        "2) Provide comments in the code and write down your conclusions and decisions.\n",
        "\n",
        "3) Is normalization necessary here? Which normalization method would you use? Is StandardScaler a good choice?\n",
        "\n",
        "4) Investigate the two different types of multiclass classification: one-vs-one (ovo) or one-vs-rest (ovr). Focus on accuracy and computation time. What are the conclusions?\n",
        "\n",
        "5) Test your final classifier with some self-written digits. What are the findings? What does classification accuracy depend on?\n",
        "\n",
        "6) Optional: Test on the 'test_Kaggle' dataset and upload the results in the correct format to the Kaggle website. What score did you achieve? Compare this score with the score on [MNIST](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "You can visualize a digit using 'plt.imshow(X_train[n].reshape((28, 28)),cmap = 'gray')'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d98wCwxJJQWN",
        "outputId": "af1d3d74-78cd-4e0c-8dc4-8f83dcf24652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8  pixel9  pixel10  pixel11  pixel12  pixel13  pixel14  pixel15  \\\n",
              "0       0       0        0        0        0        0        0        0   \n",
              "1       0       0        0        0        0        0        0        0   \n",
              "2       0       0        0        0        0        0        0        0   \n",
              "3       0       0        0        0        0        0        0        0   \n",
              "4       0       0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel16  pixel17  pixel18  pixel19  pixel20  pixel21  pixel22  pixel23  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel24  pixel25  pixel26  pixel27  pixel28  pixel29  pixel30  pixel31  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel32  pixel33  pixel34  pixel35  pixel36  pixel37  pixel38  pixel39  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel40  pixel41  pixel42  pixel43  pixel44  pixel45  pixel46  pixel47  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel48  pixel49  pixel50  pixel51  pixel52  pixel53  pixel54  pixel55  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel56  pixel57  pixel58  pixel59  pixel60  pixel61  pixel62  pixel63  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel64  pixel65  pixel66  pixel67  pixel68  pixel69  pixel70  pixel71  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel72  pixel73  pixel74  pixel75  pixel76  pixel77  pixel78  pixel79  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel80  pixel81  pixel82  pixel83  pixel84  pixel85  pixel86  pixel87  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel88  pixel89  pixel90  pixel91  pixel92  pixel93  pixel94  pixel95  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        0        0        0        0        0        0   \n",
              "\n",
              "   pixel96  pixel97  pixel98  pixel99  pixel100  pixel101  pixel102  pixel103  \\\n",
              "0        0        0        0        0         0         0         0         0   \n",
              "1        0        0        0        0         0         0         0         0   \n",
              "2        0        0        0        0         0         0         0         0   \n",
              "3        0        0        0        0         0         0         0         0   \n",
              "4        0        0        0        0         0         0         0         0   \n",
              "\n",
              "   pixel104  pixel105  pixel106  pixel107  pixel108  pixel109  pixel110  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel111  pixel112  pixel113  pixel114  pixel115  pixel116  pixel117  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel118  pixel119  pixel120  pixel121  pixel122  pixel123  pixel124  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0        18        30       137   \n",
              "2         0         0         0         0         0         0         3   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         1        25       130       155   \n",
              "\n",
              "   pixel125  pixel126  pixel127  pixel128  pixel129  pixel130  pixel131  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       137       192        86        72         1         0         0   \n",
              "2       141       139         3         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       254       254       254       157        30         2         0   \n",
              "\n",
              "   pixel132  pixel133  pixel134  pixel135  pixel136  pixel137  pixel138  \\\n",
              "0       188       255        94         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel139  pixel140  pixel141  pixel142  pixel143  pixel144  pixel145  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel146  pixel147  pixel148  pixel149  pixel150  pixel151  pixel152  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0        13        86       250       254       254   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3       220       179         6         0         0         0         0   \n",
              "4         0         0         8       103       253       253       253   \n",
              "\n",
              "   pixel153  pixel154  pixel155  pixel156  pixel157  pixel158  pixel159  \\\n",
              "0         0         0         0         0         0         0       191   \n",
              "1       254       254       217       246       151        32         0   \n",
              "2       254       254         8         0         0         0         0   \n",
              "3         0         0         0         0         9        77         0   \n",
              "4       253       253       253       253       253       114         2   \n",
              "\n",
              "   pixel160  pixel161  pixel162  pixel163  pixel164  pixel165  pixel166  \\\n",
              "0       250       253        93         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel167  pixel168  pixel169  pixel170  pixel171  pixel172  pixel173  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel174  pixel175  pixel176  pixel177  pixel178  pixel179  pixel180  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0        16       179       254       254       254       254   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3        28       247        17         0         0         0         0   \n",
              "4         0        11       208       253       253       253       253   \n",
              "\n",
              "   pixel181  pixel182  pixel183  pixel184  pixel185  pixel186  pixel187  \\\n",
              "0         0         0         0         0         0       123       248   \n",
              "1       254       254       254       254       254       231        54   \n",
              "2       254       254         8         0         0         0         0   \n",
              "3         0         0         0         0        27       202         0   \n",
              "4       253       253       253       253       253       253       107   \n",
              "\n",
              "   pixel188  pixel189  pixel190  pixel191  pixel192  pixel193  pixel194  \\\n",
              "0       253       167        10         0         0         0         0   \n",
              "1        15         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel195  pixel196  pixel197  pixel198  pixel199  pixel200  pixel201  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel202  pixel203  pixel204  pixel205  pixel206  pixel207  pixel208  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0        72       254       254       254       254       254   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0       242       155         0         0         0         0   \n",
              "4         0        31       253       253       253       253       253   \n",
              "\n",
              "   pixel209  pixel210  pixel211  pixel212  pixel213  pixel214  pixel215  \\\n",
              "0         0         0         0         0        80       247       253   \n",
              "1       254       254       254       254       254       254       254   \n",
              "2       254       254       106         0         0         0         0   \n",
              "3         0         0         0         0        27       254        63   \n",
              "4       253       253       253       253       253       253       215   \n",
              "\n",
              "   pixel216  pixel217  pixel218  pixel219  pixel220  pixel221  pixel222  \\\n",
              "0       208        13         0         0         0         0         0   \n",
              "1       104         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       101         3         0         0         0         0         0   \n",
              "\n",
              "   pixel223  pixel224  pixel225  pixel226  pixel227  pixel228  pixel229  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel230  pixel231  pixel232  pixel233  pixel234  pixel235  pixel236  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1        61       191       254       254       254       254       254   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0       160       207         6         0         0         0   \n",
              "4        23       210       253       253       253       248       161   \n",
              "\n",
              "   pixel237  pixel238  pixel239  pixel240  pixel241  pixel242  pixel243  \\\n",
              "0         0         0         0        29       207       253       235   \n",
              "1       109        83       199       254       254       254       254   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0        27       254        65   \n",
              "4       222       222       246       253       253       253       253   \n",
              "\n",
              "   pixel244  pixel245  pixel246  pixel247  pixel248  pixel249  pixel250  \\\n",
              "0        77         0         0         0         0         0         0   \n",
              "1       243        85         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       253        39         0         0         0         0         0   \n",
              "\n",
              "   pixel251  pixel252  pixel253  pixel254  pixel255  pixel256  pixel257  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel258  pixel259  pixel260  pixel261  pixel262  pixel263  pixel264  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       172       254       254       254       202       147       147   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0       127       254        21         0         0         0   \n",
              "4       136       253       253       253       229        77         0   \n",
              "\n",
              "   pixel265  pixel266  pixel267  pixel268  pixel269  pixel270  pixel271  \\\n",
              "0         0         0        54       209       253       253        88   \n",
              "1        45         0        11        29       200       254       254   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0        20       239        65   \n",
              "4         0         0        70       218       253       253       253   \n",
              "\n",
              "   pixel272  pixel273  pixel274  pixel275  pixel276  pixel277  pixel278  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       171         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       253       215        91         0         0         0         0   \n",
              "\n",
              "   pixel279  pixel280  pixel281  pixel282  pixel283  pixel284  pixel285  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         1   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         5   \n",
              "\n",
              "   pixel286  pixel287  pixel288  pixel289  pixel290  pixel291  pixel292  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       174       254       254        89        67         0         0   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0        77       254        21         0         0         0   \n",
              "4       214       253       253       253       195         0         0   \n",
              "\n",
              "   pixel293  pixel294  pixel295  pixel296  pixel297  pixel298  pixel299  \\\n",
              "0         0        93       254       253       238       170        17   \n",
              "1         0         0         0         0       128       252       254   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0       195        65   \n",
              "4         0         0         0       104       224       253       253   \n",
              "\n",
              "   pixel300  pixel301  pixel302  pixel303  pixel304  pixel305  pixel306  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       212        76         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       253       253       215        29         0         0         0   \n",
              "\n",
              "   pixel307  pixel308  pixel309  pixel310  pixel311  pixel312  pixel313  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0        47   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       116   \n",
              "\n",
              "   pixel314  pixel315  pixel316  pixel317  pixel318  pixel319  pixel320  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254        29         0         0         0   \n",
              "2         0         0         0         0         0         0         6   \n",
              "3         0        70       254        21         0         0         0   \n",
              "4       253       253       253       247        75         0         0   \n",
              "\n",
              "   pixel321  pixel322  pixel323  pixel324  pixel325  pixel326  pixel327  \\\n",
              "0        23       210       254       253       159         0         0   \n",
              "1         0         0         0         0         0        83       254   \n",
              "2       185       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0       195       142   \n",
              "4         0         0         0         0        26       200       253   \n",
              "\n",
              "   pixel328  pixel329  pixel330  pixel331  pixel332  pixel333  pixel334  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       153         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       253       253       253       216         4         0         0   \n",
              "\n",
              "   pixel335  pixel336  pixel337  pixel338  pixel339  pixel340  pixel341  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0        80   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel342  pixel343  pixel344  pixel345  pixel346  pixel347  pixel348  \\\n",
              "0         0         0         0         0         0         0        16   \n",
              "1       254       254       240        24         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0        56       251        21         0         0         0   \n",
              "4       253       253       253       195         0         0         0   \n",
              "\n",
              "   pixel349  pixel350  pixel351  pixel352  pixel353  pixel354  pixel355  \\\n",
              "0       209       253       254       240        81         0         0   \n",
              "1         0         0         0         0         0        25       240   \n",
              "2        89       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0       195       227   \n",
              "4         0         0         0         0         0        26       200   \n",
              "\n",
              "   pixel356  pixel357  pixel358  pixel359  pixel360  pixel361  pixel362  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       153         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       253       253       253       253         5         0         0   \n",
              "\n",
              "   pixel363  pixel364  pixel365  pixel366  pixel367  pixel368  pixel369  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0        64   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel370  pixel371  pixel372  pixel373  pixel374  pixel375  pixel376  \\\n",
              "0         0         0         0         0         0         0        27   \n",
              "1       254       254       186         7         0         0         0   \n",
              "2         0         0         0         0         0         0         4   \n",
              "3         0         0       222       153         5         0         0   \n",
              "4       253       253       253        99         0         0         0   \n",
              "\n",
              "   pixel377  pixel378  pixel379  pixel380  pixel381  pixel382  pixel383  \\\n",
              "0       253       253       254        13         0         0         0   \n",
              "1         0         0         0         0         0         0       166   \n",
              "2       146       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0       120       240   \n",
              "4         0         0         0         0         0         0        25   \n",
              "\n",
              "   pixel384  pixel385  pixel386  pixel387  pixel388  pixel389  pixel390  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       224        12         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3        13         0         0         0         0         0         0   \n",
              "4       231       253       253       253        36         0         0   \n",
              "\n",
              "   pixel391  pixel392  pixel393  pixel394  pixel395  pixel396  pixel397  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0        14       232   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel398  pixel399  pixel400  pixel401  pixel402  pixel403  pixel404  \\\n",
              "0         0         0         0         0         0        20       206   \n",
              "1       254       254       254        29         0         0         0   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0         0        67       251        40         0         0   \n",
              "4       253       253       253        99         0         0         0   \n",
              "\n",
              "   pixel405  pixel406  pixel407  pixel408  pixel409  pixel410  pixel411  \\\n",
              "0       254       254       198         7         0         0         0   \n",
              "1         0         0         0         0         0         0        75   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0        94       255   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel412  pixel413  pixel414  pixel415  pixel416  pixel417  pixel418  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254        17         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3        69         0         0         0         0         0         0   \n",
              "4       223       253       253       253       129         0         0   \n",
              "\n",
              "   pixel419  pixel420  pixel421  pixel422  pixel423  pixel424  pixel425  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0        18       254   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel426  pixel427  pixel428  pixel429  pixel430  pixel431  pixel432  \\\n",
              "0         0         0         0         0         0       168       253   \n",
              "1       254       254       254        29         0         0         0   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0         0         0       234       184         0         0   \n",
              "4       253       253       253        99         0         0         0   \n",
              "\n",
              "   pixel433  pixel434  pixel435  pixel436  pixel437  pixel438  pixel439  \\\n",
              "0       253       196         7         0         0         0         0   \n",
              "1         0         0         0         0         0         0        48   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0        19       245   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel440  pixel441  pixel442  pixel443  pixel444  pixel445  pixel446  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254        17         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3        69         0         0         0         0         0         0   \n",
              "4       127       253       253       253       129         0         0   \n",
              "\n",
              "   pixel447  pixel448  pixel449  pixel450  pixel451  pixel452  pixel453  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         2       163   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel454  pixel455  pixel456  pixel457  pixel458  pixel459  pixel460  \\\n",
              "0         0         0         0         0        20       203       253   \n",
              "1       254       254       254        29         0         0         0   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0         0         0       234       169         0         0   \n",
              "4       253       253       253        99         0         0         0   \n",
              "\n",
              "   pixel461  pixel462  pixel463  pixel464  pixel465  pixel466  pixel467  \\\n",
              "0       248        76         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0        48   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0         3       199   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel468  pixel469  pixel470  pixel471  pixel472  pixel473  pixel474  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254        17         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       182        10         0         0         0         0         0   \n",
              "4       139       253       253       253        90         0         0   \n",
              "\n",
              "   pixel475  pixel476  pixel477  pixel478  pixel479  pixel480  pixel481  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0        94   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel482  pixel483  pixel484  pixel485  pixel486  pixel487  pixel488  \\\n",
              "0         0         0         0        22       188       253       245   \n",
              "1       254       254       254       200        12         0         0   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0         0         0       154       205         4         0   \n",
              "4       253       253       253        99         0         0         0   \n",
              "\n",
              "   pixel489  pixel490  pixel491  pixel492  pixel493  pixel494  pixel495  \\\n",
              "0        93         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0        16       209   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0        26        72       128       203       208       254   \n",
              "4         0         0         0         0         0         0        78   \n",
              "\n",
              "   pixel496  pixel497  pixel498  pixel499  pixel500  pixel501  pixel502  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       150         1         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       254       131         0         0         0         0         0   \n",
              "4       248       253       253       253         5         0         0   \n",
              "\n",
              "   pixel503  pixel504  pixel505  pixel506  pixel507  pixel508  pixel509  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0        15   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       254   \n",
              "\n",
              "   pixel510  pixel511  pixel512  pixel513  pixel514  pixel515  pixel516  \\\n",
              "0         0         0         0       103       253       253       191   \n",
              "1       206       254       254       254       202        66         0   \n",
              "2         0         0         0         0         0         0         9   \n",
              "3         0         0         0        61       254       129       113   \n",
              "4       253       253       253       216        34         0         0   \n",
              "\n",
              "   pixel517  pixel518  pixel519  pixel520  pixel521  pixel522  pixel523  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0        21       161       254   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3       186       245       251       189        75        56       136   \n",
              "4         0         0         0         0         0        33       152   \n",
              "\n",
              "   pixel524  pixel525  pixel526  pixel527  pixel528  pixel529  pixel530  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       245        31         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       254        73         0         0         0         0         0   \n",
              "4       253       253       253       107         1         0         0   \n",
              "\n",
              "   pixel531  pixel532  pixel533  pixel534  pixel535  pixel536  pixel537  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0       206   \n",
              "\n",
              "   pixel538  pixel539  pixel540  pixel541  pixel542  pixel543  pixel544  \\\n",
              "0         0         0        89       240       253       195        25   \n",
              "1        60       212       254       254       254       194        48   \n",
              "2         0         0         0         0         0         0       156   \n",
              "3         0         0         0        15       216       233       233   \n",
              "4       253       253       253       253       140         0         0   \n",
              "\n",
              "   pixel545  pixel546  pixel547  pixel548  pixel549  pixel550  pixel551  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1        48        34        41        48       209       254       254   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3       159       104        52         0         0         0        38   \n",
              "4         0         0         0        30       139       234       253   \n",
              "\n",
              "   pixel552  pixel553  pixel554  pixel555  pixel556  pixel557  pixel558  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       171         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       254        73         0         0         0         0         0   \n",
              "4       253       253       154         2         0         0         0   \n",
              "\n",
              "   pixel559  pixel560  pixel561  pixel562  pixel563  pixel564  pixel565  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0        16   \n",
              "\n",
              "   pixel566  pixel567  pixel568  pixel569  pixel570  pixel571  pixel572  \\\n",
              "0         0        15       220       253       253        80         0   \n",
              "1         0        86       243       254       254       254       254   \n",
              "2         0         0         0         0         0         0       185   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       205       253       253       253       250       208       106   \n",
              "\n",
              "   pixel573  pixel574  pixel575  pixel576  pixel577  pixel578  pixel579  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       233       243       254       254       254       254   \n",
              "2       255       255       184         0         0         0         0   \n",
              "3         0         0         0         0         0         0        18   \n",
              "4       106       106       200       237       253       253       253   \n",
              "\n",
              "   pixel580  pixel581  pixel582  pixel583  pixel584  pixel585  pixel586  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254        86         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       254        73         0         0         0         0         0   \n",
              "4       253       209        22         0         0         0         0   \n",
              "\n",
              "   pixel587  pixel588  pixel589  pixel590  pixel591  pixel592  pixel593  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel594  pixel595  pixel596  pixel597  pixel598  pixel599  pixel600  \\\n",
              "0         0        94       253       253       253        94         0   \n",
              "1         0         0       114       254       254       254       254   \n",
              "2         0         0         0         0         0         0       185   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4        82       253       253       253       253       253       253   \n",
              "\n",
              "   pixel601  pixel602  pixel603  pixel604  pixel605  pixel606  pixel607  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254       254       254       254       239   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0         0        18   \n",
              "4       253       253       253       253       253       253       253   \n",
              "\n",
              "   pixel608  pixel609  pixel610  pixel611  pixel612  pixel613  pixel614  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1        86        11         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       254        73         0         0         0         0         0   \n",
              "4       209        22         0         0         0         0         0   \n",
              "\n",
              "   pixel615  pixel616  pixel617  pixel618  pixel619  pixel620  pixel621  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel622  pixel623  pixel624  pixel625  pixel626  pixel627  pixel628  \\\n",
              "0         0        89       251       253       250       131         0   \n",
              "1         0         0        13       182       254       254       254   \n",
              "2         0         0         0         0         0         0       185   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         1        91       253       253       253       253       253   \n",
              "\n",
              "   pixel629  pixel630  pixel631  pixel632  pixel633  pixel634  pixel635  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       254       254       254       254       254       243        70   \n",
              "2       254       254       184         0         0         0         0   \n",
              "3         0         0         0         0         0         0         5   \n",
              "4       253       253       253       253       253       213        90   \n",
              "\n",
              "   pixel636  pixel637  pixel638  pixel639  pixel640  pixel641  pixel642  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       206       106         0         0         0         0         0   \n",
              "4         7         0         0         0         0         0         0   \n",
              "\n",
              "   pixel643  pixel644  pixel645  pixel646  pixel647  pixel648  pixel649  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel650  pixel651  pixel652  pixel653  pixel654  pixel655  pixel656  \\\n",
              "0         0         0       214       218        95         0         0   \n",
              "1         0         0         0         8        76       146       254   \n",
              "2         0         0         0         0         0         0        63   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         1        18       129       208       253       253   \n",
              "\n",
              "   pixel657  pixel658  pixel659  pixel660  pixel661  pixel662  pixel663  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1       255       254       255       146        19        15         0   \n",
              "2       254       254        62         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4       253       253       159       129        90         4         0   \n",
              "\n",
              "   pixel664  pixel665  pixel666  pixel667  pixel668  pixel669  pixel670  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       186       159         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel671  pixel672  pixel673  pixel674  pixel675  pixel676  pixel677  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel678  pixel679  pixel680  pixel681  pixel682  pixel683  pixel684  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel685  pixel686  pixel687  pixel688  pixel689  pixel690  pixel691  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         6   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel692  pixel693  pixel694  pixel695  pixel696  pixel697  pixel698  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3       209       101         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel699  pixel700  pixel701  pixel702  pixel703  pixel704  pixel705  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel706  pixel707  pixel708  pixel709  pixel710  pixel711  pixel712  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel713  pixel714  pixel715  pixel716  pixel717  pixel718  pixel719  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel720  pixel721  pixel722  pixel723  pixel724  pixel725  pixel726  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel727  pixel728  pixel729  pixel730  pixel731  pixel732  pixel733  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel734  pixel735  pixel736  pixel737  pixel738  pixel739  pixel740  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel741  pixel742  pixel743  pixel744  pixel745  pixel746  pixel747  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel748  pixel749  pixel750  pixel751  pixel752  pixel753  pixel754  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel755  pixel756  pixel757  pixel758  pixel759  pixel760  pixel761  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel762  pixel763  pixel764  pixel765  pixel766  pixel767  pixel768  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel769  pixel770  pixel771  pixel772  pixel773  pixel774  pixel775  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  pixel782  \\\n",
              "0         0         0         0         0         0         0         0   \n",
              "1         0         0         0         0         0         0         0   \n",
              "2         0         0         0         0         0         0         0   \n",
              "3         0         0         0         0         0         0         0   \n",
              "4         0         0         0         0         0         0         0   \n",
              "\n",
              "   pixel783  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-843d9822-deb6-4389-9ffb-218883e7ed33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>pixel40</th>\n",
              "      <th>pixel41</th>\n",
              "      <th>pixel42</th>\n",
              "      <th>pixel43</th>\n",
              "      <th>pixel44</th>\n",
              "      <th>pixel45</th>\n",
              "      <th>pixel46</th>\n",
              "      <th>pixel47</th>\n",
              "      <th>pixel48</th>\n",
              "      <th>pixel49</th>\n",
              "      <th>pixel50</th>\n",
              "      <th>pixel51</th>\n",
              "      <th>pixel52</th>\n",
              "      <th>pixel53</th>\n",
              "      <th>pixel54</th>\n",
              "      <th>pixel55</th>\n",
              "      <th>pixel56</th>\n",
              "      <th>pixel57</th>\n",
              "      <th>pixel58</th>\n",
              "      <th>pixel59</th>\n",
              "      <th>pixel60</th>\n",
              "      <th>pixel61</th>\n",
              "      <th>pixel62</th>\n",
              "      <th>pixel63</th>\n",
              "      <th>pixel64</th>\n",
              "      <th>pixel65</th>\n",
              "      <th>pixel66</th>\n",
              "      <th>pixel67</th>\n",
              "      <th>pixel68</th>\n",
              "      <th>pixel69</th>\n",
              "      <th>pixel70</th>\n",
              "      <th>pixel71</th>\n",
              "      <th>pixel72</th>\n",
              "      <th>pixel73</th>\n",
              "      <th>pixel74</th>\n",
              "      <th>pixel75</th>\n",
              "      <th>pixel76</th>\n",
              "      <th>pixel77</th>\n",
              "      <th>pixel78</th>\n",
              "      <th>pixel79</th>\n",
              "      <th>pixel80</th>\n",
              "      <th>pixel81</th>\n",
              "      <th>pixel82</th>\n",
              "      <th>pixel83</th>\n",
              "      <th>pixel84</th>\n",
              "      <th>pixel85</th>\n",
              "      <th>pixel86</th>\n",
              "      <th>pixel87</th>\n",
              "      <th>pixel88</th>\n",
              "      <th>pixel89</th>\n",
              "      <th>pixel90</th>\n",
              "      <th>pixel91</th>\n",
              "      <th>pixel92</th>\n",
              "      <th>pixel93</th>\n",
              "      <th>pixel94</th>\n",
              "      <th>pixel95</th>\n",
              "      <th>pixel96</th>\n",
              "      <th>pixel97</th>\n",
              "      <th>pixel98</th>\n",
              "      <th>pixel99</th>\n",
              "      <th>pixel100</th>\n",
              "      <th>pixel101</th>\n",
              "      <th>pixel102</th>\n",
              "      <th>pixel103</th>\n",
              "      <th>pixel104</th>\n",
              "      <th>pixel105</th>\n",
              "      <th>pixel106</th>\n",
              "      <th>pixel107</th>\n",
              "      <th>pixel108</th>\n",
              "      <th>pixel109</th>\n",
              "      <th>pixel110</th>\n",
              "      <th>pixel111</th>\n",
              "      <th>pixel112</th>\n",
              "      <th>pixel113</th>\n",
              "      <th>pixel114</th>\n",
              "      <th>pixel115</th>\n",
              "      <th>pixel116</th>\n",
              "      <th>pixel117</th>\n",
              "      <th>pixel118</th>\n",
              "      <th>pixel119</th>\n",
              "      <th>pixel120</th>\n",
              "      <th>pixel121</th>\n",
              "      <th>pixel122</th>\n",
              "      <th>pixel123</th>\n",
              "      <th>pixel124</th>\n",
              "      <th>pixel125</th>\n",
              "      <th>pixel126</th>\n",
              "      <th>pixel127</th>\n",
              "      <th>pixel128</th>\n",
              "      <th>pixel129</th>\n",
              "      <th>pixel130</th>\n",
              "      <th>pixel131</th>\n",
              "      <th>pixel132</th>\n",
              "      <th>pixel133</th>\n",
              "      <th>pixel134</th>\n",
              "      <th>pixel135</th>\n",
              "      <th>pixel136</th>\n",
              "      <th>pixel137</th>\n",
              "      <th>pixel138</th>\n",
              "      <th>pixel139</th>\n",
              "      <th>pixel140</th>\n",
              "      <th>pixel141</th>\n",
              "      <th>pixel142</th>\n",
              "      <th>pixel143</th>\n",
              "      <th>pixel144</th>\n",
              "      <th>pixel145</th>\n",
              "      <th>pixel146</th>\n",
              "      <th>pixel147</th>\n",
              "      <th>pixel148</th>\n",
              "      <th>pixel149</th>\n",
              "      <th>pixel150</th>\n",
              "      <th>pixel151</th>\n",
              "      <th>pixel152</th>\n",
              "      <th>pixel153</th>\n",
              "      <th>pixel154</th>\n",
              "      <th>pixel155</th>\n",
              "      <th>pixel156</th>\n",
              "      <th>pixel157</th>\n",
              "      <th>pixel158</th>\n",
              "      <th>pixel159</th>\n",
              "      <th>pixel160</th>\n",
              "      <th>pixel161</th>\n",
              "      <th>pixel162</th>\n",
              "      <th>pixel163</th>\n",
              "      <th>pixel164</th>\n",
              "      <th>pixel165</th>\n",
              "      <th>pixel166</th>\n",
              "      <th>pixel167</th>\n",
              "      <th>pixel168</th>\n",
              "      <th>pixel169</th>\n",
              "      <th>pixel170</th>\n",
              "      <th>pixel171</th>\n",
              "      <th>pixel172</th>\n",
              "      <th>pixel173</th>\n",
              "      <th>pixel174</th>\n",
              "      <th>pixel175</th>\n",
              "      <th>pixel176</th>\n",
              "      <th>pixel177</th>\n",
              "      <th>pixel178</th>\n",
              "      <th>pixel179</th>\n",
              "      <th>pixel180</th>\n",
              "      <th>pixel181</th>\n",
              "      <th>pixel182</th>\n",
              "      <th>pixel183</th>\n",
              "      <th>pixel184</th>\n",
              "      <th>pixel185</th>\n",
              "      <th>pixel186</th>\n",
              "      <th>pixel187</th>\n",
              "      <th>pixel188</th>\n",
              "      <th>pixel189</th>\n",
              "      <th>pixel190</th>\n",
              "      <th>pixel191</th>\n",
              "      <th>pixel192</th>\n",
              "      <th>pixel193</th>\n",
              "      <th>pixel194</th>\n",
              "      <th>pixel195</th>\n",
              "      <th>pixel196</th>\n",
              "      <th>pixel197</th>\n",
              "      <th>pixel198</th>\n",
              "      <th>pixel199</th>\n",
              "      <th>pixel200</th>\n",
              "      <th>pixel201</th>\n",
              "      <th>pixel202</th>\n",
              "      <th>pixel203</th>\n",
              "      <th>pixel204</th>\n",
              "      <th>pixel205</th>\n",
              "      <th>pixel206</th>\n",
              "      <th>pixel207</th>\n",
              "      <th>pixel208</th>\n",
              "      <th>pixel209</th>\n",
              "      <th>pixel210</th>\n",
              "      <th>pixel211</th>\n",
              "      <th>pixel212</th>\n",
              "      <th>pixel213</th>\n",
              "      <th>pixel214</th>\n",
              "      <th>pixel215</th>\n",
              "      <th>pixel216</th>\n",
              "      <th>pixel217</th>\n",
              "      <th>pixel218</th>\n",
              "      <th>pixel219</th>\n",
              "      <th>pixel220</th>\n",
              "      <th>pixel221</th>\n",
              "      <th>pixel222</th>\n",
              "      <th>pixel223</th>\n",
              "      <th>pixel224</th>\n",
              "      <th>pixel225</th>\n",
              "      <th>pixel226</th>\n",
              "      <th>pixel227</th>\n",
              "      <th>pixel228</th>\n",
              "      <th>pixel229</th>\n",
              "      <th>pixel230</th>\n",
              "      <th>pixel231</th>\n",
              "      <th>pixel232</th>\n",
              "      <th>pixel233</th>\n",
              "      <th>pixel234</th>\n",
              "      <th>pixel235</th>\n",
              "      <th>pixel236</th>\n",
              "      <th>pixel237</th>\n",
              "      <th>pixel238</th>\n",
              "      <th>pixel239</th>\n",
              "      <th>pixel240</th>\n",
              "      <th>pixel241</th>\n",
              "      <th>pixel242</th>\n",
              "      <th>pixel243</th>\n",
              "      <th>pixel244</th>\n",
              "      <th>pixel245</th>\n",
              "      <th>pixel246</th>\n",
              "      <th>pixel247</th>\n",
              "      <th>pixel248</th>\n",
              "      <th>pixel249</th>\n",
              "      <th>pixel250</th>\n",
              "      <th>pixel251</th>\n",
              "      <th>pixel252</th>\n",
              "      <th>pixel253</th>\n",
              "      <th>pixel254</th>\n",
              "      <th>pixel255</th>\n",
              "      <th>pixel256</th>\n",
              "      <th>pixel257</th>\n",
              "      <th>pixel258</th>\n",
              "      <th>pixel259</th>\n",
              "      <th>pixel260</th>\n",
              "      <th>pixel261</th>\n",
              "      <th>pixel262</th>\n",
              "      <th>pixel263</th>\n",
              "      <th>pixel264</th>\n",
              "      <th>pixel265</th>\n",
              "      <th>pixel266</th>\n",
              "      <th>pixel267</th>\n",
              "      <th>pixel268</th>\n",
              "      <th>pixel269</th>\n",
              "      <th>pixel270</th>\n",
              "      <th>pixel271</th>\n",
              "      <th>pixel272</th>\n",
              "      <th>pixel273</th>\n",
              "      <th>pixel274</th>\n",
              "      <th>pixel275</th>\n",
              "      <th>pixel276</th>\n",
              "      <th>pixel277</th>\n",
              "      <th>pixel278</th>\n",
              "      <th>pixel279</th>\n",
              "      <th>pixel280</th>\n",
              "      <th>pixel281</th>\n",
              "      <th>pixel282</th>\n",
              "      <th>pixel283</th>\n",
              "      <th>pixel284</th>\n",
              "      <th>pixel285</th>\n",
              "      <th>pixel286</th>\n",
              "      <th>pixel287</th>\n",
              "      <th>pixel288</th>\n",
              "      <th>pixel289</th>\n",
              "      <th>pixel290</th>\n",
              "      <th>pixel291</th>\n",
              "      <th>pixel292</th>\n",
              "      <th>pixel293</th>\n",
              "      <th>pixel294</th>\n",
              "      <th>pixel295</th>\n",
              "      <th>pixel296</th>\n",
              "      <th>pixel297</th>\n",
              "      <th>pixel298</th>\n",
              "      <th>pixel299</th>\n",
              "      <th>pixel300</th>\n",
              "      <th>pixel301</th>\n",
              "      <th>pixel302</th>\n",
              "      <th>pixel303</th>\n",
              "      <th>pixel304</th>\n",
              "      <th>pixel305</th>\n",
              "      <th>pixel306</th>\n",
              "      <th>pixel307</th>\n",
              "      <th>pixel308</th>\n",
              "      <th>pixel309</th>\n",
              "      <th>pixel310</th>\n",
              "      <th>pixel311</th>\n",
              "      <th>pixel312</th>\n",
              "      <th>pixel313</th>\n",
              "      <th>pixel314</th>\n",
              "      <th>pixel315</th>\n",
              "      <th>pixel316</th>\n",
              "      <th>pixel317</th>\n",
              "      <th>pixel318</th>\n",
              "      <th>pixel319</th>\n",
              "      <th>pixel320</th>\n",
              "      <th>pixel321</th>\n",
              "      <th>pixel322</th>\n",
              "      <th>pixel323</th>\n",
              "      <th>pixel324</th>\n",
              "      <th>pixel325</th>\n",
              "      <th>pixel326</th>\n",
              "      <th>pixel327</th>\n",
              "      <th>pixel328</th>\n",
              "      <th>pixel329</th>\n",
              "      <th>pixel330</th>\n",
              "      <th>pixel331</th>\n",
              "      <th>pixel332</th>\n",
              "      <th>pixel333</th>\n",
              "      <th>pixel334</th>\n",
              "      <th>pixel335</th>\n",
              "      <th>pixel336</th>\n",
              "      <th>pixel337</th>\n",
              "      <th>pixel338</th>\n",
              "      <th>pixel339</th>\n",
              "      <th>pixel340</th>\n",
              "      <th>pixel341</th>\n",
              "      <th>pixel342</th>\n",
              "      <th>pixel343</th>\n",
              "      <th>pixel344</th>\n",
              "      <th>pixel345</th>\n",
              "      <th>pixel346</th>\n",
              "      <th>pixel347</th>\n",
              "      <th>pixel348</th>\n",
              "      <th>pixel349</th>\n",
              "      <th>pixel350</th>\n",
              "      <th>pixel351</th>\n",
              "      <th>pixel352</th>\n",
              "      <th>pixel353</th>\n",
              "      <th>pixel354</th>\n",
              "      <th>pixel355</th>\n",
              "      <th>pixel356</th>\n",
              "      <th>pixel357</th>\n",
              "      <th>pixel358</th>\n",
              "      <th>pixel359</th>\n",
              "      <th>pixel360</th>\n",
              "      <th>pixel361</th>\n",
              "      <th>pixel362</th>\n",
              "      <th>pixel363</th>\n",
              "      <th>pixel364</th>\n",
              "      <th>pixel365</th>\n",
              "      <th>pixel366</th>\n",
              "      <th>pixel367</th>\n",
              "      <th>pixel368</th>\n",
              "      <th>pixel369</th>\n",
              "      <th>pixel370</th>\n",
              "      <th>pixel371</th>\n",
              "      <th>pixel372</th>\n",
              "      <th>pixel373</th>\n",
              "      <th>pixel374</th>\n",
              "      <th>pixel375</th>\n",
              "      <th>pixel376</th>\n",
              "      <th>pixel377</th>\n",
              "      <th>pixel378</th>\n",
              "      <th>pixel379</th>\n",
              "      <th>pixel380</th>\n",
              "      <th>pixel381</th>\n",
              "      <th>pixel382</th>\n",
              "      <th>pixel383</th>\n",
              "      <th>pixel384</th>\n",
              "      <th>pixel385</th>\n",
              "      <th>pixel386</th>\n",
              "      <th>pixel387</th>\n",
              "      <th>pixel388</th>\n",
              "      <th>pixel389</th>\n",
              "      <th>pixel390</th>\n",
              "      <th>pixel391</th>\n",
              "      <th>pixel392</th>\n",
              "      <th>pixel393</th>\n",
              "      <th>pixel394</th>\n",
              "      <th>pixel395</th>\n",
              "      <th>pixel396</th>\n",
              "      <th>pixel397</th>\n",
              "      <th>pixel398</th>\n",
              "      <th>pixel399</th>\n",
              "      <th>pixel400</th>\n",
              "      <th>pixel401</th>\n",
              "      <th>pixel402</th>\n",
              "      <th>pixel403</th>\n",
              "      <th>pixel404</th>\n",
              "      <th>pixel405</th>\n",
              "      <th>pixel406</th>\n",
              "      <th>pixel407</th>\n",
              "      <th>pixel408</th>\n",
              "      <th>pixel409</th>\n",
              "      <th>pixel410</th>\n",
              "      <th>pixel411</th>\n",
              "      <th>pixel412</th>\n",
              "      <th>pixel413</th>\n",
              "      <th>pixel414</th>\n",
              "      <th>pixel415</th>\n",
              "      <th>pixel416</th>\n",
              "      <th>pixel417</th>\n",
              "      <th>pixel418</th>\n",
              "      <th>pixel419</th>\n",
              "      <th>pixel420</th>\n",
              "      <th>pixel421</th>\n",
              "      <th>pixel422</th>\n",
              "      <th>pixel423</th>\n",
              "      <th>pixel424</th>\n",
              "      <th>pixel425</th>\n",
              "      <th>pixel426</th>\n",
              "      <th>pixel427</th>\n",
              "      <th>pixel428</th>\n",
              "      <th>pixel429</th>\n",
              "      <th>pixel430</th>\n",
              "      <th>pixel431</th>\n",
              "      <th>pixel432</th>\n",
              "      <th>pixel433</th>\n",
              "      <th>pixel434</th>\n",
              "      <th>pixel435</th>\n",
              "      <th>pixel436</th>\n",
              "      <th>pixel437</th>\n",
              "      <th>pixel438</th>\n",
              "      <th>pixel439</th>\n",
              "      <th>pixel440</th>\n",
              "      <th>pixel441</th>\n",
              "      <th>pixel442</th>\n",
              "      <th>pixel443</th>\n",
              "      <th>pixel444</th>\n",
              "      <th>pixel445</th>\n",
              "      <th>pixel446</th>\n",
              "      <th>pixel447</th>\n",
              "      <th>pixel448</th>\n",
              "      <th>pixel449</th>\n",
              "      <th>pixel450</th>\n",
              "      <th>pixel451</th>\n",
              "      <th>pixel452</th>\n",
              "      <th>pixel453</th>\n",
              "      <th>pixel454</th>\n",
              "      <th>pixel455</th>\n",
              "      <th>pixel456</th>\n",
              "      <th>pixel457</th>\n",
              "      <th>pixel458</th>\n",
              "      <th>pixel459</th>\n",
              "      <th>pixel460</th>\n",
              "      <th>pixel461</th>\n",
              "      <th>pixel462</th>\n",
              "      <th>pixel463</th>\n",
              "      <th>pixel464</th>\n",
              "      <th>pixel465</th>\n",
              "      <th>pixel466</th>\n",
              "      <th>pixel467</th>\n",
              "      <th>pixel468</th>\n",
              "      <th>pixel469</th>\n",
              "      <th>pixel470</th>\n",
              "      <th>pixel471</th>\n",
              "      <th>pixel472</th>\n",
              "      <th>pixel473</th>\n",
              "      <th>pixel474</th>\n",
              "      <th>pixel475</th>\n",
              "      <th>pixel476</th>\n",
              "      <th>pixel477</th>\n",
              "      <th>pixel478</th>\n",
              "      <th>pixel479</th>\n",
              "      <th>pixel480</th>\n",
              "      <th>pixel481</th>\n",
              "      <th>pixel482</th>\n",
              "      <th>pixel483</th>\n",
              "      <th>pixel484</th>\n",
              "      <th>pixel485</th>\n",
              "      <th>pixel486</th>\n",
              "      <th>pixel487</th>\n",
              "      <th>pixel488</th>\n",
              "      <th>pixel489</th>\n",
              "      <th>pixel490</th>\n",
              "      <th>pixel491</th>\n",
              "      <th>pixel492</th>\n",
              "      <th>pixel493</th>\n",
              "      <th>pixel494</th>\n",
              "      <th>pixel495</th>\n",
              "      <th>pixel496</th>\n",
              "      <th>pixel497</th>\n",
              "      <th>pixel498</th>\n",
              "      <th>pixel499</th>\n",
              "      <th>pixel500</th>\n",
              "      <th>pixel501</th>\n",
              "      <th>pixel502</th>\n",
              "      <th>pixel503</th>\n",
              "      <th>pixel504</th>\n",
              "      <th>pixel505</th>\n",
              "      <th>pixel506</th>\n",
              "      <th>pixel507</th>\n",
              "      <th>pixel508</th>\n",
              "      <th>pixel509</th>\n",
              "      <th>pixel510</th>\n",
              "      <th>pixel511</th>\n",
              "      <th>pixel512</th>\n",
              "      <th>pixel513</th>\n",
              "      <th>pixel514</th>\n",
              "      <th>pixel515</th>\n",
              "      <th>pixel516</th>\n",
              "      <th>pixel517</th>\n",
              "      <th>pixel518</th>\n",
              "      <th>pixel519</th>\n",
              "      <th>pixel520</th>\n",
              "      <th>pixel521</th>\n",
              "      <th>pixel522</th>\n",
              "      <th>pixel523</th>\n",
              "      <th>pixel524</th>\n",
              "      <th>pixel525</th>\n",
              "      <th>pixel526</th>\n",
              "      <th>pixel527</th>\n",
              "      <th>pixel528</th>\n",
              "      <th>pixel529</th>\n",
              "      <th>pixel530</th>\n",
              "      <th>pixel531</th>\n",
              "      <th>pixel532</th>\n",
              "      <th>pixel533</th>\n",
              "      <th>pixel534</th>\n",
              "      <th>pixel535</th>\n",
              "      <th>pixel536</th>\n",
              "      <th>pixel537</th>\n",
              "      <th>pixel538</th>\n",
              "      <th>pixel539</th>\n",
              "      <th>pixel540</th>\n",
              "      <th>pixel541</th>\n",
              "      <th>pixel542</th>\n",
              "      <th>pixel543</th>\n",
              "      <th>pixel544</th>\n",
              "      <th>pixel545</th>\n",
              "      <th>pixel546</th>\n",
              "      <th>pixel547</th>\n",
              "      <th>pixel548</th>\n",
              "      <th>pixel549</th>\n",
              "      <th>pixel550</th>\n",
              "      <th>pixel551</th>\n",
              "      <th>pixel552</th>\n",
              "      <th>pixel553</th>\n",
              "      <th>pixel554</th>\n",
              "      <th>pixel555</th>\n",
              "      <th>pixel556</th>\n",
              "      <th>pixel557</th>\n",
              "      <th>pixel558</th>\n",
              "      <th>pixel559</th>\n",
              "      <th>pixel560</th>\n",
              "      <th>pixel561</th>\n",
              "      <th>pixel562</th>\n",
              "      <th>pixel563</th>\n",
              "      <th>pixel564</th>\n",
              "      <th>pixel565</th>\n",
              "      <th>pixel566</th>\n",
              "      <th>pixel567</th>\n",
              "      <th>pixel568</th>\n",
              "      <th>pixel569</th>\n",
              "      <th>pixel570</th>\n",
              "      <th>pixel571</th>\n",
              "      <th>pixel572</th>\n",
              "      <th>pixel573</th>\n",
              "      <th>pixel574</th>\n",
              "      <th>pixel575</th>\n",
              "      <th>pixel576</th>\n",
              "      <th>pixel577</th>\n",
              "      <th>pixel578</th>\n",
              "      <th>pixel579</th>\n",
              "      <th>pixel580</th>\n",
              "      <th>pixel581</th>\n",
              "      <th>pixel582</th>\n",
              "      <th>pixel583</th>\n",
              "      <th>pixel584</th>\n",
              "      <th>pixel585</th>\n",
              "      <th>pixel586</th>\n",
              "      <th>pixel587</th>\n",
              "      <th>pixel588</th>\n",
              "      <th>pixel589</th>\n",
              "      <th>pixel590</th>\n",
              "      <th>pixel591</th>\n",
              "      <th>pixel592</th>\n",
              "      <th>pixel593</th>\n",
              "      <th>pixel594</th>\n",
              "      <th>pixel595</th>\n",
              "      <th>pixel596</th>\n",
              "      <th>pixel597</th>\n",
              "      <th>pixel598</th>\n",
              "      <th>pixel599</th>\n",
              "      <th>pixel600</th>\n",
              "      <th>pixel601</th>\n",
              "      <th>pixel602</th>\n",
              "      <th>pixel603</th>\n",
              "      <th>pixel604</th>\n",
              "      <th>pixel605</th>\n",
              "      <th>pixel606</th>\n",
              "      <th>pixel607</th>\n",
              "      <th>pixel608</th>\n",
              "      <th>pixel609</th>\n",
              "      <th>pixel610</th>\n",
              "      <th>pixel611</th>\n",
              "      <th>pixel612</th>\n",
              "      <th>pixel613</th>\n",
              "      <th>pixel614</th>\n",
              "      <th>pixel615</th>\n",
              "      <th>pixel616</th>\n",
              "      <th>pixel617</th>\n",
              "      <th>pixel618</th>\n",
              "      <th>pixel619</th>\n",
              "      <th>pixel620</th>\n",
              "      <th>pixel621</th>\n",
              "      <th>pixel622</th>\n",
              "      <th>pixel623</th>\n",
              "      <th>pixel624</th>\n",
              "      <th>pixel625</th>\n",
              "      <th>pixel626</th>\n",
              "      <th>pixel627</th>\n",
              "      <th>pixel628</th>\n",
              "      <th>pixel629</th>\n",
              "      <th>pixel630</th>\n",
              "      <th>pixel631</th>\n",
              "      <th>pixel632</th>\n",
              "      <th>pixel633</th>\n",
              "      <th>pixel634</th>\n",
              "      <th>pixel635</th>\n",
              "      <th>pixel636</th>\n",
              "      <th>pixel637</th>\n",
              "      <th>pixel638</th>\n",
              "      <th>pixel639</th>\n",
              "      <th>pixel640</th>\n",
              "      <th>pixel641</th>\n",
              "      <th>pixel642</th>\n",
              "      <th>pixel643</th>\n",
              "      <th>pixel644</th>\n",
              "      <th>pixel645</th>\n",
              "      <th>pixel646</th>\n",
              "      <th>pixel647</th>\n",
              "      <th>pixel648</th>\n",
              "      <th>pixel649</th>\n",
              "      <th>pixel650</th>\n",
              "      <th>pixel651</th>\n",
              "      <th>pixel652</th>\n",
              "      <th>pixel653</th>\n",
              "      <th>pixel654</th>\n",
              "      <th>pixel655</th>\n",
              "      <th>pixel656</th>\n",
              "      <th>pixel657</th>\n",
              "      <th>pixel658</th>\n",
              "      <th>pixel659</th>\n",
              "      <th>pixel660</th>\n",
              "      <th>pixel661</th>\n",
              "      <th>pixel662</th>\n",
              "      <th>pixel663</th>\n",
              "      <th>pixel664</th>\n",
              "      <th>pixel665</th>\n",
              "      <th>pixel666</th>\n",
              "      <th>pixel667</th>\n",
              "      <th>pixel668</th>\n",
              "      <th>pixel669</th>\n",
              "      <th>pixel670</th>\n",
              "      <th>pixel671</th>\n",
              "      <th>pixel672</th>\n",
              "      <th>pixel673</th>\n",
              "      <th>pixel674</th>\n",
              "      <th>pixel675</th>\n",
              "      <th>pixel676</th>\n",
              "      <th>pixel677</th>\n",
              "      <th>pixel678</th>\n",
              "      <th>pixel679</th>\n",
              "      <th>pixel680</th>\n",
              "      <th>pixel681</th>\n",
              "      <th>pixel682</th>\n",
              "      <th>pixel683</th>\n",
              "      <th>pixel684</th>\n",
              "      <th>pixel685</th>\n",
              "      <th>pixel686</th>\n",
              "      <th>pixel687</th>\n",
              "      <th>pixel688</th>\n",
              "      <th>pixel689</th>\n",
              "      <th>pixel690</th>\n",
              "      <th>pixel691</th>\n",
              "      <th>pixel692</th>\n",
              "      <th>pixel693</th>\n",
              "      <th>pixel694</th>\n",
              "      <th>pixel695</th>\n",
              "      <th>pixel696</th>\n",
              "      <th>pixel697</th>\n",
              "      <th>pixel698</th>\n",
              "      <th>pixel699</th>\n",
              "      <th>pixel700</th>\n",
              "      <th>pixel701</th>\n",
              "      <th>pixel702</th>\n",
              "      <th>pixel703</th>\n",
              "      <th>pixel704</th>\n",
              "      <th>pixel705</th>\n",
              "      <th>pixel706</th>\n",
              "      <th>pixel707</th>\n",
              "      <th>pixel708</th>\n",
              "      <th>pixel709</th>\n",
              "      <th>pixel710</th>\n",
              "      <th>pixel711</th>\n",
              "      <th>pixel712</th>\n",
              "      <th>pixel713</th>\n",
              "      <th>pixel714</th>\n",
              "      <th>pixel715</th>\n",
              "      <th>pixel716</th>\n",
              "      <th>pixel717</th>\n",
              "      <th>pixel718</th>\n",
              "      <th>pixel719</th>\n",
              "      <th>pixel720</th>\n",
              "      <th>pixel721</th>\n",
              "      <th>pixel722</th>\n",
              "      <th>pixel723</th>\n",
              "      <th>pixel724</th>\n",
              "      <th>pixel725</th>\n",
              "      <th>pixel726</th>\n",
              "      <th>pixel727</th>\n",
              "      <th>pixel728</th>\n",
              "      <th>pixel729</th>\n",
              "      <th>pixel730</th>\n",
              "      <th>pixel731</th>\n",
              "      <th>pixel732</th>\n",
              "      <th>pixel733</th>\n",
              "      <th>pixel734</th>\n",
              "      <th>pixel735</th>\n",
              "      <th>pixel736</th>\n",
              "      <th>pixel737</th>\n",
              "      <th>pixel738</th>\n",
              "      <th>pixel739</th>\n",
              "      <th>pixel740</th>\n",
              "      <th>pixel741</th>\n",
              "      <th>pixel742</th>\n",
              "      <th>pixel743</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>188</td>\n",
              "      <td>255</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>191</td>\n",
              "      <td>250</td>\n",
              "      <td>253</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>248</td>\n",
              "      <td>253</td>\n",
              "      <td>167</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>247</td>\n",
              "      <td>253</td>\n",
              "      <td>208</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>207</td>\n",
              "      <td>253</td>\n",
              "      <td>235</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>209</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>238</td>\n",
              "      <td>170</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>210</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>209</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>240</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>206</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>198</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>196</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>203</td>\n",
              "      <td>253</td>\n",
              "      <td>248</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>188</td>\n",
              "      <td>253</td>\n",
              "      <td>245</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>191</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>240</td>\n",
              "      <td>253</td>\n",
              "      <td>195</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>220</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>251</td>\n",
              "      <td>253</td>\n",
              "      <td>250</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>214</td>\n",
              "      <td>218</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>30</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>192</td>\n",
              "      <td>86</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>86</td>\n",
              "      <td>250</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>217</td>\n",
              "      <td>246</td>\n",
              "      <td>151</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>179</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>231</td>\n",
              "      <td>54</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>191</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>109</td>\n",
              "      <td>83</td>\n",
              "      <td>199</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>243</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>202</td>\n",
              "      <td>147</td>\n",
              "      <td>147</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>29</td>\n",
              "      <td>200</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>174</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>89</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>252</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>212</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>83</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>240</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>240</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>186</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>224</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>232</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>163</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>200</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>209</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>206</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>202</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>161</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>245</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>212</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>194</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>48</td>\n",
              "      <td>209</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>243</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>233</td>\n",
              "      <td>243</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>239</td>\n",
              "      <td>86</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>182</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>243</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>76</td>\n",
              "      <td>146</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>146</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>141</td>\n",
              "      <td>139</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>185</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>146</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>185</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>185</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>185</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>220</td>\n",
              "      <td>179</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>247</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>202</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>242</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>254</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>207</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>254</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>254</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>239</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>254</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>254</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195</td>\n",
              "      <td>142</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>251</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195</td>\n",
              "      <td>227</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>153</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>240</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>251</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>255</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>234</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>245</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>234</td>\n",
              "      <td>169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>199</td>\n",
              "      <td>182</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>154</td>\n",
              "      <td>205</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>72</td>\n",
              "      <td>128</td>\n",
              "      <td>203</td>\n",
              "      <td>208</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>254</td>\n",
              "      <td>129</td>\n",
              "      <td>113</td>\n",
              "      <td>186</td>\n",
              "      <td>245</td>\n",
              "      <td>251</td>\n",
              "      <td>189</td>\n",
              "      <td>75</td>\n",
              "      <td>56</td>\n",
              "      <td>136</td>\n",
              "      <td>254</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>216</td>\n",
              "      <td>233</td>\n",
              "      <td>233</td>\n",
              "      <td>159</td>\n",
              "      <td>104</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>254</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>254</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>254</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>206</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>186</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>209</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>155</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>157</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>103</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>208</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>215</td>\n",
              "      <td>101</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>210</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>248</td>\n",
              "      <td>161</td>\n",
              "      <td>222</td>\n",
              "      <td>222</td>\n",
              "      <td>246</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>229</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>218</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>215</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>214</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>224</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>215</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>247</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>200</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>216</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>200</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>231</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>223</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "      <td>248</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>216</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>152</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>107</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>206</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>139</td>\n",
              "      <td>234</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>154</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>205</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>250</td>\n",
              "      <td>208</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>200</td>\n",
              "      <td>237</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>209</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>209</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>213</td>\n",
              "      <td>90</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>129</td>\n",
              "      <td>208</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>159</td>\n",
              "      <td>129</td>\n",
              "      <td>90</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-843d9822-deb6-4389-9ffb-218883e7ed33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-843d9822-deb6-4389-9ffb-218883e7ed33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-843d9822-deb6-4389-9ffb-218883e7ed33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b56235a3-5523-4ff5-a009-b19b5aaa571b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b56235a3-5523-4ff5-a009-b19b5aaa571b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b56235a3-5523-4ff5-a009-b19b5aaa571b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Reading the dataset\n",
        "\n",
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3UDfiAipJQWN"
      },
      "outputs": [],
      "source": [
        "##### Classificatie van MNIST\n",
        "\n",
        "# Split into features and targets\n",
        "y_train = df_train['label']\n",
        "X_train = df_train.drop('label', axis=1)\n",
        "\n",
        "y_test = df_test['label']\n",
        "X_test = df_test.drop('label', axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)\n",
        "X_train = np.asarray(X_train)\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "# To reduce the computation time, you can limit the number of training samples. For example to 2000 digits.\n",
        "\n",
        "\n",
        "training_size = 2000\n",
        "\n",
        "X_train = X_train[0:training_size,:]\n",
        "y_train = y_train[0:training_size]\n",
        "\n",
        "\n",
        "# Scaling\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Preparing the MNIST Dataset for Classification**\n",
        "\n",
        "This code prepares the **MNIST** dataset for training a **machine learning** model. The MNIST dataset contains **28x28** pixel images of **handwritten** digits (0-9).\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Splitting Features and Targets**\n",
        "\n",
        "```python\n",
        "y_train = df_train['label']\n",
        "X_train = df_train.drop('label', axis=1)\n",
        "\n",
        "y_test = df_test['label']\n",
        "X_test = df_test.drop('label', axis=1)\n",
        "```\n",
        "\n",
        "* **y\\_train** and **y\\_test**:\n",
        "\n",
        "  * These are your **target** values (the **actual** digit labels).\n",
        "* **X\\_train** and **X\\_test**:\n",
        "\n",
        "  * These are your **features** (the **pixel** values of each image).\n",
        "* **drop('label', axis=1)**:\n",
        "\n",
        "  * Removes the **label** column so that you only have the **pixel** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Convert to Numpy Arrays**\n",
        "\n",
        "```python\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)\n",
        "X_train = np.asarray(X_train)\n",
        "X_test = np.asarray(X_test)\n",
        "```\n",
        "\n",
        "* Converts the **Pandas** DataFrames to **Numpy** arrays.\n",
        "* This is necessary for most machine learning models in **Python**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Reduce the Training Size (Optional)**\n",
        "\n",
        "```python\n",
        "training_size = 2000\n",
        "\n",
        "X_train = X_train[0:training_size, :]\n",
        "y_train = y_train[0:training_size]\n",
        "```\n",
        "\n",
        "* **training\\_size = 2000**:\n",
        "\n",
        "  * Limits the training set to **2000** samples to make training **faster**.\n",
        "* **X\\_train\\[0\\:training\\_size, :]**:\n",
        "\n",
        "  * Takes only the **first 2000** rows of the training data.\n",
        "* **y\\_train\\[0\\:training\\_size]**:\n",
        "\n",
        "  * Takes only the **first 2000** labels.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Scaling the Pixel Values**\n",
        "\n",
        "```python\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "```\n",
        "\n",
        "* **astype('float32')**:\n",
        "\n",
        "  * Converts the pixel values to **floating-point** numbers.\n",
        "* **/= 255**:\n",
        "\n",
        "  * **Scales** the pixel values from **0-255** to **0-1**.\n",
        "* **Why Scaling?**:\n",
        "\n",
        "  * Makes the model **train** faster.\n",
        "  * Prevents **large** numbers from **dominating** the learning process.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Why This is Important**\n",
        "\n",
        "* **Smaller Training Set**:\n",
        "\n",
        "  * Faster **training** and **testing**.\n",
        "* **Scaled Data**:\n",
        "\n",
        "  * Better **model** performance.\n",
        "* **Efficient**:\n",
        "\n",
        "  * Prepares your data in a way that **reduces** computation time.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TtAj3o9lNWRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation via random search\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=1, tol=1e-2)\n",
        "parameters = {'C': uniform(0.01, 100), 'solver':['liblinear','saga']}\n",
        "\n",
        "\n",
        "n_iter_search = 1\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
        "\n",
        "random_search = random_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', random_search.best_score_)\n",
        "print('Best parameters :',random_search.best_params_  )\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w4QlF6-kx2q",
        "outputId": "73c134df-6f42-4e99-c073-522c8738a8c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best accuracy :  0.6905\n",
            "Best parameters : {'C': np.float64(77.81302869864075), 'solver': 'liblinear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.94      0.84      1195\n",
            "           1       0.57      0.97      0.72      1352\n",
            "           2       0.73      0.85      0.79      1157\n",
            "           3       0.58      0.81      0.67      1258\n",
            "           4       0.77      0.79      0.78      1140\n",
            "           5       0.00      0.00      0.00      1076\n",
            "           6       0.79      0.92      0.85      1167\n",
            "           7       0.75      0.88      0.81      1268\n",
            "           8       0.89      0.01      0.01      1174\n",
            "           9       0.67      0.62      0.64      1213\n",
            "\n",
            "    accuracy                           0.69     12000\n",
            "   macro avg       0.65      0.68      0.61     12000\n",
            "weighted avg       0.66      0.69      0.62     12000\n",
            "\n",
            "[[1119    5    9    8    2    0   51    0    0    1]\n",
            " [   0 1316   25    8    0    0    2    1    0    0]\n",
            " [  19   53  985   23   15    0   42   18    0    2]\n",
            " [  16   55   91 1014    1    0   24   38    0   19]\n",
            " [   3   53   10    0  898    0   42    9    0  125]\n",
            " [ 197  210   19  399   45    0   75   45    1   85]\n",
            " [  25   35   24    5    6    0 1072    0    0    0]\n",
            " [  19   66   30    2   18    0    1 1113    0   19]\n",
            " [  41  461  130  280   41    0   33   65    8  115]\n",
            " [  20   56   18   21  139    0    7  202    0  750]]\n",
            "68.95833333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Cross-Validation with RandomizedSearchCV for Logistic Regression**\n",
        "\n",
        "This code uses **RandomizedSearchCV** to **automatically** find the **best** hyperparameters for a **Logistic Regression** model. It is a faster, more **efficient** way to **tune** your model compared to **GridSearchCV**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Create the Logistic Regression Model**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1, tol=1e-2)\n",
        "```\n",
        "\n",
        "* **LogisticRegression()**:\n",
        "\n",
        "  * Creates a **logistic regression** model.\n",
        "* **max\\_iter=1**:\n",
        "\n",
        "  * Limits the training to **1** iteration (**very low**, usually **100** or **1000** is better).\n",
        "* **tol=1e-2**:\n",
        "\n",
        "  * Sets the **tolerance** for convergence (how precise the solution needs to be).\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Define the Hyperparameter Space**\n",
        "\n",
        "```python\n",
        "from scipy.stats import uniform\n",
        "\n",
        "parameters = {'C': uniform(0.01, 100), 'solver': ['liblinear', 'saga']}\n",
        "```\n",
        "\n",
        "* **C**:\n",
        "\n",
        "  * Controls the **strength** of the regularization.\n",
        "  * **Smaller** values make the model **more** strict (less likely to overfit).\n",
        "  * **uniform(0.01, 100)** means it will **randomly** pick values between **0.01** and **100**.\n",
        "* **solver**:\n",
        "\n",
        "  * **liblinear**: Good for small datasets.\n",
        "  * **saga**: Faster for large datasets, supports **l1** and **l2** penalties.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Set Up RandomizedSearchCV**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_iter_search = 1  # Test only 1 random combination\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=parameters,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    n_iter=n_iter_search,\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    verbose=1  # Print progress information\n",
        ")\n",
        "```\n",
        "\n",
        "* **cv=5**:\n",
        "\n",
        "  * Uses **5-fold cross-validation** for **more reliable** results.\n",
        "* **n\\_iter=1**:\n",
        "\n",
        "  * Tests **1** random hyperparameter combination (very small, usually **10** or **50** is better).\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Uses **all** available CPU cores for **faster** training.\n",
        "* **verbose=1**:\n",
        "\n",
        "  * Shows you what is happening in the background.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Train the Model**\n",
        "\n",
        "```python\n",
        "random_search = random_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Trains the logistic regression model using **random** hyperparameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Print the Best Hyperparameters and Accuracy**\n",
        "\n",
        "```python\n",
        "best_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', best_accuracy)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** accuracy found during training.\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** combination of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Make Predictions on the Test Set**\n",
        "\n",
        "```python\n",
        "y_pred = random_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Uses the **best** model found during the search to make **predictions** on the **test** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Evaluate the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows you precision, recall, f1-score, and support.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows you how many correct and incorrect predictions were made.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Prints the **overall** accuracy as a percentage.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best accuracy : 0.92\n",
        "Best parameters : {'C': 1.5, 'solver': 'liblinear'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "Test Accuracy: 95.0\n",
        "```\n",
        "\n",
        "* The best model had **92%** accuracy on the **training** set and **95%** on the **test** set.\n",
        "* The best **hyperparameters** might be something like **C=1.5** and **solver='liblinear'**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Why This is Important**\n",
        "\n",
        "* **Faster**:\n",
        "\n",
        "  * Tests **random** combinations instead of **every** possible combination, making it **faster**.\n",
        "* **Efficient**:\n",
        "\n",
        "  * Finds the **best** hyperparameters without **wasting** time.\n",
        "* **Flexible**:\n",
        "\n",
        "  * Works well with both **small** and **large** datasets.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YwsHLhU8Nsi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing an SVM model. Be aware that this can take a lot of time to compute\n",
        "model = SVC()\n",
        "parameters = {'kernel': ['linear','rbf','poly'],\n",
        "              'C': uniform(0.01, 1000), # haal C uit een random uniform distribution\n",
        "              'gamma': uniform(0.001, 1)}\n",
        "\n",
        "\n",
        "n_iter_search = 1\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(model, param_distributions=parameters,cv=5,n_iter=n_iter_search,n_jobs = -1,verbose=1)\n",
        "\n",
        "random_search = random_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', random_search.best_score_)\n",
        "print('Best parameters :',random_search.best_params_  )\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8gB2061lJCz",
        "outputId": "862e7b53-8022-48f9-8df6-3a80bb748565"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Best accuracy :  0.1325\n",
            "Best parameters : {'C': np.float64(809.3658362877726), 'gamma': np.float64(0.8951188846849292), 'kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1195\n",
            "           1       1.00      0.18      0.31      1352\n",
            "           2       0.10      1.00      0.18      1157\n",
            "           3       0.00      0.00      0.00      1258\n",
            "           4       0.00      0.00      0.00      1140\n",
            "           5       0.00      0.00      0.00      1076\n",
            "           6       0.00      0.00      0.00      1167\n",
            "           7       0.00      0.00      0.00      1268\n",
            "           8       0.00      0.00      0.00      1174\n",
            "           9       0.00      0.00      0.00      1213\n",
            "\n",
            "    accuracy                           0.12     12000\n",
            "   macro avg       0.11      0.12      0.05     12000\n",
            "weighted avg       0.12      0.12      0.05     12000\n",
            "\n",
            "[[   0    0 1195    0    0    0    0    0    0    0]\n",
            " [   0  246 1106    0    0    0    0    0    0    0]\n",
            " [   0    0 1157    0    0    0    0    0    0    0]\n",
            " [   0    0 1258    0    0    0    0    0    0    0]\n",
            " [   0    0 1140    0    0    0    0    0    0    0]\n",
            " [   0    0 1076    0    0    0    0    0    0    0]\n",
            " [   0    0 1167    0    0    0    0    0    0    0]\n",
            " [   0    0 1268    0    0    0    0    0    0    0]\n",
            " [   0    0 1174    0    0    0    0    0    0    0]\n",
            " [   0    0 1213    0    0    0    0    0    0    0]]\n",
            "11.691666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Training and Testing an SVM Model with RandomizedSearchCV**\n",
        "\n",
        "This code trains an **SVM (Support Vector Machine)** model and **automatically** finds the **best** hyperparameters using **RandomizedSearchCV**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Create the SVM Model**\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "```\n",
        "\n",
        "* **SVC()**:\n",
        "\n",
        "  * Creates a **Support Vector Machine** model.\n",
        "* This model needs to be **trained** with **data**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Define the Hyperparameter Space**\n",
        "\n",
        "```python\n",
        "from scipy.stats import uniform\n",
        "\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': uniform(0.01, 1000),  # Random values between 0.01 and 1000\n",
        "    'gamma': uniform(0.001, 1)  # Random values between 0.001 and 1\n",
        "}\n",
        "```\n",
        "\n",
        "* **kernel**:\n",
        "\n",
        "  * **linear**: Straight line decision boundary.\n",
        "  * **rbf** (Radial Basis Function): Curved decision boundary, very flexible.\n",
        "  * **poly** (Polynomial): More complex, curved decision boundary.\n",
        "* **C**:\n",
        "\n",
        "  * Controls how **strict** the model is about avoiding **errors**.\n",
        "  * **Smaller** values = **stricter**.\n",
        "* **gamma**:\n",
        "\n",
        "  * Controls how **far** each data point influences the decision boundary.\n",
        "  * **Smaller** values = **smoother** boundary.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Set Up RandomizedSearchCV**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_iter_search = 1  # Test only 1 random combination\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=parameters,\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    n_iter=n_iter_search,\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    verbose=1  # Print progress information\n",
        ")\n",
        "```\n",
        "\n",
        "* **cv=5**:\n",
        "\n",
        "  * Uses **5-fold cross-validation** for **more reliable** results.\n",
        "* **n\\_iter=1**:\n",
        "\n",
        "  * Tests **1** random hyperparameter combination (usually **10** or **50** is better).\n",
        "* **n\\_jobs=-1**:\n",
        "\n",
        "  * Uses **all** available CPU cores for **faster** training.\n",
        "* **verbose=1**:\n",
        "\n",
        "  * Shows you what is happening in the background.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Train the Model**\n",
        "\n",
        "```python\n",
        "random_search = random_search.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* Trains the SVM model using **random** hyperparameter combinations.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Print the Best Hyperparameters and Accuracy**\n",
        "\n",
        "```python\n",
        "best_accuracy = random_search.best_score_\n",
        "best_parameters = random_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', best_accuracy)\n",
        "print('Best parameters :', best_parameters)\n",
        "```\n",
        "\n",
        "* **best\\_score\\_**:\n",
        "\n",
        "  * The **highest** accuracy found during training.\n",
        "* **best\\_params\\_**:\n",
        "\n",
        "  * The **best** combination of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Make Predictions on the Test Set**\n",
        "\n",
        "```python\n",
        "y_pred = random_search.predict(X_test)\n",
        "```\n",
        "\n",
        "* Uses the **best** model found during the search to make **predictions** on the **test** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Evaluate the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "```\n",
        "\n",
        "* **classification\\_report**:\n",
        "\n",
        "  * Shows you precision, recall, f1-score, and support.\n",
        "* **confusion\\_matrix**:\n",
        "\n",
        "  * Shows you how many correct and incorrect predictions were made.\n",
        "* **accuracy\\_score**:\n",
        "\n",
        "  * Prints the **overall** accuracy as a percentage.\n",
        "\n",
        "---\n",
        "\n",
        "#### **8. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best accuracy : 0.92\n",
        "Best parameters : {'C': 500, 'gamma': 0.05, 'kernel': 'rbf'}\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      0.95      0.96       100\n",
        "           1       0.93      0.96      0.95       100\n",
        "\n",
        "    accuracy                           0.95       200\n",
        "   macro avg       0.95      0.95      0.95       200\n",
        "weighted avg       0.95      0.95      0.95       200\n",
        "\n",
        "[[95  5]\n",
        " [ 4 96]]\n",
        "Test Accuracy: 95.0\n",
        "```\n",
        "\n",
        "* The best model had **92%** accuracy on the **training** set and **95%** on the **test** set.\n",
        "* The best **hyperparameters** might be something like **C=500**, **gamma=0.05**, and **kernel='rbf'**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **9. Why This is Important**\n",
        "\n",
        "* **Faster**:\n",
        "\n",
        "  * Tests **random** combinations instead of **every** possible combination, making it **faster**.\n",
        "* **Efficient**:\n",
        "\n",
        "  * Finds the **best** hyperparameters without **wasting** time.\n",
        "* **Flexible**:\n",
        "\n",
        "  * Works well with both **small** and **large** datasets.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UiivOWKVOaBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the computation time and compare between one-vs-one and one-vs-rest classification\n",
        "\n",
        "import time\n",
        "\n",
        "# one-vs-one\n",
        "start = time.perf_counter()\n",
        "\n",
        "model = SVC(decision_function_shape='ovo')\n",
        "paramaters = [\n",
        "        {'kernel': ['linear'], 'C': np.linspace(1,10,10)}]\n",
        "grid_search = GridSearchCV(estimator = model,\n",
        "                           param_grid = paramaters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           n_jobs = -1)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_  )\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n",
        "\n",
        "stop = time.perf_counter()\n",
        "\n",
        "print('computation time one-vs-one: ',stop-start)\n",
        "\n",
        "\n",
        "# one-vs-rest\n",
        "\n",
        "start = time.perf_counter()\n",
        "\n",
        "model = SVC(decision_function_shape='ovr')\n",
        "paramaters = [\n",
        "        {'kernel': ['linear'], 'C': np.linspace(1,10,10)}]\n",
        "grid_search = GridSearchCV(estimator = model,\n",
        "                           param_grid = paramaters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           n_jobs = -1)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print('Best accuracy : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_  )\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(accuracy_score(y_test, y_pred) * 100)\n",
        "\n",
        "stop = time.perf_counter()\n",
        "\n",
        "print('computation time one-vs-rest: ',stop-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1JYT7hvlZxv",
        "outputId": "b330b294-b0dd-4000-8009-59f851ad45e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy :  0.9\n",
            "Best parameters : {'C': np.float64(1.0), 'kernel': 'linear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96      1195\n",
            "           1       0.92      0.99      0.95      1352\n",
            "           2       0.87      0.91      0.89      1157\n",
            "           3       0.89      0.86      0.87      1258\n",
            "           4       0.85      0.92      0.88      1140\n",
            "           5       0.85      0.86      0.86      1076\n",
            "           6       0.95      0.93      0.94      1167\n",
            "           7       0.94      0.89      0.91      1268\n",
            "           8       0.91      0.83      0.86      1174\n",
            "           9       0.88      0.84      0.86      1213\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.90      0.90      0.90     12000\n",
            "weighted avg       0.90      0.90      0.90     12000\n",
            "\n",
            "[[1164    0    2    4    2    8    8    0    6    1]\n",
            " [   0 1332    2    6    1    1    0    2    6    2]\n",
            " [  18    8 1048   15   19   14   16    7    9    3]\n",
            " [   6   20   33 1079    0   50    9   12   33   16]\n",
            " [   2    7   13    1 1048    1   11    2    2   53]\n",
            " [  12   18   13   47   17  927   11    2   25    4]\n",
            " [  12    7   24    0    6   28 1082    0    8    0]\n",
            " [   6    4   31    7   39    3    0 1123    1   54]\n",
            " [   6   50   21   40   11   50    7   11  969    9]\n",
            " [  11    5   21   11   86    9    0   42    9 1019]]\n",
            "89.925\n",
            "computation time one-vs-one:  12.88456303599969\n",
            "Best accuracy :  0.9\n",
            "Best parameters : {'C': np.float64(1.0), 'kernel': 'linear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96      1195\n",
            "           1       0.92      0.99      0.95      1352\n",
            "           2       0.87      0.91      0.89      1157\n",
            "           3       0.89      0.86      0.87      1258\n",
            "           4       0.85      0.92      0.88      1140\n",
            "           5       0.85      0.86      0.86      1076\n",
            "           6       0.95      0.93      0.94      1167\n",
            "           7       0.94      0.89      0.91      1268\n",
            "           8       0.91      0.83      0.86      1174\n",
            "           9       0.88      0.84      0.86      1213\n",
            "\n",
            "    accuracy                           0.90     12000\n",
            "   macro avg       0.90      0.90      0.90     12000\n",
            "weighted avg       0.90      0.90      0.90     12000\n",
            "\n",
            "[[1164    0    2    4    2    8    8    0    6    1]\n",
            " [   0 1332    2    6    1    1    0    2    6    2]\n",
            " [  18    8 1048   15   19   14   16    7    9    3]\n",
            " [   6   20   33 1079    0   50    9   12   33   16]\n",
            " [   2    7   13    1 1048    1   11    2    2   53]\n",
            " [  12   18   13   47   17  927   11    2   25    4]\n",
            " [  12    7   24    0    6   28 1082    0    8    0]\n",
            " [   6    4   31    7   39    3    0 1123    1   54]\n",
            " [   6   50   21   40   11   50    7   11  969    9]\n",
            " [  11    5   21   11   86    9    0   42    9 1019]]\n",
            "89.925\n",
            "computation time one-vs-rest:  12.42917788700015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Comparing One-vs-One and One-vs-Rest SVM Classification**\n",
        "\n",
        "This code compares the **training time** and **accuracy** of two different **SVM** (**Support Vector Machine**) classification strategies: **One-vs-One (OvO)** and **One-vs-Rest (OvR)**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. What are OvO and OvR?**\n",
        "\n",
        "* **One-vs-One (OvO)**:\n",
        "\n",
        "  * Creates a **separate** model for **every** possible pair of classes.\n",
        "  * If you have **3** classes (**A**, **B**, **C**), it creates **3** models:\n",
        "\n",
        "    * A vs B\n",
        "    * A vs C\n",
        "    * B vs C\n",
        "  * **Slower**, but can be **more accurate** for **small** datasets.\n",
        "\n",
        "* **One-vs-Rest (OvR)**:\n",
        "\n",
        "  * Creates a **separate** model for **each** class against **all** the **other** classes.\n",
        "  * If you have **3** classes (**A**, **B**, **C**), it creates **3** models:\n",
        "\n",
        "    * A vs (B + C)\n",
        "    * B vs (A + C)\n",
        "    * C vs (A + B)\n",
        "  * **Faster**, but can be **less accurate** for **complex** datasets.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Measuring the Computation Time for OvO**\n",
        "\n",
        "```python\n",
        "import time\n",
        "\n",
        "# Start the timer\n",
        "start = time.perf_counter()\n",
        "\n",
        "# Create the OvO SVM model\n",
        "model = SVC(decision_function_shape='ovo')\n",
        "\n",
        "# Set the hyperparameter grid\n",
        "paramaters = [{'kernel': ['linear'], 'C': np.linspace(1, 10, 10)}]\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print('Best accuracy : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_)\n",
        "\n",
        "# Test the model\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(classification_report(y_test, y_pred))\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "\n",
        "# Stop the timer\n",
        "stop = time.perf_counter()\n",
        "\n",
        "print('Computation time one-vs-one: ', stop-start)\n",
        "```\n",
        "\n",
        "* **decision\\_function\\_shape='ovo'**:\n",
        "\n",
        "  * Tells the SVM to use the **One-vs-One** strategy.\n",
        "* **GridSearchCV**:\n",
        "\n",
        "  * Searches for the **best** combination of hyperparameters.\n",
        "* **time.perf\\_counter()**:\n",
        "\n",
        "  * Measures the **computation** time.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Measuring the Computation Time for OvR**\n",
        "\n",
        "```python\n",
        "# Start the timer\n",
        "start = time.perf_counter()\n",
        "\n",
        "# Create the OvR SVM model\n",
        "model = SVC(decision_function_shape='ovr')\n",
        "\n",
        "# Set the hyperparameter grid\n",
        "paramaters = [{'kernel': ['linear'], 'C': np.linspace(1, 10, 10)}]\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=paramaters,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and accuracy\n",
        "print('Best accuracy : ', grid_search.best_score_)\n",
        "print('Best parameters :', grid_search.best_params_)\n",
        "\n",
        "# Test the model\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(classification_report(y_test, y_pred))\n",
        "cf = confusion_matrix(y_test, y_pred)\n",
        "print(cf)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
        "\n",
        "# Stop the timer\n",
        "stop = time.perf_counter()\n",
        "\n",
        "print('Computation time one-vs-rest: ', stop-start)\n",
        "```\n",
        "\n",
        "* **decision\\_function\\_shape='ovr'**:\n",
        "\n",
        "  * Tells the SVM to use the **One-vs-Rest** strategy.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Best accuracy (OvO): 0.92\n",
        "Best parameters (OvO): {'C': 5.0, 'kernel': 'linear'}\n",
        "Test Accuracy (OvO): 95.0\n",
        "Computation time one-vs-one: 25.0 seconds\n",
        "\n",
        "Best accuracy (OvR): 0.91\n",
        "Best parameters (OvR): {'C': 3.0, 'kernel': 'linear'}\n",
        "Test Accuracy (OvR): 94.0\n",
        "Computation time one-vs-rest: 15.0 seconds\n",
        "```\n",
        "\n",
        "* **OvO** is **slower** but might be **more accurate**.\n",
        "* **OvR** is **faster** but might have **slightly** lower accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Why This is Important**\n",
        "\n",
        "* **Computation Time**:\n",
        "\n",
        "  * Shows you which strategy is **faster**.\n",
        "* **Accuracy**:\n",
        "\n",
        "  * Helps you pick the **best** strategy for your data.\n",
        "* **Model Selection**:\n",
        "\n",
        "  * Gives you a **choice** between speed and accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m5FAZc6FO0_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifify your own handwritten digit\n",
        "\n",
        "\n",
        "model = LogisticRegression(C=1.3,solver= 'liblinear',multi_class='ovr')\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "testimage = imread(\"/content/testimage.jpg\", as_gray = True)\n",
        "\n",
        "\n",
        "imshow(testimage)\n",
        "\n",
        "testimage = testimage.reshape(1,-1)\n",
        "print(X_train[1].shape)\n",
        "\n",
        "result = model.predict(testimage)\n",
        "\n",
        "print('Recognized digit ',result[0])\n",
        "\n",
        "result_proba = model.predict_proba(testimage)\n",
        "\n",
        "print('Model confidence:', result_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "Js7AY9rvl2Cg",
        "outputId": "f34c698f-ed0f-4ecb-ffe1-3193427ef935"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784,)\n",
            "Recognized digit  3\n",
            "Model confidence: [[2.03795154e-05 3.20563831e-03 4.21271915e-03 8.34115625e-01\n",
            "  6.69317030e-03 2.53940336e-03 2.70599172e-05 1.15343950e-02\n",
            "  4.77127182e-02 8.99388911e-02]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-fabcee5b0def>:14: FutureWarning: `imshow` is deprecated since version 0.25 and will be removed in version 0.27. Please use `matplotlib`, `napari`, etc. to visualize images.\n",
            "  imshow(testimage)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Beginner-Friendly Explanation: Classify Your Own Handwritten Digit**\n",
        "\n",
        "This code lets you **predict** the digit in your own **handwritten** image using a **Logistic Regression** model. It also tells you how **confident** the model is about its prediction.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Create and Train the Model**\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(C=1.3, solver='liblinear', multi_class='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* **LogisticRegression()**:\n",
        "\n",
        "  * Creates a **logistic regression** model.\n",
        "* **C=1.3**:\n",
        "\n",
        "  * Controls how **strict** the model is about avoiding **errors**.\n",
        "* **solver='liblinear'**:\n",
        "\n",
        "  * A **fast** solver for **small** datasets.\n",
        "* **multi\\_class='ovr'**:\n",
        "\n",
        "  * Uses the **One-vs-Rest** strategy for **multi-class** classification.\n",
        "* **fit(X\\_train, y\\_train)**:\n",
        "\n",
        "  * **Trains** the model with your **training** data.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Load Your Handwritten Image**\n",
        "\n",
        "```python\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "\n",
        "testimage = imread(\"/content/testimage.jpg\", as_gray=True)\n",
        "imshow(testimage)\n",
        "```\n",
        "\n",
        "* **imread()**:\n",
        "\n",
        "  * Loads your image from the **file path**.\n",
        "* **as\\_gray=True**:\n",
        "\n",
        "  * Converts the image to **grayscale** (only **black** and **white**).\n",
        "* **imshow()**:\n",
        "\n",
        "  * Shows the **loaded** image.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Prepare the Image for Prediction**\n",
        "\n",
        "```python\n",
        "testimage = testimage.reshape(1, -1)\n",
        "print(X_train[1].shape)\n",
        "```\n",
        "\n",
        "* **reshape(1, -1)**:\n",
        "\n",
        "  * **Flattens** the image from a **2D** matrix (e.g., **28x28**) to a **1D** array (e.g., **784** pixels).\n",
        "* **print(X\\_train\\[1].shape)**:\n",
        "\n",
        "  * Prints the shape of a **single** training sample to **confirm** it matches the shape of your **test** image.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Make a Prediction**\n",
        "\n",
        "```python\n",
        "result = model.predict(testimage)\n",
        "print('Recognized digit:', result[0])\n",
        "```\n",
        "\n",
        "* **predict()**:\n",
        "\n",
        "  * Uses the **trained** model to **predict** the digit.\n",
        "* **result\\[0]**:\n",
        "\n",
        "  * Prints the **predicted** digit.\n",
        "\n",
        "---\n",
        "\n",
        "#### **5. Check the Model's Confidence**\n",
        "\n",
        "```python\n",
        "result_proba = model.predict_proba(testimage)\n",
        "print('Model confidence:', result_proba)\n",
        "```\n",
        "\n",
        "* **predict\\_proba()**:\n",
        "\n",
        "  * Returns the **probability** for each possible digit (**0-9**).\n",
        "* **result\\_proba**:\n",
        "\n",
        "  * Shows you **how confident** the model is for each digit.\n",
        "\n",
        "---\n",
        "\n",
        "#### **6. Expected Output (Example)**\n",
        "\n",
        "```\n",
        "Recognized digit: 4\n",
        "Model confidence: [[0.01, 0.05, 0.02, 0.03, 0.90, 0.01, 0.02, 0.01, 0.02, 0.02]]\n",
        "```\n",
        "\n",
        "* The model **predicted** the digit **4** with **90%** confidence.\n",
        "\n",
        "---\n",
        "\n",
        "#### **7. Why This is Important**\n",
        "\n",
        "* **Real-World Testing**:\n",
        "\n",
        "  * Lets you **test** your model with **new** images.\n",
        "* **Confidence Check**:\n",
        "\n",
        "  * Helps you understand how **confident** the model is about its **predictions**.\n",
        "* **Personalization**:\n",
        "\n",
        "  * You can try different **handwritten** styles to **challenge** your model.\n",
        "\n",
        "---\n",
        "\n",
        "Would you like me to show you how to **improve** this model for even **better** results? \n"
      ],
      "metadata": {
        "id": "Iq-nrw0GPSFx"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}